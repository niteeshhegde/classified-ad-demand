{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az3GlpeIsyZu",
        "colab_type": "text"
      },
      "source": [
        "# **Application of ML Algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZNYec8a-U7t",
        "colab_type": "text"
      },
      "source": [
        "## **Data Preparation and Environment Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgyeHUV-s9OT",
        "colab_type": "text"
      },
      "source": [
        "Different Machiene Learning Classification Algorithms were applied on the dataset.\n",
        "\n",
        "This is divided into 2 notebooks and this is the first one.\n",
        "\n",
        "The classification Algorithms applied and compared in this notebook are \n",
        "\n",
        "1.   Logistic Regression\n",
        "2.   Logistic Regression with SMOTE Resampling\n",
        "3.   Decision Tree Classifier\n",
        "4.   Random Forest Classifier\n",
        "5.   Gradient Boosting Classifier\n",
        "6.   CAT Boost Classifier\n",
        "\n",
        "As the data is highly skewed, all the above models are tried with and without resampling an the results are analysed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eqJaI20vkQv",
        "colab_type": "text"
      },
      "source": [
        "Second round of data preparation was essential and number of classes were reduced. \n",
        "\n",
        "Google's Colab has free GPUs and users can run 2 sessions at a time.\n",
        "\n",
        "This notebook was run on colab with Python 3 and GPU with 25Gi RAM.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDHSdOfGrSr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2FsVDtIqTCg",
        "colab_type": "code",
        "outputId": "63d0d98c-9236-490b-8377-1e6e608e03b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "!pip install gcloud"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcloud\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/ab/d0cee58db2d8445c26e6f5db25d9b1f1aa14a3ab30eea8ce77ae808d10ef/gcloud-0.18.3.tar.gz (454kB)\n",
            "\r\u001b[K     |▊                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 460kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from gcloud) (0.11.3)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from gcloud) (1.6.0)\n",
            "Requirement already satisfied: oauth2client>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from gcloud) (4.1.3)\n",
            "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /usr/local/lib/python3.6/dist-packages (from gcloud) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gcloud) (1.12.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.0.1->gcloud) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.0.1->gcloud) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.0.1->gcloud) (0.2.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf!=3.0.0.b2.post1,>=3.0.0b2->gcloud) (42.0.2)\n",
            "Building wheels for collected packages: gcloud\n",
            "  Building wheel for gcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcloud: filename=gcloud-0.18.3-cp36-none-any.whl size=602939 sha256=ca8751ca972917922697c55dfbf52e84f7f947d230e77e08475173d369bf706a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/9b/9c/a01be401658fea33b93a35d03921b0c638266821b264dc8662\n",
            "Successfully built gcloud\n",
            "Installing collected packages: gcloud\n",
            "Successfully installed gcloud-0.18.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEngMu0Cw5DE",
        "colab_type": "text"
      },
      "source": [
        "Authenticate yourself to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKCcWwMUrUCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nve0Xdstpefs",
        "colab_type": "code",
        "outputId": "7d1745e9-7c82-4cf2-df71-80472380244e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!pip install gcsfs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/3e/9f/864a9ff497ed4ba12502c4037db8c66fde0049d9dd0388bd55b67e5c4249/gcsfs-0.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHAXDV1fw9ze",
        "colab_type": "text"
      },
      "source": [
        "Set the project on GCP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_VW02kwsvD-",
        "colab_type": "code",
        "outputId": "c3fd55e6-4283-427c-d51f-2e61ef61d114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!gcloud config set project skilful-orb-255314"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm9iHokoxD7Z",
        "colab_type": "text"
      },
      "source": [
        "Copy the three_class_model_train.csv file which was prepared in data-prep-notebook-2 to the Disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl_6qfJ9thgt",
        "colab_type": "code",
        "outputId": "47a5cdf5-0135-4c02-962d-1ecd2648fdcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!gsutil cp gs://dataproc-e3bd1f7b-2e29-4da6-a5c4-077c164fd32a-us-central1/avito/test/three_class_model_train.csv /train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://dataproc-e3bd1f7b-2e29-4da6-a5c4-077c164fd32a-us-central1/avito/test/three_class_model_train.csv...\n",
            "\\ [1 files][137.4 MiB/137.4 MiB]                                                \n",
            "Operation completed over 1 objects/137.4 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdzjWotExelS",
        "colab_type": "text"
      },
      "source": [
        "**HACK For More RAM**\n",
        "\n",
        "Colab by default gives 12.5 Gi of RAM an there are no settings to configure and increase it.\n",
        "\n",
        "Only way to get 25 Gi of RAM is to crash the container by running out of Memory.\n",
        "\n",
        "After crashing, memory can be upgraded. \n",
        "\n",
        "Lets Crash it,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l99LzxpUyBOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr=[]\n",
        "while(1):\n",
        "  arr.append('42')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ys76HPDykPj",
        "colab_type": "text"
      },
      "source": [
        "Import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT6iu4f3pmMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gcsfs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXEOLqUcpsmG",
        "colab_type": "code",
        "outputId": "cd88bbe4-66c8-4c65-9384-573a06b45a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "df_train = pd.read_csv('/train.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>region_en</th>\n",
              "      <th>category_name_en</th>\n",
              "      <th>parent_category_name_en</th>\n",
              "      <th>user_type</th>\n",
              "      <th>weekend</th>\n",
              "      <th>price</th>\n",
              "      <th>description_len</th>\n",
              "      <th>title_len</th>\n",
              "      <th>param_combined_len</th>\n",
              "      <th>image_present</th>\n",
              "      <th>image_top_1</th>\n",
              "      <th>deal_class_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sverdlovsk oblast</td>\n",
              "      <td>Children's products and toys</td>\n",
              "      <td>Personal belongings</td>\n",
              "      <td>Private</td>\n",
              "      <td>0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Samara oblast</td>\n",
              "      <td>Furniture and interior</td>\n",
              "      <td>For the home and garden</td>\n",
              "      <td>Private</td>\n",
              "      <td>1</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>692.0</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rostov oblast</td>\n",
              "      <td>Audio and video</td>\n",
              "      <td>Consumer electronics</td>\n",
              "      <td>Private</td>\n",
              "      <td>1</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>3032.0</td>\n",
              "      <td>Okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tatarstan</td>\n",
              "      <td>Children's products and toys</td>\n",
              "      <td>Personal belongings</td>\n",
              "      <td>Company</td>\n",
              "      <td>0</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>796.0</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Volgograd oblast</td>\n",
              "      <td>Cars</td>\n",
              "      <td>Transport</td>\n",
              "      <td>Private</td>\n",
              "      <td>0</td>\n",
              "      <td>40000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>2264.0</td>\n",
              "      <td>Poor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           region_en              category_name_en  ... image_top_1 deal_class_5\n",
              "0  Sverdlovsk oblast  Children's products and toys  ...      1008.0         Poor\n",
              "1      Samara oblast        Furniture and interior  ...       692.0         Poor\n",
              "2      Rostov oblast               Audio and video  ...      3032.0         Okay\n",
              "3          Tatarstan  Children's products and toys  ...       796.0         Good\n",
              "4   Volgograd oblast                          Cars  ...      2264.0         Poor\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXDzhTtM0aQs",
        "colab_type": "text"
      },
      "source": [
        "These columns are selected after data preparation:\n",
        "\n",
        "\n",
        "1.   region_en : Region where the ad was posted\n",
        "2.   category_name_en : Category name of the product. \n",
        "3.   parent_category_name_en : Parent Category name of the product. \n",
        "4.   user_type : Type of user\n",
        "5.   weekend : Whether the ad was posted on weekday or weekend.\n",
        "6.   price : Selling price of the product.\n",
        "7.   description_len : As NLP and tokenizer will be used in the later notebooks, just the number of words in description is taken into acount.\n",
        "8.   title_len : Just like description, number of words in title is considered.\n",
        "9.   param_combined_len : All the 3 optional parameters are combined and the total number of words in parameters combined is considered.\n",
        "10.  image_present : Boolean column with True if image present else false.\n",
        "11.  image_top_1 : Avito's code for image quality.\n",
        "\n",
        "**Note** : category_name_en was eliminated and only parent_category_name_en was considered for modelling due to the large number of categorical vaiables present.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lkL0O84ynl8",
        "colab_type": "text"
      },
      "source": [
        "Target variable **deal_class_5** consists on 3 classes :\n",
        "\n",
        "\n",
        "1.   Poor [Deal Probability between 0 and 0.3]\n",
        "2.   Okay [Deal Probability between 0.3 and 0.7]\n",
        "3.   Good [Deal Probability between 0.7 and 1]\n",
        "\n",
        "These classes were fixed after multiple rounds of selection of number of classes and class intervals. The selected one did the best when Classification alorithms were applied.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4QVR4bMscDB",
        "colab_type": "code",
        "outputId": "c0018202-164b-4598-c9c0-a4bde4812a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1503424 entries, 0 to 1503423\n",
            "Data columns (total 12 columns):\n",
            "region_en                  1503424 non-null object\n",
            "category_name_en           1503424 non-null object\n",
            "parent_category_name_en    1503424 non-null object\n",
            "user_type                  1503424 non-null object\n",
            "weekend                    1503424 non-null int64\n",
            "price                      1503424 non-null float64\n",
            "description_len            1503424 non-null int64\n",
            "title_len                  1503424 non-null int64\n",
            "param_combined_len         1503424 non-null int64\n",
            "image_present              1503424 non-null bool\n",
            "image_top_1                1503424 non-null float64\n",
            "deal_class_5               1503424 non-null object\n",
            "dtypes: bool(1), float64(2), int64(4), object(5)\n",
            "memory usage: 127.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k154DNy8zyJX",
        "colab_type": "text"
      },
      "source": [
        "Import Libraries :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGsmm3-jv6nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhEb6zs_z6aq",
        "colab_type": "text"
      },
      "source": [
        "Dependent Variable X and Independent Variable y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQNHNGoiwPIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_train[['region_en','parent_category_name_en','user_type','weekend','price','description_len','title_len','param_combined_len','image_present','image_top_1']]\n",
        "y = df_train[['deal_class_5']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0JssE2z0H09",
        "colab_type": "text"
      },
      "source": [
        "Encoding is done on 3 categorical variables \n",
        "\n",
        "*   region_en\n",
        "*   parent_category_name_en\n",
        "*   user_type\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxc3LKg0wakK",
        "colab_type": "code",
        "outputId": "85f9d3c3-834a-43d6-92fd-090cef328219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "X_enc = pd.get_dummies(X, columns=['region_en','user_type','parent_category_name_en'], drop_first = True)\n",
        "X_enc.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weekend</th>\n",
              "      <th>price</th>\n",
              "      <th>description_len</th>\n",
              "      <th>title_len</th>\n",
              "      <th>param_combined_len</th>\n",
              "      <th>image_present</th>\n",
              "      <th>image_top_1</th>\n",
              "      <th>region_en_Bashkortostan</th>\n",
              "      <th>region_en_Belgorod oblast</th>\n",
              "      <th>region_en_Chelyabinsk oblast</th>\n",
              "      <th>region_en_Irkutsk oblast</th>\n",
              "      <th>region_en_Kaliningrad oblast</th>\n",
              "      <th>region_en_Kemerovo oblast</th>\n",
              "      <th>region_en_Khanty-Mansi Autonomous Okrug</th>\n",
              "      <th>region_en_Krasnodar Krai</th>\n",
              "      <th>region_en_Krasnoyarsk Krai</th>\n",
              "      <th>region_en_Nizhny Novgorod oblast</th>\n",
              "      <th>region_en_Novosibirsk oblast</th>\n",
              "      <th>region_en_Omsk oblast</th>\n",
              "      <th>region_en_Orenburg oblast</th>\n",
              "      <th>region_en_Perm Krai</th>\n",
              "      <th>region_en_Rostov oblast</th>\n",
              "      <th>region_en_Samara oblast</th>\n",
              "      <th>region_en_Saratov oblast</th>\n",
              "      <th>region_en_Stavropol Krai</th>\n",
              "      <th>region_en_Sverdlovsk oblast</th>\n",
              "      <th>region_en_Tatarstan</th>\n",
              "      <th>region_en_Tula oblast</th>\n",
              "      <th>region_en_Tyumen oblast</th>\n",
              "      <th>region_en_Udmurtia</th>\n",
              "      <th>region_en_Vladimir oblast</th>\n",
              "      <th>region_en_Volgograd oblast</th>\n",
              "      <th>region_en_Voronezh oblast</th>\n",
              "      <th>region_en_Yaroslavl oblast</th>\n",
              "      <th>user_type_Private</th>\n",
              "      <th>user_type_Shop</th>\n",
              "      <th>parent_category_name_en_Consumer electronics</th>\n",
              "      <th>parent_category_name_en_For business</th>\n",
              "      <th>parent_category_name_en_For the home and garden</th>\n",
              "      <th>parent_category_name_en_Hobbies &amp; leisure</th>\n",
              "      <th>parent_category_name_en_Personal belongings</th>\n",
              "      <th>parent_category_name_en_Real estate</th>\n",
              "      <th>parent_category_name_en_Services</th>\n",
              "      <th>parent_category_name_en_Transport</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>692.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>3032.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>796.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>40000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>2264.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   weekend  ...  parent_category_name_en_Transport\n",
              "0        0  ...                                  0\n",
              "1        1  ...                                  0\n",
              "2        1  ...                                  0\n",
              "3        0  ...                                  0\n",
              "4        0  ...                                  1\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2l39rl35ToI",
        "colab_type": "text"
      },
      "source": [
        "Test Train split : 12% of observations used for test.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m19p-hrhXhfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size = 0.12, random_state = 0, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuy1NcuK5hPN",
        "colab_type": "text"
      },
      "source": [
        "Validation Train split : 12% of observations from the previously train set used for validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mUvhhS3ZeGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.12, random_state = 0, stratify=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPb1VOC050S_",
        "colab_type": "text"
      },
      "source": [
        "Normaliation of numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLsIswQuwe2a",
        "colab_type": "code",
        "outputId": "fde0e315-60d1-4298-967b-bacb35eb3c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "sc = StandardScaler()\n",
        "X_train.loc[:,[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]] = sc.fit_transform(X_train[[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]])\n",
        "X_test.loc[:,[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]] = sc.transform(X_test[[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]])\n",
        "X_valid.loc[:,[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]] = sc.transform(X_valid[[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq7hpgwd6L8g",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrrqGvXj6O28",
        "colab_type": "text"
      },
      "source": [
        "## **Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOL3a6rx8Xcu",
        "colab_type": "text"
      },
      "source": [
        "As the data is highy skewed and **Okay : Good : Poor** are in the ratio\n",
        "**1 : 2 : 15** ,\n",
        "\n",
        "**F1 score** is considered as evaluation metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFD7t_e37nA4",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hla_8prLroQ-",
        "colab_type": "text"
      },
      "source": [
        "**Class weigth given as balanced**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haaFNSKFwkAp",
        "colab_type": "code",
        "outputId": "702b56aa-b524-4d65-a8cf-3c90d07ffa77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "clf = LogisticRegression(class_weight=\"balanced\")\n",
        "# Fit the model on the trainng data.\n",
        "clf.fit(X_train, y_train.values.ravel())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5YlWPEKaanz",
        "colab_type": "text"
      },
      "source": [
        "Validation Set : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_yApQt8wqNQ",
        "colab_type": "code",
        "outputId": "f8b332c7-26a1-47a4-c0ca-4bbd55bfeb53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.17      0.39      0.24     17217\n",
            "        Okay       0.15      0.62      0.25      8730\n",
            "        Poor       0.92      0.59      0.72    132815\n",
            "\n",
            "    accuracy                           0.57    158762\n",
            "   macro avg       0.42      0.53      0.40    158762\n",
            "weighted avg       0.80      0.57      0.64    158762\n",
            "\n",
            "[[ 6642  5257  5318]\n",
            " [ 2252  5412  1066]\n",
            " [29850 24429 78536]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqt4SZrFsDVo",
        "colab_type": "text"
      },
      "source": [
        " **Sampling using SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHO8PHEfxeyV",
        "colab_type": "code",
        "outputId": "c3bd6c0e-440e-4581-c200-7ca1c8261267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!pip install imblearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (0.22.1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zobBtPRxf9l",
        "colab_type": "code",
        "outputId": "b28a2382-c99e-4944-b460-681e1e446edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "  from imblearn.over_sampling import SMOTE\n",
        "  import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmDKKG4xjoO",
        "colab_type": "code",
        "outputId": "1e6f2aaa-bc6e-4075-d6d0-8532b87133f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "sm = SMOTE(sampling_strategy='auto',random_state=27)\n",
        "y_train_smote = y_train.iloc[:, 0]\n",
        "start = time.time()\n",
        "X_train_smote, y_train_smote = sm.fit_sample(X_train, y_train_smote)\n",
        "smote = LogisticRegression().fit(X_train_smote, y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time in seconds :  265.06606698036194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhDh6tuMdH5I",
        "colab_type": "text"
      },
      "source": [
        "Validation Set :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EmljOhNx7n-",
        "colab_type": "code",
        "outputId": "7da35dc1-8e2d-42aa-9c13-9f8f5f8f6d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = smote.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.17      0.39      0.24     17217\n",
            "        Okay       0.15      0.62      0.25      8730\n",
            "        Poor       0.92      0.59      0.72    132815\n",
            "\n",
            "    accuracy                           0.57    158762\n",
            "   macro avg       0.42      0.53      0.40    158762\n",
            "weighted avg       0.80      0.57      0.64    158762\n",
            "\n",
            "[[ 6646  5239  5332]\n",
            " [ 2247  5412  1071]\n",
            " [29836 24276 78703]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKB6Bo1xdLA9",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression Prediction on Test Set :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey0u1BTe0uzl",
        "colab_type": "code",
        "outputId": "51d7b757-2e34-419e-ecdd-6b3f2749fc15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = smote.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.17      0.38      0.23     19565\n",
            "        Okay       0.15      0.62      0.25      9920\n",
            "        Poor       0.93      0.59      0.72    150926\n",
            "\n",
            "    accuracy                           0.57    180411\n",
            "   macro avg       0.42      0.53      0.40    180411\n",
            "weighted avg       0.80      0.57      0.64    180411\n",
            "\n",
            "[[ 7397  6171  5997]\n",
            " [ 2621  6112  1187]\n",
            " [33879 27556 89491]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fwcs7yV8Bwf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9biI0xZLWB1v",
        "colab_type": "text"
      },
      "source": [
        "### Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJhiIvt9VPhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6cKAe8p-yhv",
        "colab_type": "text"
      },
      "source": [
        "Simple Decision Tree with balanced weight :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYcIZX1d0e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpk03fY3d-qS",
        "colab_type": "code",
        "outputId": "0a2e4c15-c57f-4c59-e3fe-9594a569f61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.24      0.26      0.25     17217\n",
            "        Okay       0.15      0.18      0.17      8730\n",
            "        Poor       0.88      0.86      0.87    132815\n",
            "\n",
            "    accuracy                           0.75    158762\n",
            "   macro avg       0.42      0.43      0.43    158762\n",
            "weighted avg       0.77      0.75      0.76    158762\n",
            "\n",
            "[[  4548   1905  10764]\n",
            " [  1828   1555   5347]\n",
            " [ 12574   6648 113593]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQq9uXnmukRL",
        "colab_type": "text"
      },
      "source": [
        "Use Entropy as criterion and set max depth 10:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVrIDCM7fOkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 10,class_weight=\"balanced\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWQs0Ljoe1UT",
        "colab_type": "code",
        "outputId": "d746c6d5-6311-494b-a479-06e977a5ec52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.50      0.30     17217\n",
            "        Okay       0.16      0.60      0.25      8730\n",
            "        Poor       0.94      0.61      0.74    132815\n",
            "\n",
            "    accuracy                           0.60    158762\n",
            "   macro avg       0.44      0.57      0.43    158762\n",
            "weighted avg       0.82      0.60      0.67    158762\n",
            "\n",
            "[[ 8637  4799  3781]\n",
            " [ 2451  5233  1046]\n",
            " [28433 23599 80783]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXIfKrebuqlO",
        "colab_type": "text"
      },
      "source": [
        "Use Gini Index as criterion and set max depth 10:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJtPqemzfVuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth = 10,class_weight=\"balanced\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X78mSFHrfdDN",
        "colab_type": "code",
        "outputId": "bfc950cc-e2c4-448e-a152-7882a3e51c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.21      0.54      0.30     17217\n",
            "        Okay       0.16      0.58      0.25      8730\n",
            "        Poor       0.95      0.58      0.72    132815\n",
            "\n",
            "    accuracy                           0.58    158762\n",
            "   macro avg       0.44      0.57      0.42    158762\n",
            "weighted avg       0.82      0.58      0.65    158762\n",
            "\n",
            "[[ 9285  4488  3444]\n",
            " [ 2648  5093   989]\n",
            " [33045 22149 77621]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyDAZHuEuuzj",
        "colab_type": "text"
      },
      "source": [
        "Use Entropy as criterion and set max depth 15:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEcdJPLqHRxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 15,class_weight=\"balanced\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM4VOpK5f5ef",
        "colab_type": "code",
        "outputId": "6507b99b-91b5-444d-a13a-594dd6a36aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.53      0.31     17217\n",
            "        Okay       0.16      0.56      0.25      8730\n",
            "        Poor       0.94      0.62      0.75    132815\n",
            "\n",
            "    accuracy                           0.61    158762\n",
            "   macro avg       0.44      0.57      0.44    158762\n",
            "weighted avg       0.82      0.61      0.67    158762\n",
            "\n",
            "[[ 9138  4344  3735]\n",
            " [ 2571  4913  1246]\n",
            " [29306 21288 82221]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEnsrQc6u4P0",
        "colab_type": "text"
      },
      "source": [
        "Use Gini Index as criterion and set max depth 15:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTbtNPcKfPUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth = 15,class_weight=\"balanced\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4imzRMdQf8W2",
        "colab_type": "code",
        "outputId": "0de01068-e5e7-49ce-f90d-f6656e8998ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.23      0.52      0.32     17217\n",
            "        Okay       0.16      0.57      0.25      8730\n",
            "        Poor       0.94      0.62      0.75    132815\n",
            "\n",
            "    accuracy                           0.61    158762\n",
            "   macro avg       0.44      0.57      0.44    158762\n",
            "weighted avg       0.82      0.61      0.67    158762\n",
            "\n",
            "[[ 9017  4448  3752]\n",
            " [ 2532  4944  1254]\n",
            " [28345 22064 82406]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJLtRcTjvKQ_",
        "colab_type": "text"
      },
      "source": [
        "Use Entropy as criterion and set max depth 7:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuSPMvOSvObG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 7,class_weight=\"balanced\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNzIv4zTf_00",
        "colab_type": "code",
        "outputId": "a42e76d3-24b4-4eaf-f709-564885b0c566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.20      0.38      0.27     17217\n",
            "        Okay       0.13      0.71      0.22      8730\n",
            "        Poor       0.94      0.56      0.71    132815\n",
            "\n",
            "    accuracy                           0.55    158762\n",
            "   macro avg       0.43      0.55      0.40    158762\n",
            "weighted avg       0.82      0.55      0.63    158762\n",
            "\n",
            "[[ 6593  7068  3556]\n",
            " [ 1668  6178   884]\n",
            " [24037 33882 74896]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtcFcGMgvUma",
        "colab_type": "text"
      },
      "source": [
        "Use Entropy as Gini Index and set max depth 7:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl3drhfpV0Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth = 7,class_weight=\"balanced\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl48Dg53gDgx",
        "colab_type": "code",
        "outputId": "55a19494-9faf-4327-b13e-57c10ef88f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.20      0.50      0.28     17217\n",
            "        Okay       0.14      0.62      0.23      8730\n",
            "        Poor       0.95      0.55      0.70    132815\n",
            "\n",
            "    accuracy                           0.55    158762\n",
            "   macro avg       0.43      0.56      0.40    158762\n",
            "weighted avg       0.82      0.55      0.63    158762\n",
            "\n",
            "[[ 8597  5228  3392]\n",
            " [ 2473  5405   852]\n",
            " [32192 27210 73413]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1vhOTfntDIx",
        "colab_type": "text"
      },
      "source": [
        "Without depth with Smote resampled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsbT78k-tBL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train_smote,y_train_smote)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8z3lPWWtJsN",
        "colab_type": "code",
        "outputId": "dfd8266b-48b4-4cd1-f11d-d2c0c4664061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.23      0.30      0.26     17217\n",
            "        Okay       0.15      0.21      0.17      8730\n",
            "        Poor       0.88      0.82      0.85    132815\n",
            "\n",
            "    accuracy                           0.73    158762\n",
            "   macro avg       0.42      0.44      0.43    158762\n",
            "weighted avg       0.77      0.73      0.75    158762\n",
            "\n",
            "[[  5081   2167   9969]\n",
            " [  1951   1815   4964]\n",
            " [ 14965   8400 109450]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzLpBBZ7lc_O",
        "colab_type": "text"
      },
      "source": [
        "Model with Entropy Criterion max_depth set to 15 with Smote Resampled data produced best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL0CSF-BgPXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 15)\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train_smote,y_train_smote)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RNhSMrAlkdp",
        "colab_type": "code",
        "outputId": "86c9bf75-287e-4817-bbbc-34722e18aa9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.24      0.44      0.31     17217\n",
            "        Okay       0.17      0.51      0.25      8730\n",
            "        Poor       0.92      0.70      0.80    132815\n",
            "\n",
            "    accuracy                           0.66    158762\n",
            "   macro avg       0.44      0.55      0.45    158762\n",
            "weighted avg       0.81      0.66      0.72    158762\n",
            "\n",
            "[[ 7573  3975  5669]\n",
            " [ 2182  4409  2139]\n",
            " [21687 17783 93345]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmqvFa_Wl-RF",
        "colab_type": "text"
      },
      "source": [
        "**On Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3YSTSxzmAN4",
        "colab_type": "code",
        "outputId": "5f32c431-bc90-42c5-8b4b-225cd81a08fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.24      0.44      0.31     19565\n",
            "        Okay       0.17      0.49      0.25      9920\n",
            "        Poor       0.92      0.70      0.80    150926\n",
            "\n",
            "    accuracy                           0.66    180411\n",
            "   macro avg       0.44      0.54      0.45    180411\n",
            "weighted avg       0.81      0.66      0.71    180411\n",
            "\n",
            "[[  8526   4639   6400]\n",
            " [  2433   4884   2603]\n",
            " [ 24699  20039 106188]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bedQ_SwmRm4",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S2qPK5zWLUe",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Dm8SumC5tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRxcR6z7AadT",
        "colab_type": "text"
      },
      "source": [
        "Base Random Forest Classifier with 100 trees with balanced class weight:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUBODcAWnfUu",
        "colab_type": "code",
        "outputId": "f7843cdc-e21e-4179-d9f1-2321e0e8b815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(random_state=42, n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100building tree 2 of 100\n",
            "\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   58.8s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  211.23202991485596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.4min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6wjzaulnhk0",
        "colab_type": "code",
        "outputId": "761446b6-ba96-46ab-a476-260591036771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    5.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.42      0.14      0.21     17217\n",
            "        Okay       0.27      0.08      0.12      8730\n",
            "        Poor       0.86      0.97      0.91    132815\n",
            "\n",
            "    accuracy                           0.83    158762\n",
            "   macro avg       0.52      0.40      0.41    158762\n",
            "weighted avg       0.78      0.83      0.79    158762\n",
            "\n",
            "[[  2442    617  14158]\n",
            " [   883    661   7186]\n",
            " [  2492   1160 129163]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL9aXYeDuFDa",
        "colab_type": "text"
      },
      "source": [
        "Default 100 trees Random Forest with SMOTE Resampled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdU5IL2Kt99p",
        "colab_type": "code",
        "outputId": "ddecbaa3-6d64-42cf-e546-77fc345cb9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(random_state=42, n_estimators = 100, n_jobs=-1,verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 2 of 100building tree 3 of 100\n",
            "\n",
            "building tree 1 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.7min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  502.57410621643066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  8.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X78h6WVMuJZH",
        "colab_type": "code",
        "outputId": "4b3c6320-c315-45a7-b4ae-a860ad23aceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.30      0.31      0.30     17217\n",
            "        Okay       0.20      0.25      0.22      8730\n",
            "        Poor       0.89      0.87      0.88    132815\n",
            "\n",
            "    accuracy                           0.78    158762\n",
            "   macro avg       0.46      0.48      0.47    158762\n",
            "weighted avg       0.79      0.78      0.78    158762\n",
            "\n",
            "[[  5358   2124   9735]\n",
            " [  1909   2143   4678]\n",
            " [ 10758   6428 115629]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ3GuymL5ZrN",
        "colab_type": "code",
        "outputId": "e7009d2e-1281-49db-ffd4-28e3632d6e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.30      0.31      0.30     19565\n",
            "        Okay       0.20      0.23      0.21      9920\n",
            "        Poor       0.89      0.87      0.88    150926\n",
            "\n",
            "    accuracy                           0.78    180411\n",
            "   macro avg       0.46      0.47      0.47    180411\n",
            "weighted avg       0.79      0.78      0.78    180411\n",
            "\n",
            "[[  6054   2376  11135]\n",
            " [  2135   2329   5456]\n",
            " [ 12187   7214 131525]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8I6EQLLvx9x",
        "colab_type": "text"
      },
      "source": [
        "Random Forest with Gini Index and Max depth 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl8U5KyUWfUR",
        "colab_type": "code",
        "outputId": "2808ea07-7260-4805-ab11-4d97d12ed841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=10, random_state=42, n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100building tree 2 of 100\n",
            "\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   26.3s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100building tree 92 of 100\n",
            "\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  97.64019560813904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8fWuSaaYLra",
        "colab_type": "code",
        "outputId": "0fe2ac88-27f3-4db8-cbcc-50bb505a93b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.20      0.49      0.28     17217\n",
            "        Okay       0.16      0.65      0.25      8730\n",
            "        Poor       0.95      0.57      0.71    132815\n",
            "\n",
            "    accuracy                           0.56    158762\n",
            "   macro avg       0.43      0.57      0.41    158762\n",
            "weighted avg       0.82      0.56      0.64    158762\n",
            "\n",
            "[[ 8489  5386  3342]\n",
            " [ 2282  5646   802]\n",
            " [32095 25370 75350]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGfN5McGY7Sg",
        "colab_type": "text"
      },
      "source": [
        "Random Forest with Entropy and Max depth 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL9YB58qY6tP",
        "colab_type": "code",
        "outputId": "b112d308-bbe4-4f4a-eb6f-ec4ac34e91b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=10, random_state=42, criterion=\"entropy\", n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100\n",
            "building tree 2 of 100\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   30.9s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  111.39498043060303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCDeYSR-Y561",
        "colab_type": "code",
        "outputId": "9cd9d3cf-9ba6-4d73-b6f1-f91cd549df3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.20      0.49      0.28     17217\n",
            "        Okay       0.15      0.65      0.25      8730\n",
            "        Poor       0.95      0.57      0.71    132815\n",
            "\n",
            "    accuracy                           0.56    158762\n",
            "   macro avg       0.43      0.57      0.41    158762\n",
            "weighted avg       0.82      0.56      0.64    158762\n",
            "\n",
            "[[ 8458  5412  3347]\n",
            " [ 2292  5640   798]\n",
            " [32172 25432 75211]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu_s47rBxHw-",
        "colab_type": "text"
      },
      "source": [
        "Random Forest with Gini Index and Max depth 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClRg1AoFxIS6",
        "colab_type": "code",
        "outputId": "c5672824-cfa1-43e0-934a-1496eaac2002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=15, random_state=42, n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100building tree 2 of 100\n",
            "\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   38.8s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  139.0405101776123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL65EmP_xPwe",
        "colab_type": "code",
        "outputId": "bbb350b9-b520-45a7-b537-1240089317c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.50      0.30     17217\n",
            "        Okay       0.17      0.62      0.27      8730\n",
            "        Poor       0.94      0.62      0.75    132815\n",
            "\n",
            "    accuracy                           0.61    158762\n",
            "   macro avg       0.44      0.58      0.44    158762\n",
            "weighted avg       0.82      0.61      0.68    158762\n",
            "\n",
            "[[ 8610  4825  3782]\n",
            " [ 2281  5376  1073]\n",
            " [28457 21508 82850]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YudSBWFmxb7R",
        "colab_type": "text"
      },
      "source": [
        "Random Forest with Entropy and Max depth 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zNjgeDLxZH7",
        "colab_type": "code",
        "outputId": "48495a06-2075-4f78-ce86-621f6b9f5782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=15, random_state=42, criterion=\"entropy\", n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100building tree 2 of 100\n",
            "\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   41.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  140.7048487663269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quooKN7dxY8f",
        "colab_type": "code",
        "outputId": "5f8cc473-2225-4145-8243-92fe6f9a3224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.50      0.30     17217\n",
            "        Okay       0.17      0.61      0.27      8730\n",
            "        Poor       0.94      0.62      0.75    132815\n",
            "\n",
            "    accuracy                           0.61    158762\n",
            "   macro avg       0.44      0.58      0.44    158762\n",
            "weighted avg       0.82      0.61      0.68    158762\n",
            "\n",
            "[[ 8582  4837  3798]\n",
            " [ 2275  5367  1088]\n",
            " [28766 21116 82933]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDu2eDGcxn3H",
        "colab_type": "text"
      },
      "source": [
        "Random Forest with Gini Index and Max depth 14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHF81-dMxYrz",
        "colab_type": "code",
        "outputId": "c4824a33-818a-4329-8330-e47e7f90fb46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=14, random_state=42, n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100\n",
            "building tree 2 of 100\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   33.9s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  127.18466067314148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l61WDUXZx1zk",
        "colab_type": "code",
        "outputId": "83cbdd06-8fe6-47b8-8fad-924ff2e4e11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.21      0.50      0.30     17217\n",
            "        Okay       0.17      0.62      0.26      8730\n",
            "        Poor       0.95      0.61      0.74    132815\n",
            "\n",
            "    accuracy                           0.60    158762\n",
            "   macro avg       0.44      0.58      0.44    158762\n",
            "weighted avg       0.82      0.60      0.67    158762\n",
            "\n",
            "[[ 8587  4938  3692]\n",
            " [ 2297  5420  1013]\n",
            " [29372 22106 81337]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-AW3VZ4x4Q2",
        "colab_type": "text"
      },
      "source": [
        "Random Forest with Entropy and Max depth 14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGwsv8RAx1kk",
        "colab_type": "code",
        "outputId": "9ff87756-b381-4370-8609-45fe37974d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=14, random_state=42, criterion=\"entropy\", n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 100building tree 2 of 100\n",
            "\n",
            "building tree 3 of 100\n",
            "building tree 4 of 100\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n",
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   34.7s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  121.57087540626526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.9min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3MzCTCIyS7H",
        "colab_type": "code",
        "outputId": "93466a34-bb73-4d3e-9212-4495873e7646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.21      0.49      0.30     17217\n",
            "        Okay       0.17      0.63      0.26      8730\n",
            "        Poor       0.95      0.61      0.74    132815\n",
            "\n",
            "    accuracy                           0.60    158762\n",
            "   macro avg       0.44      0.58      0.43    158762\n",
            "weighted avg       0.82      0.60      0.67    158762\n",
            "\n",
            "[[ 8514  5014  3689]\n",
            " [ 2259  5462  1009]\n",
            " [29070 22386 81359]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oORnDZLs7TgT",
        "colab_type": "text"
      },
      "source": [
        "**Best Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7jRbkg4FVql",
        "colab_type": "text"
      },
      "source": [
        "Random Forest with Entropy and Max depth 15 with SMOTE Resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtXWOmAXyVB2",
        "colab_type": "code",
        "outputId": "40fbd39f-3391-4e5b-ee82-9e912a47a26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=15, random_state=42, criterion=\"entropy\", n_estimators = 100, n_jobs=-1,class_weight=\"balanced\",verbose = 3 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 2 of 100building tree 3 of 100\n",
            "building tree 4 of 100building tree 1 of 100\n",
            "\n",
            "\n",
            "building tree 5 of 100\n",
            "building tree 6 of 100\n",
            "building tree 7 of 100\n",
            "building tree 8 of 100\n",
            "building tree 9 of 100\n",
            "building tree 10 of 100\n",
            "building tree 11 of 100\n",
            "building tree 12 of 100\n",
            "building tree 13 of 100\n",
            "building tree 14 of 100\n",
            "building tree 15 of 100\n",
            "building tree 16 of 100\n",
            "building tree 17 of 100\n",
            "building tree 18 of 100\n",
            "building tree 19 of 100\n",
            "building tree 20 of 100\n",
            "building tree 21 of 100\n",
            "building tree 22 of 100\n",
            "building tree 23 of 100\n",
            "building tree 24 of 100\n",
            "building tree 25 of 100\n",
            "building tree 26 of 100\n",
            "building tree 27 of 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.1min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 28 of 100\n",
            "building tree 29 of 100\n",
            "building tree 30 of 100\n",
            "building tree 31 of 100\n",
            "building tree 32 of 100\n",
            "building tree 33 of 100\n",
            "building tree 34 of 100\n",
            "building tree 35 of 100\n",
            "building tree 36 of 100\n",
            "building tree 37 of 100\n",
            "building tree 38 of 100\n",
            "building tree 39 of 100\n",
            "building tree 40 of 100\n",
            "building tree 41 of 100\n",
            "building tree 42 of 100\n",
            "building tree 43 of 100\n",
            "building tree 44 of 100\n",
            "building tree 45 of 100\n",
            "building tree 46 of 100\n",
            "building tree 47 of 100\n",
            "building tree 48 of 100\n",
            "building tree 49 of 100\n",
            "building tree 50 of 100\n",
            "building tree 51 of 100\n",
            "building tree 52 of 100\n",
            "building tree 53 of 100\n",
            "building tree 54 of 100\n",
            "building tree 55 of 100\n",
            "building tree 56 of 100\n",
            "building tree 57 of 100\n",
            "building tree 58 of 100\n",
            "building tree 59 of 100\n",
            "building tree 60 of 100\n",
            "building tree 61 of 100\n",
            "building tree 62 of 100\n",
            "building tree 63 of 100\n",
            "building tree 64 of 100\n",
            "building tree 65 of 100\n",
            "building tree 66 of 100\n",
            "building tree 67 of 100\n",
            "building tree 68 of 100\n",
            "building tree 69 of 100\n",
            "building tree 70 of 100\n",
            "building tree 71 of 100\n",
            "building tree 72 of 100\n",
            "building tree 73 of 100\n",
            "building tree 74 of 100\n",
            "building tree 75 of 100\n",
            "building tree 76 of 100\n",
            "building tree 77 of 100\n",
            "building tree 78 of 100\n",
            "building tree 79 of 100\n",
            "building tree 80 of 100\n",
            "building tree 81 of 100\n",
            "building tree 82 of 100\n",
            "building tree 83 of 100\n",
            "building tree 84 of 100\n",
            "building tree 85 of 100\n",
            "building tree 86 of 100\n",
            "building tree 87 of 100\n",
            "building tree 88 of 100\n",
            "building tree 89 of 100\n",
            "building tree 90 of 100\n",
            "building tree 91 of 100\n",
            "building tree 92 of 100\n",
            "building tree 93 of 100\n",
            "building tree 94 of 100\n",
            "building tree 95 of 100\n",
            "building tree 96 of 100\n",
            "building tree 97 of 100\n",
            "building tree 98 of 100\n",
            "building tree 99 of 100\n",
            "building tree 100 of 100\n",
            "Time in seconds :  263.69940161705017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SguOxXuyU8P",
        "colab_type": "code",
        "outputId": "e0637e54-2ae0-4b86-8bda-210095cef16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.46      0.30     17217\n",
            "        Okay       0.17      0.59      0.27      8730\n",
            "        Poor       0.94      0.66      0.77    132815\n",
            "\n",
            "    accuracy                           0.63    158762\n",
            "   macro avg       0.44      0.57      0.45    158762\n",
            "weighted avg       0.82      0.63      0.69    158762\n",
            "\n",
            "[[ 7870  4867  4480]\n",
            " [ 2055  5186  1489]\n",
            " [25682 19630 87503]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYfkQu4qFePp",
        "colab_type": "text"
      },
      "source": [
        "**Prediction on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps6vVjxbN6HE",
        "colab_type": "code",
        "outputId": "3b6a5d50-3202-497f-9bec-d5706269c766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    1.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.46      0.30     19565\n",
            "        Okay       0.17      0.59      0.27      9920\n",
            "        Poor       0.94      0.66      0.77    150926\n",
            "\n",
            "    accuracy                           0.63    180411\n",
            "   macro avg       0.44      0.57      0.45    180411\n",
            "weighted avg       0.82      0.63      0.69    180411\n",
            "\n",
            "[[ 8903  5716  4946]\n",
            " [ 2378  5843  1699]\n",
            " [29157 22365 99404]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilhxeHhKJp6A",
        "colab_type": "text"
      },
      "source": [
        "-------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oOQtKF7be1v",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WglsDDyFbePl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNE4-q6RFroi",
        "colab_type": "text"
      },
      "source": [
        "Base Graient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt-ttAnSz8R7",
        "colab_type": "code",
        "outputId": "59643123-0b69-445c-8079-b7427b78d7c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = GradientBoostingClassifier( verbose = 3 ,  n_estimators=100,  random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train,y_train.values.ravel())\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1      624925.5044           11.41m\n",
            "         2      614007.1695           11.28m\n",
            "         3      605586.8818           11.16m\n",
            "         4      598897.1672           11.09m\n",
            "         5      593094.1224           11.05m\n",
            "         6      588176.3368           10.94m\n",
            "         7      584395.2487           10.82m\n",
            "         8      581284.6467           10.70m\n",
            "         9      578697.2900           10.60m\n",
            "        10      576452.1915           10.50m\n",
            "        11      574501.0041           10.41m\n",
            "        12      572259.6588           10.29m\n",
            "        13      570643.2931           10.20m\n",
            "        14      569272.5988           10.11m\n",
            "        15      567657.1522           10.04m\n",
            "        16      566542.9565            9.94m\n",
            "        17      565295.2551            9.83m\n",
            "        18      564198.4765            9.72m\n",
            "        19      563196.0635            9.62m\n",
            "        20      562231.1418            9.52m\n",
            "        21      561279.9556            9.41m\n",
            "        22      560547.2437            9.30m\n",
            "        23      559590.3480            9.19m\n",
            "        24      559010.3976            9.10m\n",
            "        25      558233.9839            8.99m\n",
            "        26      557561.0801            8.88m\n",
            "        27      557018.9955            8.77m\n",
            "        28      556425.4143            8.66m\n",
            "        29      555939.0855            8.55m\n",
            "        30      555497.0002            8.44m\n",
            "        31      555021.2855            8.32m\n",
            "        32      554595.5255            8.21m\n",
            "        33      554174.9307            8.09m\n",
            "        34      553826.2472            7.97m\n",
            "        35      553363.5337            7.85m\n",
            "        36      553024.5651            7.73m\n",
            "        37      552621.8588            7.61m\n",
            "        38      552226.4396            7.49m\n",
            "        39      551942.7224            7.37m\n",
            "        40      551529.3865            7.24m\n",
            "        41      551302.4458            7.12m\n",
            "        42      550797.7003            7.00m\n",
            "        43      550485.6907            6.88m\n",
            "        44      550174.7341            6.76m\n",
            "        45      549943.5123            6.64m\n",
            "        46      549538.3241            6.51m\n",
            "        47      549285.1190            6.39m\n",
            "        48      549084.0767            6.27m\n",
            "        49      548861.5145            6.15m\n",
            "        50      548710.9455            6.03m\n",
            "        51      548258.8496            5.91m\n",
            "        52      547949.9939            5.79m\n",
            "        53      547702.9243            5.67m\n",
            "        54      547558.1672            5.55m\n",
            "        55      547349.4254            5.43m\n",
            "        56      547090.7893            5.31m\n",
            "        57      546900.1754            5.20m\n",
            "        58      546667.6978            5.08m\n",
            "        59      546406.6955            4.96m\n",
            "        60      546235.5571            4.84m\n",
            "        61      545979.5416            4.72m\n",
            "        62      545767.1878            4.60m\n",
            "        63      545536.6117            4.48m\n",
            "        64      545412.5570            4.36m\n",
            "        65      545292.4953            4.24m\n",
            "        66      545030.4209            4.12m\n",
            "        67      544877.9049            4.00m\n",
            "        68      544692.3796            3.88m\n",
            "        69      544541.5436            3.76m\n",
            "        70      544403.6739            3.64m\n",
            "        71      544244.5700            3.52m\n",
            "        72      544108.7565            3.39m\n",
            "        73      543936.7299            3.27m\n",
            "        74      543836.2889            3.15m\n",
            "        75      543712.4829            3.03m\n",
            "        76      543503.3607            2.91m\n",
            "        77      543374.7963            2.79m\n",
            "        78      543225.0134            2.67m\n",
            "        79      543105.0916            2.54m\n",
            "        80      543001.2102            2.42m\n",
            "        81      542857.0182            2.30m\n",
            "        82      542753.3822            2.18m\n",
            "        83      542652.2829            2.06m\n",
            "        84      542561.9397            1.94m\n",
            "        85      542462.4587            1.82m\n",
            "        86      542340.3551            1.70m\n",
            "        87      541976.4023            1.58m\n",
            "        88      541828.2069            1.46m\n",
            "        89      541735.1031            1.33m\n",
            "        90      541653.5159            1.21m\n",
            "        91      541541.4992            1.09m\n",
            "        92      541451.5793           58.21s\n",
            "        93      541302.1661           50.93s\n",
            "        94      541152.5594           43.65s\n",
            "        95      541059.1003           36.37s\n",
            "        96      540992.6870           29.09s\n",
            "        97      540928.2599           21.81s\n",
            "        98      540805.4478           14.54s\n",
            "        99      540653.4940            7.27s\n",
            "       100      540556.9598            0.00s\n",
            "Time in seconds :  730.8996200561523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZFOnH_uMnZO",
        "colab_type": "code",
        "outputId": "f9ef8af5-4884-4677-bd5d-19aacc43db85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.54      0.00      0.00     17217\n",
            "        Okay       0.45      0.00      0.01      8730\n",
            "        Poor       0.84      1.00      0.91    132815\n",
            "\n",
            "    accuracy                           0.84    158762\n",
            "   macro avg       0.61      0.34      0.31    158762\n",
            "weighted avg       0.78      0.84      0.76    158762\n",
            "\n",
            "[[    29     15  17173]\n",
            " [    11     36   8683]\n",
            " [    14     29 132772]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONT29J3em5Z7",
        "colab_type": "text"
      },
      "source": [
        "Default Gradient Boost with Respampling :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1IhOjKoOawz",
        "colab_type": "code",
        "outputId": "808e545c-7ee7-477d-83cd-b8790d186cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = GradientBoostingClassifier(verbose = 3, n_estimators=100, random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1     3137286.7735           59.87m\n",
            "         2     3077546.4358           59.46m\n",
            "         3     3028395.8471           58.80m\n",
            "         4     2986789.5770           58.17m\n",
            "         5     2952110.5996           57.52m\n",
            "         6     2921196.5002           56.90m\n",
            "         7     2895316.7782           56.31m\n",
            "         8     2872975.5755           55.65m\n",
            "         9     2853569.0430           55.02m\n",
            "        10     2836338.5529           54.36m\n",
            "        11     2821368.0085           53.62m\n",
            "        12     2807184.1996           52.95m\n",
            "        13     2794684.9631           52.32m\n",
            "        14     2783862.8255           51.71m\n",
            "        15     2773101.1561           51.06m\n",
            "        16     2764551.1539           50.45m\n",
            "        17     2756590.2172           49.84m\n",
            "        18     2748439.3312           49.23m\n",
            "        19     2740899.2946           48.66m\n",
            "        20     2734314.7252           48.01m\n",
            "        21     2728663.7061           47.40m\n",
            "        22     2722152.2840           46.76m\n",
            "        23     2717854.6029           46.16m\n",
            "        24     2710487.8435           45.58m\n",
            "        25     2704939.1341           45.01m\n",
            "        26     2699242.5564           44.38m\n",
            "        27     2693877.1372           43.77m\n",
            "        28     2689917.4287           43.20m\n",
            "        29     2685556.9356           42.60m\n",
            "        30     2681803.2148           41.96m\n",
            "        31     2678649.0524           41.36m\n",
            "        32     2674543.1317           40.75m\n",
            "        33     2670040.6410           40.13m\n",
            "        34     2666394.6137           39.51m\n",
            "        35     2662036.7524           38.90m\n",
            "        36     2658969.4915           38.29m\n",
            "        37     2655195.4105           37.66m\n",
            "        38     2651672.6064           37.04m\n",
            "        39     2649207.5601           36.44m\n",
            "        40     2645021.6281           35.82m\n",
            "        41     2642212.5646           35.21m\n",
            "        42     2638647.9179           34.59m\n",
            "        43     2635089.1884           33.99m\n",
            "        44     2631769.0843           33.37m\n",
            "        45     2628159.0516           32.77m\n",
            "        46     2626068.1989           32.17m\n",
            "        47     2621971.8530           31.57m\n",
            "        48     2620497.8273           30.99m\n",
            "        49     2617829.8458           30.40m\n",
            "        50     2614599.2619           29.81m\n",
            "        51     2610859.3906           29.22m\n",
            "        52     2607644.2973           28.62m\n",
            "        53     2605346.3190           28.03m\n",
            "        54     2601095.8484           27.43m\n",
            "        55     2598909.9467           26.84m\n",
            "        56     2596114.6926           26.24m\n",
            "        57     2592560.3808           25.63m\n",
            "        58     2589913.7865           25.03m\n",
            "        59     2587040.9647           24.43m\n",
            "        60     2585076.1494           23.83m\n",
            "        61     2582991.2445           23.22m\n",
            "        62     2574580.7927           22.62m\n",
            "        63     2571705.9458           22.01m\n",
            "        64     2569175.6939           21.41m\n",
            "        65     2567078.5693           20.81m\n",
            "        66     2565156.0249           20.22m\n",
            "        67     2562247.9668           19.62m\n",
            "        68     2559214.3085           19.02m\n",
            "        69     2556886.2652           18.42m\n",
            "        70     2549478.3009           17.82m\n",
            "        71     2546024.1632           17.22m\n",
            "        72     2544142.7461           16.62m\n",
            "        73     2543002.3390           16.02m\n",
            "        74     2538584.4386           15.43m\n",
            "        75     2536769.5660           14.83m\n",
            "        76     2535163.3233           14.23m\n",
            "        77     2532762.6275           13.63m\n",
            "        78     2529405.4419           13.03m\n",
            "        79     2527371.1142           12.44m\n",
            "        80     2524309.9159           11.84m\n",
            "        81     2522736.4514           11.25m\n",
            "        82     2515463.1332           10.65m\n",
            "        83     2511874.9196           10.06m\n",
            "        84     2510039.2405            9.47m\n",
            "        85     2508236.0777            8.88m\n",
            "        86     2506701.3898            8.28m\n",
            "        87     2504571.6943            7.69m\n",
            "        88     2502398.4213            7.10m\n",
            "        89     2496961.3283            6.51m\n",
            "        90     2493391.0546            5.92m\n",
            "        91     2491341.0358            5.32m\n",
            "        92     2489767.4893            4.73m\n",
            "        93     2486666.3901            4.14m\n",
            "        94     2484039.8541            3.55m\n",
            "        95     2482534.1834            2.96m\n",
            "        96     2480763.8549            2.37m\n",
            "        97     2479017.7604            1.77m\n",
            "        98     2477824.2341            1.18m\n",
            "        99     2472132.6000           35.46s\n",
            "       100     2469072.6310            0.00s\n",
            "Time in seconds :  3551.199547767639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NICVfCBHOjEr",
        "colab_type": "code",
        "outputId": "c092b7c6-c2c2-4603-ad60-acdbe33fee49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.45      0.29     17217\n",
            "        Okay       0.16      0.58      0.25      8730\n",
            "        Poor       0.93      0.64      0.76    132815\n",
            "\n",
            "    accuracy                           0.62    158762\n",
            "   macro avg       0.44      0.56      0.43    158762\n",
            "weighted avg       0.81      0.62      0.68    158762\n",
            "\n",
            "[[ 7696  4708  4813]\n",
            " [ 2108  5049  1573]\n",
            " [25701 21609 85505]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b60SDhycVi5",
        "colab_type": "code",
        "outputId": "9e1410ba-6f8a-4363-8c77-b0bc29156f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.44      0.29     19565\n",
            "        Okay       0.16      0.57      0.25      9920\n",
            "        Poor       0.93      0.64      0.76    150926\n",
            "\n",
            "    accuracy                           0.62    180411\n",
            "   macro avg       0.44      0.55      0.43    180411\n",
            "weighted avg       0.81      0.62      0.68    180411\n",
            "\n",
            "[[ 8656  5576  5333]\n",
            " [ 2490  5642  1788]\n",
            " [28969 24614 97343]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWwznu8iGJP5",
        "colab_type": "text"
      },
      "source": [
        "Note : Resampled set did better than non-resampled set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3SXf21PkuKK",
        "colab_type": "text"
      },
      "source": [
        "Gradient Boost with Max Depth = 10, Learning Rate = 0.05 with Resampling:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq1MgwkNclaI",
        "colab_type": "code",
        "outputId": "a8c0ad0e-81d6-4aa1-cef5-2d568cc284c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = GradientBoostingClassifier( verbose = 3 ,learning_rate = 0.05,  n_estimators=100, max_depth=10, max_features='sqrt',n_iter_no_change=5, tol=80, subsample=0.8, random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1     2280282.1650        7693.5820           28.99m\n",
            "         2     2249405.8880        7667.4634           29.62m\n",
            "         3     2219902.7628        7357.2452           29.87m\n",
            "         4     2194398.7741        6340.7127           29.93m\n",
            "         5     2168318.6449        6510.2760           29.63m\n",
            "         6     2144769.1892        5845.3809           29.33m\n",
            "         7     2122037.4973        5632.1168           28.86m\n",
            "         8     2106025.3612        4036.6482           28.55m\n",
            "         9     2088044.2600        4388.8881           28.24m\n",
            "        10     2071582.4653        4152.9763           27.77m\n",
            "        11     2057102.6658        3548.9257           27.41m\n",
            "        12     2041841.6641        3733.0058           27.09m\n",
            "        13     2027475.1911        3654.5097           26.72m\n",
            "        14     2015297.5375        2980.8359           26.39m\n",
            "        15     2003422.6082        3001.5170           26.11m\n",
            "        16     1991458.0395        2920.4538           25.76m\n",
            "        17     1979952.0712        2859.5371           25.43m\n",
            "        18     1969281.9730        2672.9561           25.24m\n",
            "        19     1958431.7969        2651.8963           24.99m\n",
            "        20     1950267.6741        2061.0312           24.69m\n",
            "        21     1942769.7342        1863.5974           24.40m\n",
            "        22     1933310.3814        2309.0240           24.14m\n",
            "        23     1926005.5158        1842.5782           23.83m\n",
            "        24     1919065.2245        1663.1836           23.49m\n",
            "        25     1911990.7600        1718.5100           23.22m\n",
            "        26     1905049.2212        1707.7413           22.92m\n",
            "        27     1898567.0402        1582.5418           22.66m\n",
            "        28     1891950.5694        1661.3210           22.34m\n",
            "        29     1885191.9340        1652.7023           22.02m\n",
            "        30     1879452.1690        1411.6458           21.69m\n",
            "        31     1874587.5592        1227.3540           21.38m\n",
            "        32     1870002.9759        1079.3040           21.07m\n",
            "        33     1864719.7198        1363.1320           20.76m\n",
            "        34     1858759.2526        1378.8717           20.46m\n",
            "        35     1853764.0909        1255.1919           20.12m\n",
            "        36     1849499.7482        1063.4693           19.81m\n",
            "        37     1845367.4106        1081.1499           19.52m\n",
            "        38     1840618.3742        1076.1194           19.18m\n",
            "        39     1836971.9598         843.3622           18.82m\n",
            "        40     1833300.5085         969.5835           18.49m\n",
            "        41     1829938.1390         748.6482           18.14m\n",
            "        42     1826056.9564         996.8848           17.83m\n",
            "        43     1822933.3590         866.8814           17.51m\n",
            "        44     1818607.7984         826.6769           17.20m\n",
            "        45     1814531.3397        1139.1885           16.86m\n",
            "        46     1810969.9774         873.3188           16.52m\n",
            "        47     1808117.4471         719.5882           16.21m\n",
            "        48     1804354.2592         838.5366           15.88m\n",
            "        49     1799428.8553        1155.0485           15.58m\n",
            "        50     1796557.7839         738.0744           15.27m\n",
            "        51     1793125.8145         845.2942           14.98m\n",
            "        52     1789650.6776         722.1260           14.66m\n",
            "        53     1786981.4504         673.8993           14.34m\n",
            "        54     1783980.7148         726.7766           14.01m\n",
            "        55     1781120.2773         681.9755           13.69m\n",
            "        56     1778813.1682         734.9434           13.38m\n",
            "        57     1775219.5474         739.8324           13.07m\n",
            "        58     1770911.1296        1035.4612           12.76m\n",
            "        59     1767960.1648         665.3716           12.44m\n",
            "        60     1764711.9854         770.8874           12.14m\n",
            "        61     1762851.7382         631.9199           11.84m\n",
            "        62     1760203.3575         567.5899           11.53m\n",
            "        63     1756926.9406         608.9730           11.21m\n",
            "        64     1753889.5266         683.0719           10.92m\n",
            "        65     1751352.3325         806.1248           10.61m\n",
            "        66     1749620.4926         439.0252           10.29m\n",
            "        67     1746783.9234         488.0878            9.99m\n",
            "        68     1744351.6149         725.8711            9.68m\n",
            "        69     1741829.9203         600.1548            9.37m\n",
            "        70     1739671.1710         584.3347            9.06m\n",
            "        71     1737209.0052         473.9726            8.75m\n",
            "        72     1734011.9983         674.9601            8.44m\n",
            "        73     1732218.0149         489.0927            8.14m\n",
            "        74     1730237.8336         539.4718            7.84m\n",
            "        75     1727874.6574         459.8324            7.54m\n",
            "        76     1726063.3448         549.8614            7.24m\n",
            "        77     1724137.8884         529.3242            6.93m\n",
            "        78     1720756.1274         748.5931            6.62m\n",
            "        79     1718472.3505         569.1607            6.32m\n",
            "        80     1716049.7150         477.8568            6.03m\n",
            "        81     1713258.8145         715.2616            5.73m\n",
            "        82     1710748.9579         482.7958            5.43m\n",
            "        83     1709293.0406         489.7382            5.13m\n",
            "        84     1706367.4428         603.7782            4.83m\n",
            "        85     1703798.0701         519.2499            4.53m\n",
            "        86     1701254.7273         684.3714            4.22m\n",
            "        87     1699764.5942         502.5685            3.92m\n",
            "        88     1697001.3229         470.8759            3.62m\n",
            "        89     1694675.0424         583.1217            3.32m\n",
            "        90     1694055.0812         359.3956            3.02m\n",
            "        91     1691668.8850         501.9669            2.72m\n",
            "        92     1688100.0252         801.5069            2.42m\n",
            "        93     1686770.5349         392.6035            2.11m\n",
            "        94     1683736.3035         700.9360            1.81m\n",
            "        95     1681070.9410         552.1640            1.51m\n",
            "        96     1679528.3030         441.7862            1.21m\n",
            "        97     1676991.1868         512.0868           54.34s\n",
            "        98     1675608.6261         489.7660           36.22s\n",
            "        99     1671637.6038         666.4397           18.12s\n",
            "       100     1670069.3603         541.4040            0.00s\n",
            "Time in seconds :  1818.817574262619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Zj9_k1kIpL",
        "colab_type": "code",
        "outputId": "ae8a5e5c-13dd-4091-a6cd-05e0b585edb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.24      0.46      0.31     17217\n",
            "        Okay       0.18      0.56      0.27      8730\n",
            "        Poor       0.93      0.69      0.79    132815\n",
            "\n",
            "    accuracy                           0.66    158762\n",
            "   macro avg       0.45      0.57      0.46    158762\n",
            "weighted avg       0.81      0.66      0.71    158762\n",
            "\n",
            "[[ 7872  4270  5075]\n",
            " [ 2098  4855  1777]\n",
            " [23450 17884 91481]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLMDZ2hsx9NF",
        "colab_type": "text"
      },
      "source": [
        "Gradient Boost with Max Depth = 12, Learning Rate = 0.1 with Resampling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXFXXfLrx3_G",
        "colab_type": "code",
        "outputId": "c9cc4107-27b4-436c-d2c2-4b9837286b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "clf = GradientBoostingClassifier( verbose = 3 ,learning_rate = 0.1,  n_estimators=100, max_depth=12, max_features='sqrt', subsample=0.8,n_iter_no_change=5, tol=10000, random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1     2238687.8195       17949.9446           41.29m\n",
            "         2     2178392.6988       14908.2484           43.37m\n",
            "         3     2122772.3306       13748.0594           44.68m\n",
            "         4     2076931.5996       11285.8357           45.59m\n",
            "         5     2038992.9869        9443.0068           45.06m\n",
            "         6     2004338.5790        8526.1501           44.91m\n",
            "         7     1974514.5773        7305.3305           44.88m\n",
            "         8     1950295.2084        5999.3856           44.72m\n",
            "         9     1927686.6427        5459.3719           44.40m\n",
            "        10     1907947.6653        4916.4758           43.99m\n",
            "        11     1888941.1895        4511.8652           43.46m\n",
            "        12     1868905.9785        4779.3364           43.21m\n",
            "        13     1853450.8895        3922.1110           42.83m\n",
            "        14     1839848.5538        3235.3558           42.43m\n",
            "        15     1825155.3696        3592.5602           42.04m\n",
            "        16     1813195.0365        2826.8613           41.59m\n",
            "        17     1802549.0836        2562.8335           41.03m\n",
            "Time in seconds :  510.68720626831055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsJRiTVxyBWf",
        "colab_type": "code",
        "outputId": "b3a45148-642a-4e93-b249-4dc74e2f33f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.46      0.30     17217\n",
            "        Okay       0.17      0.59      0.27      8730\n",
            "        Poor       0.94      0.66      0.77    132815\n",
            "\n",
            "    accuracy                           0.63    158762\n",
            "   macro avg       0.44      0.57      0.45    158762\n",
            "weighted avg       0.82      0.63      0.69    158762\n",
            "\n",
            "[[ 7983  4772  4462]\n",
            " [ 2072  5165  1493]\n",
            " [25521 20146 87148]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3r7qShskmxy",
        "colab_type": "text"
      },
      "source": [
        "Gradient Boost with Max Depth = 15, Learning Rate = 0.05 with Resampling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-ebGIojkOX7",
        "colab_type": "code",
        "outputId": "f9760967-a815-48f0-f474-619fd895f905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "clf = GradientBoostingClassifier( verbose = 3 ,learning_rate = 0.05,  n_estimators=100, max_depth=15, max_features='sqrt', subsample=0.8,n_iter_no_change=5, tol=10000, random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1     2269230.9284       10264.0122           75.57m\n",
            "         2     2228026.6646       10101.5885           93.06m\n",
            "         3     2189447.1710        9432.2649          101.16m\n",
            "         4     2155877.0819        8214.7129          102.77m\n",
            "         5     2123772.0610        7838.1687          101.93m\n",
            "         6     2092924.7387        7532.5909          103.09m\n",
            "         7     2064029.9055        7032.7827          102.85m\n",
            "         8     2041344.9180        5564.7476          101.15m\n",
            "         9     2018116.1587        5584.8410          100.21m\n",
            "        10     1994663.4192        5726.5608           99.91m\n",
            "        11     1973208.7749        5127.9105           98.57m\n",
            "        12     1954734.5278        4395.2367           97.24m\n",
            "        13     1934940.1800        4887.8650           97.11m\n",
            "        14     1918162.2110        3993.4596           95.87m\n",
            "        15     1901823.1695        3931.2787           95.04m\n",
            "        16     1886387.2600        3637.0230           93.65m\n",
            "        17     1872167.5638        3441.7364           92.36m\n",
            "        18     1858026.4839        3397.8783           91.37m\n",
            "        19     1843497.6237        3382.7632           90.30m\n",
            "Time in seconds :  1277.6497151851654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWNsUd3RkIGg",
        "colab_type": "code",
        "outputId": "5e0a9998-ab56-4e6c-9e5d-d7bdf7e9a601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.23      0.47      0.31     17217\n",
            "        Okay       0.18      0.58      0.27      8730\n",
            "        Poor       0.93      0.67      0.78    132815\n",
            "\n",
            "    accuracy                           0.64    158762\n",
            "   macro avg       0.45      0.57      0.45    158762\n",
            "weighted avg       0.82      0.64      0.70    158762\n",
            "\n",
            "[[ 8029  4560  4628]\n",
            " [ 2074  5059  1597]\n",
            " [24871 18764 89180]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r5cnhJZrgqk",
        "colab_type": "text"
      },
      "source": [
        "Gradient Boost with Max Depth = 15, Learning Rate = 0.1 with Resampling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jktvojHerM7J",
        "colab_type": "code",
        "outputId": "a1c22761-0fde-4690-e84c-503c664ee438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "clf = GradientBoostingClassifier( verbose = 3 ,learning_rate = 0.1,  n_estimators=100, max_depth=15, max_features='sqrt', subsample=0.8,n_iter_no_change=5, tol=10000, random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1     2229229.6033       20028.0040           72.88m\n",
            "         2     2156501.8057       17772.1193           89.63m\n",
            "         3     2092285.5646       15626.7394          100.09m\n",
            "         4     2039157.4550       12905.3994          102.84m\n",
            "         5     1992986.0183       11186.8274          102.32m\n",
            "         6     1949913.9806       10411.5568          102.77m\n",
            "         7     1913241.9969        8773.3780          102.60m\n",
            "         8     1883754.0229        7165.0544          101.07m\n",
            "         9     1854957.9870        6789.7723          100.34m\n",
            "        10     1827919.7937        6464.4315          100.11m\n",
            "        11     1804289.4358        5431.3689           99.24m\n",
            "        12     1782971.0418        4980.0940           97.98m\n",
            "        13     1761782.9788        5124.5454           97.53m\n",
            "        14     1743723.3029        4163.8290           96.09m\n",
            "        15     1727410.9167        3757.2450           95.23m\n",
            "        16     1711791.6550        3613.2631           93.51m\n",
            "        17     1694322.1553        4050.1902           92.53m\n",
            "        18     1680243.2941        3208.8453           91.52m\n",
            "        19     1665729.1245        3233.3358           90.53m\n",
            "        20     1653067.0002        2933.8853           89.43m\n",
            "Time in seconds :  1347.8092234134674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnQt-0pfkzej",
        "colab_type": "code",
        "outputId": "961148d0-a251-49bc-d21a-a1049fc5f9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.24      0.46      0.32     17217\n",
            "        Okay       0.18      0.55      0.28      8730\n",
            "        Poor       0.93      0.70      0.80    132815\n",
            "\n",
            "    accuracy                           0.66    158762\n",
            "   macro avg       0.45      0.57      0.46    158762\n",
            "weighted avg       0.82      0.66      0.72    158762\n",
            "\n",
            "[[ 7916  4292  5009]\n",
            " [ 2108  4836  1786]\n",
            " [22963 17253 92599]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMOdZvWNxiQH",
        "colab_type": "text"
      },
      "source": [
        "With the test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcKdpz-rrxID",
        "colab_type": "code",
        "outputId": "d74f89c0-d431-441e-cfe4-94efe267bbf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.24      0.46      0.32     19565\n",
            "        Okay       0.18      0.54      0.27      9920\n",
            "        Poor       0.93      0.70      0.80    150926\n",
            "\n",
            "    accuracy                           0.66    180411\n",
            "   macro avg       0.45      0.57      0.46    180411\n",
            "weighted avg       0.82      0.66      0.72    180411\n",
            "\n",
            "[[  8991   5080   5494]\n",
            " [  2392   5404   2124]\n",
            " [ 25940  19653 105333]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpqmJKio0sKY",
        "colab_type": "text"
      },
      "source": [
        " Gradient Boost with Max Depth = 15, Learning Rate = 0.1 with Resampling and Reducing tol to 7000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw6nfRhZxp9S",
        "colab_type": "code",
        "outputId": "777eeb2f-3463-4c9b-af5a-b51eee9cf4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "clf = GradientBoostingClassifier( verbose = 3 ,learning_rate = 0.1,  n_estimators=100, max_depth=15, max_features='sqrt', subsample=0.8,n_iter_no_change=5, tol=7000, random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1     2229229.6033       20028.0040           74.71m\n",
            "         2     2156501.8057       17772.1193           92.38m\n",
            "         3     2092285.5646       15626.7394          102.73m\n",
            "         4     2039157.4550       12905.3994          104.72m\n",
            "         5     1992986.0183       11186.8274          105.23m\n",
            "         6     1949913.9806       10411.5568          106.32m\n",
            "         7     1913241.9969        8773.3780          105.96m\n",
            "         8     1883754.0229        7165.0544          104.53m\n",
            "         9     1854957.9870        6789.7723          103.92m\n",
            "        10     1827919.7937        6464.4315          103.81m\n",
            "        11     1804289.4358        5431.3689          103.12m\n",
            "        12     1782971.0418        4980.0940          102.01m\n",
            "        13     1761782.9788        5124.5454          101.92m\n",
            "        14     1743723.3029        4163.8290          100.57m\n",
            "        15     1727410.9167        3757.2450          100.29m\n",
            "        16     1711791.6550        3613.2631           98.68m\n",
            "        17     1694322.1553        4050.1902           97.84m\n",
            "        18     1680243.2941        3208.8453           96.96m\n",
            "        19     1665729.1245        3233.3358           95.84m\n",
            "        20     1653067.0002        2933.8853           94.65m\n",
            "        21     1641993.8888        2519.0296           93.11m\n",
            "        22     1630331.3396        2562.9191           92.05m\n",
            "        23     1620850.3339        2102.5391           90.69m\n",
            "        24     1610610.3222        2268.1349           89.20m\n",
            "Time in seconds :  1696.8934836387634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dMf02Ntrw92",
        "colab_type": "code",
        "outputId": "d3f4ee28-2c69-457d-c568-76f86d260c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.24      0.46      0.32     17217\n",
            "        Okay       0.18      0.54      0.27      8730\n",
            "        Poor       0.93      0.70      0.80    132815\n",
            "\n",
            "    accuracy                           0.67    158762\n",
            "   macro avg       0.45      0.57      0.46    158762\n",
            "weighted avg       0.81      0.67      0.72    158762\n",
            "\n",
            "[[ 7916  4178  5123]\n",
            " [ 2140  4715  1875]\n",
            " [22682 16722 93411]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-RA1Y2OAQ2J",
        "colab_type": "text"
      },
      "source": [
        "Gradient Boost with Max Depth = 15, Learning Rate = 0.1 with Resampling and Reducing tol to 5000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my1VzjreAHgz",
        "colab_type": "code",
        "outputId": "1b7c195c-11c1-451a-fc33-fbed035fb183",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "clf = GradientBoostingClassifier( verbose = 3 ,learning_rate = 0.1,  n_estimators=100, max_depth=15, max_features='sqrt', subsample=0.8,n_iter_no_change=5, tol=5000, random_state=10 )\n",
        "start = time.time()\n",
        "clf = clf.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1     2229229.6033       20028.0040           74.18m\n",
            "         2     2156501.8057       17772.1193           89.91m\n",
            "         3     2092285.5646       15626.7394           99.69m\n",
            "         4     2039157.4550       12905.3994          101.35m\n",
            "         5     1992986.0183       11186.8274          100.66m\n",
            "         6     1949913.9806       10411.5568          101.09m\n",
            "         7     1913241.9969        8773.3780          100.60m\n",
            "         8     1883754.0229        7165.0544           98.94m\n",
            "         9     1854957.9870        6789.7723           97.88m\n",
            "        10     1827919.7937        6464.4315           97.37m\n",
            "        11     1804289.4358        5431.3689           96.25m\n",
            "        12     1782971.0418        4980.0940           94.92m\n",
            "        13     1761782.9788        5124.5454           94.33m\n",
            "        14     1743723.3029        4163.8290           92.80m\n",
            "        15     1727410.9167        3757.2450           91.86m\n",
            "        16     1711791.6550        3613.2631           90.04m\n",
            "        17     1694322.1553        4050.1902           89.05m\n",
            "        18     1680243.2941        3208.8453           87.95m\n",
            "        19     1665729.1245        3233.3358           86.94m\n",
            "        20     1653067.0002        2933.8853           85.86m\n",
            "        21     1641993.8888        2519.0296           84.47m\n",
            "        22     1630331.3396        2562.9191           83.57m\n",
            "        23     1620850.3339        2102.5391           82.27m\n",
            "        24     1610610.3222        2268.1349           80.84m\n",
            "        25     1598262.8609        2673.4759           79.83m\n",
            "        26     1589166.5194        2086.5109           78.45m\n",
            "        27     1579813.0844        1960.0730           77.35m\n",
            "        28     1568301.4178        2594.2078           76.59m\n",
            "        29     1559636.3984        1961.5503           75.32m\n",
            "        30     1549662.0996        2145.9174           74.20m\n",
            "        31     1541436.4150        1846.8364           73.05m\n",
            "        32     1533959.7479        1617.6583           71.76m\n",
            "        33     1525045.3477        2010.3202           70.50m\n",
            "        34     1517010.7864        1605.9622           69.38m\n",
            "        35     1507229.9393        2244.6379           68.16m\n",
            "        36     1499572.4401        1649.0669           67.00m\n",
            "        37     1492065.4312        1725.9984           65.74m\n",
            "        38     1480670.7070        2368.4470           64.82m\n",
            "        39     1472924.8412        1645.3546           63.63m\n",
            "        40     1465206.3052        1728.5872           62.41m\n",
            "        41     1457751.5015        1592.6485           61.44m\n",
            "        42     1451195.9683        1383.1122           60.29m\n",
            "Time in seconds :  2626.1716685295105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amm_VDOu1rcw",
        "colab_type": "code",
        "outputId": "499f842f-ef19-400c-b74a-52ac0e29bd8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.26      0.45      0.33     17217\n",
            "        Okay       0.19      0.49      0.28      8730\n",
            "        Poor       0.92      0.74      0.82    132815\n",
            "\n",
            "    accuracy                           0.70    158762\n",
            "   macro avg       0.46      0.56      0.48    158762\n",
            "weighted avg       0.81      0.70      0.74    158762\n",
            "\n",
            "[[ 7740  3605  5872]\n",
            " [ 2140  4247  2343]\n",
            " [20088 13952 98775]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SpJtQMu_S55",
        "colab_type": "code",
        "outputId": "989c1b0b-4ef0-4743-dfa2-ae4cfecab90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.26      0.45      0.33     19565\n",
            "        Okay       0.19      0.47      0.27      9920\n",
            "        Poor       0.92      0.75      0.83    150926\n",
            "\n",
            "    accuracy                           0.70    180411\n",
            "   macro avg       0.46      0.56      0.48    180411\n",
            "weighted avg       0.81      0.70      0.74    180411\n",
            "\n",
            "[[  8803   4276   6486]\n",
            " [  2449   4685   2786]\n",
            " [ 22695  15615 112616]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYo19b88_RfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYn_Pr_rAGz4",
        "colab_type": "code",
        "outputId": "233335ac-8a70-4db5-aacc-4e011a484dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.26      0.45      0.33     17217\n",
            "        Okay       0.19      0.49      0.28      8730\n",
            "        Poor       0.92      0.74      0.82    132815\n",
            "\n",
            "    accuracy                           0.70    158762\n",
            "   macro avg       0.46      0.56      0.48    158762\n",
            "weighted avg       0.81      0.70      0.74    158762\n",
            "\n",
            "[[ 7740  3605  5872]\n",
            " [ 2140  4247  2343]\n",
            " [20088 13952 98775]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYcx_uIgL5Ip",
        "colab_type": "text"
      },
      "source": [
        "Reducing tol to 3000  and no of iterations to 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3cQkf4lD_fX",
        "colab_type": "code",
        "outputId": "7cc0cf55-7db8-44a2-83a5-a59801401f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "clf2 = GradientBoostingClassifier( verbose = 3 ,learning_rate = 0.1,  n_estimators=100, max_depth=15, max_features='sqrt', subsample=0.8,n_iter_no_change=3, tol=3000, random_state=10 )\n",
        "start = time.time()\n",
        "clf2 = clf2.fit(X_train_smote,y_train_smote)\n",
        "end = time.time()\n",
        "print(\"Time in seconds : \", end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1     2229229.6033       20028.0040           65.06m\n",
            "         2     2156501.8057       17772.1193           80.53m\n",
            "         3     2092285.5646       15626.7394           89.72m\n",
            "         4     2039157.4550       12905.3994           91.37m\n",
            "         5     1992986.0183       11186.8274           90.68m\n",
            "         6     1949913.9806       10411.5568           91.16m\n",
            "         7     1913241.9969        8773.3780           91.15m\n",
            "         8     1883754.0229        7165.0544           90.09m\n",
            "         9     1854957.9870        6789.7723           89.59m\n",
            "        10     1827919.7937        6464.4315           89.52m\n",
            "        11     1804289.4358        5431.3689           88.98m\n",
            "        12     1782971.0418        4980.0940           88.00m\n",
            "        13     1761782.9788        5124.5454           87.80m\n",
            "        14     1743723.3029        4163.8290           87.04m\n",
            "        15     1727410.9167        3757.2450           86.81m\n",
            "        16     1711791.6550        3613.2631           85.64m\n",
            "        17     1694322.1553        4050.1902           84.97m\n",
            "        18     1680243.2941        3208.8453           84.19m\n",
            "        19     1665729.1245        3233.3358           83.41m\n",
            "        20     1653067.0002        2933.8853           82.68m\n",
            "        21     1641993.8888        2519.0296           81.45m\n",
            "        22     1630331.3396        2562.9191           80.94m\n",
            "        23     1620850.3339        2102.5391           79.73m\n",
            "        24     1610610.3222        2268.1349           78.41m\n",
            "        25     1598262.8609        2673.4759           77.46m\n",
            "        26     1589166.5194        2086.5109           76.10m\n",
            "        27     1579813.0844        1960.0730           75.21m\n",
            "        28     1568301.4178        2594.2078           74.25m\n",
            "        29     1559636.3984        1961.5503           73.05m\n",
            "        30     1549662.0996        2145.9174           72.01m\n",
            "        31     1541436.4150        1846.8364           70.97m\n",
            "        32     1533959.7479        1617.6583           69.82m\n",
            "        33     1525045.3477        2010.3202           68.61m\n",
            "        34     1517010.7864        1605.9622           67.52m\n",
            "Time in seconds :  2093.1477444171906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izetadGIHlF-",
        "colab_type": "code",
        "outputId": "da780599-5212-4099-e455-1738fc8027d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf2.predict(X_valid)\n",
        "print(classification_report(y_valid,predictions))\n",
        "print(confusion_matrix(y_valid,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.26      0.45      0.33     17217\n",
            "        Okay       0.19      0.49      0.28      8730\n",
            "        Poor       0.92      0.74      0.82    132815\n",
            "\n",
            "    accuracy                           0.70    158762\n",
            "   macro avg       0.46      0.56      0.48    158762\n",
            "weighted avg       0.81      0.70      0.74    158762\n",
            "\n",
            "[[ 7740  3605  5872]\n",
            " [ 2140  4247  2343]\n",
            " [20088 13952 98775]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX900SlhIVqu",
        "colab_type": "code",
        "outputId": "8a702c9f-5510-4e6f-8700-a42ae4efb2f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf2.predict(X_train)\n",
        "print(classification_report(y_train,predictions))\n",
        "print(confusion_matrix(y_train,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.29      0.51      0.37    126262\n",
            "        Okay       0.23      0.57      0.33     64016\n",
            "        Poor       0.93      0.75      0.83    973973\n",
            "\n",
            "    accuracy                           0.72   1164251\n",
            "   macro avg       0.49      0.61      0.51   1164251\n",
            "weighted avg       0.82      0.72      0.76   1164251\n",
            "\n",
            "[[ 64421  23526  38315]\n",
            " [ 13261  36339  14416]\n",
            " [142036  97967 733970]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap6dvMr5HueL",
        "colab_type": "text"
      },
      "source": [
        "Previous model did better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzNv1QrwIL1C",
        "colab_type": "text"
      },
      "source": [
        "Best Model was Gradient Boost with Max Depth = 15, Learning Rate = 0.1 with Resampling and Reducing tol to 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jzeML9BH2Pi",
        "colab_type": "text"
      },
      "source": [
        "**Predictions on testset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpYXK9tAHkwR",
        "colab_type": "code",
        "outputId": "c0b71684-452f-48c0-d365-289b7b855eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.26      0.45      0.33     19565\n",
            "        Okay       0.19      0.47      0.27      9920\n",
            "        Poor       0.92      0.75      0.83    150926\n",
            "\n",
            "    accuracy                           0.70    180411\n",
            "   macro avg       0.46      0.56      0.48    180411\n",
            "weighted avg       0.81      0.70      0.74    180411\n",
            "\n",
            "[[  8803   4276   6486]\n",
            " [  2449   4685   2786]\n",
            " [ 22695  15615 112616]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_-afo8FIAJX",
        "colab_type": "text"
      },
      "source": [
        "----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yna_zoAlI6LJ",
        "colab_type": "text"
      },
      "source": [
        "### Cat Boost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69IlAGXLRkak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.12, random_state = 0, stratify=y)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.12, random_state = 0, stratify=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0eKaGfdk9Z8",
        "colab_type": "code",
        "outputId": "3cab785d-3dac-468f-adf6-f85a151341be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "sc = StandardScaler()\n",
        "X_train.loc[:,[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]] = sc.fit_transform(X_train[[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]])\n",
        "X_test.loc[:,[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]] = sc.transform(X_test[[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]])\n",
        "X_valid.loc[:,[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]] = sc.transform(X_valid[[\"price\",\"description_len\",\"title_len\",\"param_combined_len\",\"image_top_1\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM-ssqqsH_tc",
        "colab_type": "code",
        "outputId": "cce170c4-df12-4c29-9c94-609d262a5c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooP4s_gtMh-v",
        "colab_type": "code",
        "outputId": "3aefddac-311e-4a5a-c6c7-65bf3dab9cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "pip install ipywidgets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (3.5.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.7.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (42.0.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (4.5.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets) (1.12.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.6.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (17.0.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.10.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjnR9i6KMbd8",
        "colab_type": "code",
        "outputId": "646eab32-cedb-46b6-8fa1-14cde06fabd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "pip install catboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/586923de4634f88a31fd1b4966e15707a912b98b6f4566651b5ef58f36b5/catboost-0.20.2-cp36-none-manylinux1_x86_64.whl (63.9MB)\n",
            "\u001b[K     |████████████████████████████████| 63.9MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (42.0.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.20.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPIvr7puLzef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from  sklearn.utils.class_weight import compute_class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjRJucWRLy3N",
        "colab_type": "code",
        "outputId": "91c57341-6a54-400c-98e4-02291e315ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "arr_y = np.unique(y.values.ravel())\n",
        "sample_weights_data = compute_class_weight(class_weight = \"balanced\", classes = arr_y, y = y.values.ravel())\n",
        "sample_weights_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.07365701, 6.06224244, 0.39845413])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5w3I4txQquL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cate_features_index = np.array([0,1,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOkYdm-aRK01",
        "colab_type": "code",
        "outputId": "bf4c59bd-873f-4799-8b90-6fb838654ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cate_features_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vThM7iDVJeVe",
        "colab_type": "text"
      },
      "source": [
        "Using MultiClass Loss function for the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynxIRCwFJ6_7",
        "colab_type": "text"
      },
      "source": [
        "Using all edfault parameters including default 1000 trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebtcqu03lHIz",
        "colab_type": "code",
        "outputId": "767a13fb-f962-498b-939f-e09389e6787c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = CatBoostClassifier(random_seed=42,loss_function='MultiClass', class_weights=sample_weights_data)\n",
        "clf.fit(X_train, y_train, cat_features=cate_features_index )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 1.0904747\ttotal: 1.52s\tremaining: 25m 15s\n",
            "1:\tlearn: 1.0828443\ttotal: 2.9s\tremaining: 24m 6s\n",
            "2:\tlearn: 1.0757271\ttotal: 4.28s\tremaining: 23m 41s\n",
            "3:\tlearn: 1.0689030\ttotal: 5.54s\tremaining: 22m 58s\n",
            "4:\tlearn: 1.0624592\ttotal: 6.67s\tremaining: 22m 6s\n",
            "5:\tlearn: 1.0564419\ttotal: 7.92s\tremaining: 21m 52s\n",
            "6:\tlearn: 1.0508201\ttotal: 9.21s\tremaining: 21m 46s\n",
            "7:\tlearn: 1.0454109\ttotal: 10.3s\tremaining: 21m 21s\n",
            "8:\tlearn: 1.0402768\ttotal: 11.4s\tremaining: 20m 56s\n",
            "9:\tlearn: 1.0354693\ttotal: 12.5s\tremaining: 20m 41s\n",
            "10:\tlearn: 1.0309135\ttotal: 13.7s\tremaining: 20m 30s\n",
            "11:\tlearn: 1.0266235\ttotal: 14.8s\tremaining: 20m 18s\n",
            "12:\tlearn: 1.0225063\ttotal: 16s\tremaining: 20m 17s\n",
            "13:\tlearn: 1.0186259\ttotal: 17.4s\tremaining: 20m 22s\n",
            "14:\tlearn: 1.0148554\ttotal: 18.4s\tremaining: 20m 10s\n",
            "15:\tlearn: 1.0113419\ttotal: 19.7s\tremaining: 20m 11s\n",
            "16:\tlearn: 1.0080443\ttotal: 20.8s\tremaining: 20m 2s\n",
            "17:\tlearn: 1.0047871\ttotal: 22s\tremaining: 20m\n",
            "18:\tlearn: 1.0017339\ttotal: 23.2s\tremaining: 19m 59s\n",
            "19:\tlearn: 0.9988590\ttotal: 24.5s\tremaining: 19m 59s\n",
            "20:\tlearn: 0.9960552\ttotal: 25.7s\tremaining: 19m 57s\n",
            "21:\tlearn: 0.9934523\ttotal: 26.8s\tremaining: 19m 53s\n",
            "22:\tlearn: 0.9909733\ttotal: 28.1s\tremaining: 19m 52s\n",
            "23:\tlearn: 0.9884865\ttotal: 29.3s\tremaining: 19m 53s\n",
            "24:\tlearn: 0.9862212\ttotal: 30.6s\tremaining: 19m 54s\n",
            "25:\tlearn: 0.9840437\ttotal: 32s\tremaining: 19m 57s\n",
            "26:\tlearn: 0.9821002\ttotal: 33.1s\tremaining: 19m 52s\n",
            "27:\tlearn: 0.9800605\ttotal: 34.6s\tremaining: 19m 59s\n",
            "28:\tlearn: 0.9781138\ttotal: 35.7s\tremaining: 19m 55s\n",
            "29:\tlearn: 0.9762768\ttotal: 37s\tremaining: 19m 56s\n",
            "30:\tlearn: 0.9745996\ttotal: 38.3s\tremaining: 19m 58s\n",
            "31:\tlearn: 0.9727753\ttotal: 39.5s\tremaining: 19m 56s\n",
            "32:\tlearn: 0.9711855\ttotal: 40.9s\tremaining: 19m 58s\n",
            "33:\tlearn: 0.9696799\ttotal: 42.1s\tremaining: 19m 55s\n",
            "34:\tlearn: 0.9681004\ttotal: 43.2s\tremaining: 19m 52s\n",
            "35:\tlearn: 0.9666981\ttotal: 44.4s\tremaining: 19m 49s\n",
            "36:\tlearn: 0.9653773\ttotal: 45.4s\tremaining: 19m 41s\n",
            "37:\tlearn: 0.9640916\ttotal: 46.9s\tremaining: 19m 46s\n",
            "38:\tlearn: 0.9627271\ttotal: 48s\tremaining: 19m 42s\n",
            "39:\tlearn: 0.9614659\ttotal: 49.3s\tremaining: 19m 44s\n",
            "40:\tlearn: 0.9604309\ttotal: 50.6s\tremaining: 19m 43s\n",
            "41:\tlearn: 0.9593992\ttotal: 51.9s\tremaining: 19m 44s\n",
            "42:\tlearn: 0.9583531\ttotal: 53.1s\tremaining: 19m 42s\n",
            "43:\tlearn: 0.9573578\ttotal: 54.3s\tremaining: 19m 38s\n",
            "44:\tlearn: 0.9562898\ttotal: 55.5s\tremaining: 19m 38s\n",
            "45:\tlearn: 0.9553970\ttotal: 56.8s\tremaining: 19m 38s\n",
            "46:\tlearn: 0.9545823\ttotal: 58.1s\tremaining: 19m 38s\n",
            "47:\tlearn: 0.9535998\ttotal: 59.3s\tremaining: 19m 36s\n",
            "48:\tlearn: 0.9527024\ttotal: 1m\tremaining: 19m 36s\n",
            "49:\tlearn: 0.9518833\ttotal: 1m 1s\tremaining: 19m 36s\n",
            "50:\tlearn: 0.9510505\ttotal: 1m 3s\tremaining: 19m 40s\n",
            "51:\tlearn: 0.9503374\ttotal: 1m 4s\tremaining: 19m 37s\n",
            "52:\tlearn: 0.9495996\ttotal: 1m 5s\tremaining: 19m 36s\n",
            "53:\tlearn: 0.9489652\ttotal: 1m 7s\tremaining: 19m 37s\n",
            "54:\tlearn: 0.9482101\ttotal: 1m 8s\tremaining: 19m 37s\n",
            "55:\tlearn: 0.9475325\ttotal: 1m 9s\tremaining: 19m 35s\n",
            "56:\tlearn: 0.9468873\ttotal: 1m 10s\tremaining: 19m 33s\n",
            "57:\tlearn: 0.9462129\ttotal: 1m 12s\tremaining: 19m 30s\n",
            "58:\tlearn: 0.9454892\ttotal: 1m 13s\tremaining: 19m 31s\n",
            "59:\tlearn: 0.9448693\ttotal: 1m 14s\tremaining: 19m 31s\n",
            "60:\tlearn: 0.9442090\ttotal: 1m 15s\tremaining: 19m 29s\n",
            "61:\tlearn: 0.9437341\ttotal: 1m 17s\tremaining: 19m 28s\n",
            "62:\tlearn: 0.9432113\ttotal: 1m 18s\tremaining: 19m 27s\n",
            "63:\tlearn: 0.9426443\ttotal: 1m 19s\tremaining: 19m 27s\n",
            "64:\tlearn: 0.9420567\ttotal: 1m 21s\tremaining: 19m 27s\n",
            "65:\tlearn: 0.9415502\ttotal: 1m 22s\tremaining: 19m 28s\n",
            "66:\tlearn: 0.9410559\ttotal: 1m 23s\tremaining: 19m 26s\n",
            "67:\tlearn: 0.9405428\ttotal: 1m 25s\tremaining: 19m 26s\n",
            "68:\tlearn: 0.9400528\ttotal: 1m 26s\tremaining: 19m 26s\n",
            "69:\tlearn: 0.9396315\ttotal: 1m 27s\tremaining: 19m 26s\n",
            "70:\tlearn: 0.9391377\ttotal: 1m 29s\tremaining: 19m 27s\n",
            "71:\tlearn: 0.9387152\ttotal: 1m 30s\tremaining: 19m 27s\n",
            "72:\tlearn: 0.9382821\ttotal: 1m 31s\tremaining: 19m 27s\n",
            "73:\tlearn: 0.9378601\ttotal: 1m 33s\tremaining: 19m 27s\n",
            "74:\tlearn: 0.9374986\ttotal: 1m 34s\tremaining: 19m 29s\n",
            "75:\tlearn: 0.9371317\ttotal: 1m 36s\tremaining: 19m 30s\n",
            "76:\tlearn: 0.9367520\ttotal: 1m 37s\tremaining: 19m 31s\n",
            "77:\tlearn: 0.9364154\ttotal: 1m 39s\tremaining: 19m 32s\n",
            "78:\tlearn: 0.9360502\ttotal: 1m 40s\tremaining: 19m 34s\n",
            "79:\tlearn: 0.9356816\ttotal: 1m 42s\tremaining: 19m 33s\n",
            "80:\tlearn: 0.9353773\ttotal: 1m 43s\tremaining: 19m 34s\n",
            "81:\tlearn: 0.9350579\ttotal: 1m 45s\tremaining: 19m 35s\n",
            "82:\tlearn: 0.9347533\ttotal: 1m 46s\tremaining: 19m 37s\n",
            "83:\tlearn: 0.9344643\ttotal: 1m 47s\tremaining: 19m 36s\n",
            "84:\tlearn: 0.9341555\ttotal: 1m 49s\tremaining: 19m 37s\n",
            "85:\tlearn: 0.9339032\ttotal: 1m 50s\tremaining: 19m 38s\n",
            "86:\tlearn: 0.9336062\ttotal: 1m 52s\tremaining: 19m 38s\n",
            "87:\tlearn: 0.9333545\ttotal: 1m 53s\tremaining: 19m 37s\n",
            "88:\tlearn: 0.9330953\ttotal: 1m 54s\tremaining: 19m 36s\n",
            "89:\tlearn: 0.9327604\ttotal: 1m 56s\tremaining: 19m 35s\n",
            "90:\tlearn: 0.9324580\ttotal: 1m 57s\tremaining: 19m 36s\n",
            "91:\tlearn: 0.9322061\ttotal: 1m 59s\tremaining: 19m 37s\n",
            "92:\tlearn: 0.9319967\ttotal: 2m\tremaining: 19m 37s\n",
            "93:\tlearn: 0.9317686\ttotal: 2m 2s\tremaining: 19m 38s\n",
            "94:\tlearn: 0.9315141\ttotal: 2m 3s\tremaining: 19m 39s\n",
            "95:\tlearn: 0.9312813\ttotal: 2m 5s\tremaining: 19m 41s\n",
            "96:\tlearn: 0.9310917\ttotal: 2m 6s\tremaining: 19m 41s\n",
            "97:\tlearn: 0.9308895\ttotal: 2m 8s\tremaining: 19m 41s\n",
            "98:\tlearn: 0.9307005\ttotal: 2m 9s\tremaining: 19m 41s\n",
            "99:\tlearn: 0.9304908\ttotal: 2m 11s\tremaining: 19m 41s\n",
            "100:\tlearn: 0.9302914\ttotal: 2m 12s\tremaining: 19m 40s\n",
            "101:\tlearn: 0.9300443\ttotal: 2m 14s\tremaining: 19m 41s\n",
            "102:\tlearn: 0.9298585\ttotal: 2m 15s\tremaining: 19m 41s\n",
            "103:\tlearn: 0.9296487\ttotal: 2m 17s\tremaining: 19m 40s\n",
            "104:\tlearn: 0.9294388\ttotal: 2m 18s\tremaining: 19m 41s\n",
            "105:\tlearn: 0.9292591\ttotal: 2m 19s\tremaining: 19m 40s\n",
            "106:\tlearn: 0.9289865\ttotal: 2m 21s\tremaining: 19m 40s\n",
            "107:\tlearn: 0.9287546\ttotal: 2m 22s\tremaining: 19m 40s\n",
            "108:\tlearn: 0.9285245\ttotal: 2m 24s\tremaining: 19m 39s\n",
            "109:\tlearn: 0.9283603\ttotal: 2m 25s\tremaining: 19m 39s\n",
            "110:\tlearn: 0.9282198\ttotal: 2m 27s\tremaining: 19m 40s\n",
            "111:\tlearn: 0.9280286\ttotal: 2m 28s\tremaining: 19m 40s\n",
            "112:\tlearn: 0.9278778\ttotal: 2m 30s\tremaining: 19m 39s\n",
            "113:\tlearn: 0.9277031\ttotal: 2m 31s\tremaining: 19m 38s\n",
            "114:\tlearn: 0.9275579\ttotal: 2m 33s\tremaining: 19m 39s\n",
            "115:\tlearn: 0.9273343\ttotal: 2m 34s\tremaining: 19m 39s\n",
            "116:\tlearn: 0.9271768\ttotal: 2m 36s\tremaining: 19m 39s\n",
            "117:\tlearn: 0.9270096\ttotal: 2m 37s\tremaining: 19m 37s\n",
            "118:\tlearn: 0.9267775\ttotal: 2m 39s\tremaining: 19m 38s\n",
            "119:\tlearn: 0.9265254\ttotal: 2m 40s\tremaining: 19m 38s\n",
            "120:\tlearn: 0.9263432\ttotal: 2m 42s\tremaining: 19m 39s\n",
            "121:\tlearn: 0.9262073\ttotal: 2m 43s\tremaining: 19m 38s\n",
            "122:\tlearn: 0.9260796\ttotal: 2m 45s\tremaining: 19m 36s\n",
            "123:\tlearn: 0.9258801\ttotal: 2m 46s\tremaining: 19m 36s\n",
            "124:\tlearn: 0.9256412\ttotal: 2m 48s\tremaining: 19m 37s\n",
            "125:\tlearn: 0.9254371\ttotal: 2m 49s\tremaining: 19m 36s\n",
            "126:\tlearn: 0.9252439\ttotal: 2m 51s\tremaining: 19m 35s\n",
            "127:\tlearn: 0.9251027\ttotal: 2m 52s\tremaining: 19m 35s\n",
            "128:\tlearn: 0.9249552\ttotal: 2m 54s\tremaining: 19m 35s\n",
            "129:\tlearn: 0.9247077\ttotal: 2m 55s\tremaining: 19m 35s\n",
            "130:\tlearn: 0.9245067\ttotal: 2m 57s\tremaining: 19m 34s\n",
            "131:\tlearn: 0.9243254\ttotal: 2m 58s\tremaining: 19m 34s\n",
            "132:\tlearn: 0.9241306\ttotal: 3m\tremaining: 19m 33s\n",
            "133:\tlearn: 0.9239910\ttotal: 3m 1s\tremaining: 19m 32s\n",
            "134:\tlearn: 0.9238643\ttotal: 3m 2s\tremaining: 19m 32s\n",
            "135:\tlearn: 0.9237258\ttotal: 3m 4s\tremaining: 19m 31s\n",
            "136:\tlearn: 0.9235950\ttotal: 3m 5s\tremaining: 19m 31s\n",
            "137:\tlearn: 0.9234679\ttotal: 3m 7s\tremaining: 19m 31s\n",
            "138:\tlearn: 0.9233193\ttotal: 3m 9s\tremaining: 19m 31s\n",
            "139:\tlearn: 0.9232152\ttotal: 3m 10s\tremaining: 19m 31s\n",
            "140:\tlearn: 0.9231080\ttotal: 3m 12s\tremaining: 19m 30s\n",
            "141:\tlearn: 0.9229541\ttotal: 3m 13s\tremaining: 19m 29s\n",
            "142:\tlearn: 0.9227808\ttotal: 3m 15s\tremaining: 19m 29s\n",
            "143:\tlearn: 0.9226488\ttotal: 3m 16s\tremaining: 19m 29s\n",
            "144:\tlearn: 0.9225034\ttotal: 3m 18s\tremaining: 19m 28s\n",
            "145:\tlearn: 0.9223830\ttotal: 3m 19s\tremaining: 19m 28s\n",
            "146:\tlearn: 0.9222644\ttotal: 3m 21s\tremaining: 19m 28s\n",
            "147:\tlearn: 0.9220734\ttotal: 3m 22s\tremaining: 19m 27s\n",
            "148:\tlearn: 0.9219592\ttotal: 3m 24s\tremaining: 19m 27s\n",
            "149:\tlearn: 0.9218355\ttotal: 3m 26s\tremaining: 19m 27s\n",
            "150:\tlearn: 0.9217031\ttotal: 3m 27s\tremaining: 19m 26s\n",
            "151:\tlearn: 0.9215767\ttotal: 3m 29s\tremaining: 19m 26s\n",
            "152:\tlearn: 0.9214084\ttotal: 3m 30s\tremaining: 19m 25s\n",
            "153:\tlearn: 0.9212464\ttotal: 3m 32s\tremaining: 19m 25s\n",
            "154:\tlearn: 0.9211457\ttotal: 3m 33s\tremaining: 19m 24s\n",
            "155:\tlearn: 0.9210621\ttotal: 3m 35s\tremaining: 19m 23s\n",
            "156:\tlearn: 0.9209359\ttotal: 3m 36s\tremaining: 19m 23s\n",
            "157:\tlearn: 0.9208012\ttotal: 3m 38s\tremaining: 19m 22s\n",
            "158:\tlearn: 0.9206039\ttotal: 3m 39s\tremaining: 19m 22s\n",
            "159:\tlearn: 0.9205010\ttotal: 3m 41s\tremaining: 19m 21s\n",
            "160:\tlearn: 0.9203776\ttotal: 3m 42s\tremaining: 19m 20s\n",
            "161:\tlearn: 0.9202479\ttotal: 3m 44s\tremaining: 19m 20s\n",
            "162:\tlearn: 0.9201232\ttotal: 3m 45s\tremaining: 19m 19s\n",
            "163:\tlearn: 0.9200441\ttotal: 3m 47s\tremaining: 19m 17s\n",
            "164:\tlearn: 0.9199439\ttotal: 3m 48s\tremaining: 19m 16s\n",
            "165:\tlearn: 0.9198467\ttotal: 3m 50s\tremaining: 19m 15s\n",
            "166:\tlearn: 0.9196700\ttotal: 3m 51s\tremaining: 19m 15s\n",
            "167:\tlearn: 0.9195911\ttotal: 3m 53s\tremaining: 19m 15s\n",
            "168:\tlearn: 0.9194850\ttotal: 3m 54s\tremaining: 19m 13s\n",
            "169:\tlearn: 0.9193782\ttotal: 3m 56s\tremaining: 19m 13s\n",
            "170:\tlearn: 0.9192669\ttotal: 3m 57s\tremaining: 19m 12s\n",
            "171:\tlearn: 0.9191424\ttotal: 3m 59s\tremaining: 19m 11s\n",
            "172:\tlearn: 0.9190459\ttotal: 4m\tremaining: 19m 10s\n",
            "173:\tlearn: 0.9188716\ttotal: 4m 2s\tremaining: 19m 9s\n",
            "174:\tlearn: 0.9187612\ttotal: 4m 3s\tremaining: 19m 8s\n",
            "175:\tlearn: 0.9186682\ttotal: 4m 5s\tremaining: 19m 7s\n",
            "176:\tlearn: 0.9185978\ttotal: 4m 6s\tremaining: 19m 7s\n",
            "177:\tlearn: 0.9184859\ttotal: 4m 8s\tremaining: 19m 5s\n",
            "178:\tlearn: 0.9184052\ttotal: 4m 9s\tremaining: 19m 4s\n",
            "179:\tlearn: 0.9183055\ttotal: 4m 10s\tremaining: 19m 3s\n",
            "180:\tlearn: 0.9181917\ttotal: 4m 12s\tremaining: 19m\n",
            "181:\tlearn: 0.9180783\ttotal: 4m 13s\tremaining: 18m 59s\n",
            "182:\tlearn: 0.9180047\ttotal: 4m 14s\tremaining: 18m 58s\n",
            "183:\tlearn: 0.9178761\ttotal: 4m 16s\tremaining: 18m 56s\n",
            "184:\tlearn: 0.9177874\ttotal: 4m 17s\tremaining: 18m 53s\n",
            "185:\tlearn: 0.9177012\ttotal: 4m 18s\tremaining: 18m 52s\n",
            "186:\tlearn: 0.9175664\ttotal: 4m 20s\tremaining: 18m 50s\n",
            "187:\tlearn: 0.9174594\ttotal: 4m 21s\tremaining: 18m 49s\n",
            "188:\tlearn: 0.9173857\ttotal: 4m 23s\tremaining: 18m 48s\n",
            "189:\tlearn: 0.9172912\ttotal: 4m 24s\tremaining: 18m 47s\n",
            "190:\tlearn: 0.9172150\ttotal: 4m 25s\tremaining: 18m 45s\n",
            "191:\tlearn: 0.9171356\ttotal: 4m 27s\tremaining: 18m 45s\n",
            "192:\tlearn: 0.9170406\ttotal: 4m 28s\tremaining: 18m 44s\n",
            "193:\tlearn: 0.9169327\ttotal: 4m 30s\tremaining: 18m 42s\n",
            "194:\tlearn: 0.9168092\ttotal: 4m 31s\tremaining: 18m 41s\n",
            "195:\tlearn: 0.9166409\ttotal: 4m 33s\tremaining: 18m 40s\n",
            "196:\tlearn: 0.9165577\ttotal: 4m 34s\tremaining: 18m 39s\n",
            "197:\tlearn: 0.9164879\ttotal: 4m 36s\tremaining: 18m 38s\n",
            "198:\tlearn: 0.9163731\ttotal: 4m 37s\tremaining: 18m 37s\n",
            "199:\tlearn: 0.9163142\ttotal: 4m 39s\tremaining: 18m 36s\n",
            "200:\tlearn: 0.9162338\ttotal: 4m 40s\tremaining: 18m 36s\n",
            "201:\tlearn: 0.9161640\ttotal: 4m 42s\tremaining: 18m 35s\n",
            "202:\tlearn: 0.9160835\ttotal: 4m 43s\tremaining: 18m 34s\n",
            "203:\tlearn: 0.9160174\ttotal: 4m 45s\tremaining: 18m 34s\n",
            "204:\tlearn: 0.9159393\ttotal: 4m 47s\tremaining: 18m 33s\n",
            "205:\tlearn: 0.9158576\ttotal: 4m 48s\tremaining: 18m 32s\n",
            "206:\tlearn: 0.9157729\ttotal: 4m 50s\tremaining: 18m 31s\n",
            "207:\tlearn: 0.9157125\ttotal: 4m 51s\tremaining: 18m 30s\n",
            "208:\tlearn: 0.9155941\ttotal: 4m 53s\tremaining: 18m 29s\n",
            "209:\tlearn: 0.9155226\ttotal: 4m 54s\tremaining: 18m 26s\n",
            "210:\tlearn: 0.9154303\ttotal: 4m 55s\tremaining: 18m 25s\n",
            "211:\tlearn: 0.9153748\ttotal: 4m 57s\tremaining: 18m 24s\n",
            "212:\tlearn: 0.9153107\ttotal: 4m 58s\tremaining: 18m 23s\n",
            "213:\tlearn: 0.9152042\ttotal: 4m 59s\tremaining: 18m 21s\n",
            "214:\tlearn: 0.9151595\ttotal: 5m 1s\tremaining: 18m 20s\n",
            "215:\tlearn: 0.9150818\ttotal: 5m 3s\tremaining: 18m 19s\n",
            "216:\tlearn: 0.9150158\ttotal: 5m 4s\tremaining: 18m 18s\n",
            "217:\tlearn: 0.9149606\ttotal: 5m 5s\tremaining: 18m 17s\n",
            "218:\tlearn: 0.9149035\ttotal: 5m 7s\tremaining: 18m 15s\n",
            "219:\tlearn: 0.9148618\ttotal: 5m 8s\tremaining: 18m 14s\n",
            "220:\tlearn: 0.9147665\ttotal: 5m 10s\tremaining: 18m 13s\n",
            "221:\tlearn: 0.9146938\ttotal: 5m 11s\tremaining: 18m 12s\n",
            "222:\tlearn: 0.9146316\ttotal: 5m 12s\tremaining: 18m 10s\n",
            "223:\tlearn: 0.9145298\ttotal: 5m 14s\tremaining: 18m 9s\n",
            "224:\tlearn: 0.9144842\ttotal: 5m 15s\tremaining: 18m 8s\n",
            "225:\tlearn: 0.9143784\ttotal: 5m 17s\tremaining: 18m 6s\n",
            "226:\tlearn: 0.9143292\ttotal: 5m 18s\tremaining: 18m 5s\n",
            "227:\tlearn: 0.9141983\ttotal: 5m 20s\tremaining: 18m 4s\n",
            "228:\tlearn: 0.9141048\ttotal: 5m 21s\tremaining: 18m 3s\n",
            "229:\tlearn: 0.9140535\ttotal: 5m 23s\tremaining: 18m 2s\n",
            "230:\tlearn: 0.9139776\ttotal: 5m 24s\tremaining: 18m 1s\n",
            "231:\tlearn: 0.9138887\ttotal: 5m 26s\tremaining: 18m\n",
            "232:\tlearn: 0.9138068\ttotal: 5m 27s\tremaining: 17m 59s\n",
            "233:\tlearn: 0.9137024\ttotal: 5m 29s\tremaining: 17m 58s\n",
            "234:\tlearn: 0.9136135\ttotal: 5m 31s\tremaining: 17m 57s\n",
            "235:\tlearn: 0.9135579\ttotal: 5m 32s\tremaining: 17m 56s\n",
            "236:\tlearn: 0.9134371\ttotal: 5m 34s\tremaining: 17m 56s\n",
            "237:\tlearn: 0.9133564\ttotal: 5m 35s\tremaining: 17m 55s\n",
            "238:\tlearn: 0.9132914\ttotal: 5m 36s\tremaining: 17m 52s\n",
            "239:\tlearn: 0.9132417\ttotal: 5m 38s\tremaining: 17m 51s\n",
            "240:\tlearn: 0.9131569\ttotal: 5m 40s\tremaining: 17m 51s\n",
            "241:\tlearn: 0.9130706\ttotal: 5m 41s\tremaining: 17m 49s\n",
            "242:\tlearn: 0.9129890\ttotal: 5m 43s\tremaining: 17m 48s\n",
            "243:\tlearn: 0.9128930\ttotal: 5m 44s\tremaining: 17m 47s\n",
            "244:\tlearn: 0.9128078\ttotal: 5m 46s\tremaining: 17m 46s\n",
            "245:\tlearn: 0.9127559\ttotal: 5m 47s\tremaining: 17m 44s\n",
            "246:\tlearn: 0.9127094\ttotal: 5m 48s\tremaining: 17m 42s\n",
            "247:\tlearn: 0.9126637\ttotal: 5m 50s\tremaining: 17m 41s\n",
            "248:\tlearn: 0.9126052\ttotal: 5m 51s\tremaining: 17m 40s\n",
            "249:\tlearn: 0.9125268\ttotal: 5m 52s\tremaining: 17m 38s\n",
            "250:\tlearn: 0.9124831\ttotal: 5m 54s\tremaining: 17m 37s\n",
            "251:\tlearn: 0.9123783\ttotal: 5m 56s\tremaining: 17m 36s\n",
            "252:\tlearn: 0.9123408\ttotal: 5m 57s\tremaining: 17m 36s\n",
            "253:\tlearn: 0.9122679\ttotal: 5m 59s\tremaining: 17m 34s\n",
            "254:\tlearn: 0.9122054\ttotal: 6m\tremaining: 17m 33s\n",
            "255:\tlearn: 0.9121586\ttotal: 6m 2s\tremaining: 17m 32s\n",
            "256:\tlearn: 0.9121156\ttotal: 6m 3s\tremaining: 17m 30s\n",
            "257:\tlearn: 0.9120313\ttotal: 6m 4s\tremaining: 17m 28s\n",
            "258:\tlearn: 0.9119755\ttotal: 6m 6s\tremaining: 17m 27s\n",
            "259:\tlearn: 0.9119374\ttotal: 6m 7s\tremaining: 17m 26s\n",
            "260:\tlearn: 0.9118530\ttotal: 6m 9s\tremaining: 17m 24s\n",
            "261:\tlearn: 0.9117742\ttotal: 6m 10s\tremaining: 17m 23s\n",
            "262:\tlearn: 0.9117175\ttotal: 6m 11s\tremaining: 17m 22s\n",
            "263:\tlearn: 0.9116393\ttotal: 6m 13s\tremaining: 17m 20s\n",
            "264:\tlearn: 0.9115759\ttotal: 6m 14s\tremaining: 17m 19s\n",
            "265:\tlearn: 0.9115135\ttotal: 6m 16s\tremaining: 17m 18s\n",
            "266:\tlearn: 0.9114565\ttotal: 6m 17s\tremaining: 17m 17s\n",
            "267:\tlearn: 0.9113887\ttotal: 6m 19s\tremaining: 17m 16s\n",
            "268:\tlearn: 0.9113212\ttotal: 6m 21s\tremaining: 17m 15s\n",
            "269:\tlearn: 0.9112686\ttotal: 6m 22s\tremaining: 17m 14s\n",
            "270:\tlearn: 0.9112179\ttotal: 6m 24s\tremaining: 17m 13s\n",
            "271:\tlearn: 0.9111749\ttotal: 6m 25s\tremaining: 17m 11s\n",
            "272:\tlearn: 0.9111082\ttotal: 6m 26s\tremaining: 17m 10s\n",
            "273:\tlearn: 0.9110408\ttotal: 6m 28s\tremaining: 17m 8s\n",
            "274:\tlearn: 0.9109929\ttotal: 6m 29s\tremaining: 17m 6s\n",
            "275:\tlearn: 0.9109179\ttotal: 6m 30s\tremaining: 17m 5s\n",
            "276:\tlearn: 0.9108569\ttotal: 6m 32s\tremaining: 17m 3s\n",
            "277:\tlearn: 0.9108207\ttotal: 6m 33s\tremaining: 17m 2s\n",
            "278:\tlearn: 0.9107817\ttotal: 6m 35s\tremaining: 17m 1s\n",
            "279:\tlearn: 0.9107456\ttotal: 6m 36s\tremaining: 16m 59s\n",
            "280:\tlearn: 0.9107036\ttotal: 6m 37s\tremaining: 16m 57s\n",
            "281:\tlearn: 0.9106297\ttotal: 6m 39s\tremaining: 16m 56s\n",
            "282:\tlearn: 0.9105624\ttotal: 6m 40s\tremaining: 16m 54s\n",
            "283:\tlearn: 0.9105228\ttotal: 6m 42s\tremaining: 16m 53s\n",
            "284:\tlearn: 0.9104474\ttotal: 6m 43s\tremaining: 16m 52s\n",
            "285:\tlearn: 0.9104219\ttotal: 6m 44s\tremaining: 16m 50s\n",
            "286:\tlearn: 0.9103769\ttotal: 6m 46s\tremaining: 16m 48s\n",
            "287:\tlearn: 0.9103292\ttotal: 6m 47s\tremaining: 16m 47s\n",
            "288:\tlearn: 0.9102891\ttotal: 6m 48s\tremaining: 16m 45s\n",
            "289:\tlearn: 0.9102467\ttotal: 6m 50s\tremaining: 16m 44s\n",
            "290:\tlearn: 0.9102146\ttotal: 6m 51s\tremaining: 16m 43s\n",
            "291:\tlearn: 0.9101796\ttotal: 6m 53s\tremaining: 16m 42s\n",
            "292:\tlearn: 0.9101453\ttotal: 6m 55s\tremaining: 16m 41s\n",
            "293:\tlearn: 0.9101000\ttotal: 6m 56s\tremaining: 16m 40s\n",
            "294:\tlearn: 0.9100497\ttotal: 6m 58s\tremaining: 16m 39s\n",
            "295:\tlearn: 0.9100015\ttotal: 6m 59s\tremaining: 16m 37s\n",
            "296:\tlearn: 0.9099518\ttotal: 7m\tremaining: 16m 36s\n",
            "297:\tlearn: 0.9099296\ttotal: 7m 2s\tremaining: 16m 34s\n",
            "298:\tlearn: 0.9098840\ttotal: 7m 3s\tremaining: 16m 33s\n",
            "299:\tlearn: 0.9098443\ttotal: 7m 5s\tremaining: 16m 32s\n",
            "300:\tlearn: 0.9097967\ttotal: 7m 6s\tremaining: 16m 31s\n",
            "301:\tlearn: 0.9097235\ttotal: 7m 8s\tremaining: 16m 29s\n",
            "302:\tlearn: 0.9096797\ttotal: 7m 9s\tremaining: 16m 28s\n",
            "303:\tlearn: 0.9096439\ttotal: 7m 11s\tremaining: 16m 27s\n",
            "304:\tlearn: 0.9095680\ttotal: 7m 12s\tremaining: 16m 25s\n",
            "305:\tlearn: 0.9095120\ttotal: 7m 14s\tremaining: 16m 24s\n",
            "306:\tlearn: 0.9094683\ttotal: 7m 15s\tremaining: 16m 23s\n",
            "307:\tlearn: 0.9093924\ttotal: 7m 16s\tremaining: 16m 21s\n",
            "308:\tlearn: 0.9093576\ttotal: 7m 18s\tremaining: 16m 20s\n",
            "309:\tlearn: 0.9093179\ttotal: 7m 19s\tremaining: 16m 18s\n",
            "310:\tlearn: 0.9092756\ttotal: 7m 21s\tremaining: 16m 17s\n",
            "311:\tlearn: 0.9092237\ttotal: 7m 22s\tremaining: 16m 15s\n",
            "312:\tlearn: 0.9091613\ttotal: 7m 24s\tremaining: 16m 14s\n",
            "313:\tlearn: 0.9090977\ttotal: 7m 25s\tremaining: 16m 13s\n",
            "314:\tlearn: 0.9090669\ttotal: 7m 26s\tremaining: 16m 11s\n",
            "315:\tlearn: 0.9090248\ttotal: 7m 28s\tremaining: 16m 10s\n",
            "316:\tlearn: 0.9089876\ttotal: 7m 29s\tremaining: 16m 8s\n",
            "317:\tlearn: 0.9089396\ttotal: 7m 31s\tremaining: 16m 7s\n",
            "318:\tlearn: 0.9089144\ttotal: 7m 32s\tremaining: 16m 5s\n",
            "319:\tlearn: 0.9088713\ttotal: 7m 33s\tremaining: 16m 4s\n",
            "320:\tlearn: 0.9088331\ttotal: 7m 35s\tremaining: 16m 2s\n",
            "321:\tlearn: 0.9087969\ttotal: 7m 36s\tremaining: 16m 1s\n",
            "322:\tlearn: 0.9087687\ttotal: 7m 37s\tremaining: 15m 59s\n",
            "323:\tlearn: 0.9087094\ttotal: 7m 39s\tremaining: 15m 58s\n",
            "324:\tlearn: 0.9086623\ttotal: 7m 40s\tremaining: 15m 56s\n",
            "325:\tlearn: 0.9086315\ttotal: 7m 42s\tremaining: 15m 55s\n",
            "326:\tlearn: 0.9085585\ttotal: 7m 43s\tremaining: 15m 54s\n",
            "327:\tlearn: 0.9085045\ttotal: 7m 44s\tremaining: 15m 52s\n",
            "328:\tlearn: 0.9084129\ttotal: 7m 46s\tremaining: 15m 51s\n",
            "329:\tlearn: 0.9083430\ttotal: 7m 47s\tremaining: 15m 49s\n",
            "330:\tlearn: 0.9082954\ttotal: 7m 49s\tremaining: 15m 48s\n",
            "331:\tlearn: 0.9082565\ttotal: 7m 50s\tremaining: 15m 47s\n",
            "332:\tlearn: 0.9082053\ttotal: 7m 52s\tremaining: 15m 45s\n",
            "333:\tlearn: 0.9081552\ttotal: 7m 53s\tremaining: 15m 44s\n",
            "334:\tlearn: 0.9081137\ttotal: 7m 55s\tremaining: 15m 42s\n",
            "335:\tlearn: 0.9080751\ttotal: 7m 56s\tremaining: 15m 41s\n",
            "336:\tlearn: 0.9080447\ttotal: 7m 57s\tremaining: 15m 40s\n",
            "337:\tlearn: 0.9079890\ttotal: 7m 59s\tremaining: 15m 38s\n",
            "338:\tlearn: 0.9079115\ttotal: 8m\tremaining: 15m 37s\n",
            "339:\tlearn: 0.9078374\ttotal: 8m 2s\tremaining: 15m 36s\n",
            "340:\tlearn: 0.9077754\ttotal: 8m 3s\tremaining: 15m 35s\n",
            "341:\tlearn: 0.9077449\ttotal: 8m 5s\tremaining: 15m 33s\n",
            "342:\tlearn: 0.9076636\ttotal: 8m 6s\tremaining: 15m 32s\n",
            "343:\tlearn: 0.9076156\ttotal: 8m 8s\tremaining: 15m 31s\n",
            "344:\tlearn: 0.9075227\ttotal: 8m 9s\tremaining: 15m 30s\n",
            "345:\tlearn: 0.9074738\ttotal: 8m 11s\tremaining: 15m 29s\n",
            "346:\tlearn: 0.9073963\ttotal: 8m 13s\tremaining: 15m 27s\n",
            "347:\tlearn: 0.9073500\ttotal: 8m 14s\tremaining: 15m 27s\n",
            "348:\tlearn: 0.9072628\ttotal: 8m 16s\tremaining: 15m 25s\n",
            "349:\tlearn: 0.9072126\ttotal: 8m 17s\tremaining: 15m 24s\n",
            "350:\tlearn: 0.9071740\ttotal: 8m 19s\tremaining: 15m 22s\n",
            "351:\tlearn: 0.9071338\ttotal: 8m 20s\tremaining: 15m 21s\n",
            "352:\tlearn: 0.9070545\ttotal: 8m 22s\tremaining: 15m 20s\n",
            "353:\tlearn: 0.9070219\ttotal: 8m 23s\tremaining: 15m 18s\n",
            "354:\tlearn: 0.9069973\ttotal: 8m 24s\tremaining: 15m 16s\n",
            "355:\tlearn: 0.9069716\ttotal: 8m 25s\tremaining: 15m 15s\n",
            "356:\tlearn: 0.9068957\ttotal: 8m 27s\tremaining: 15m 13s\n",
            "357:\tlearn: 0.9068613\ttotal: 8m 28s\tremaining: 15m 12s\n",
            "358:\tlearn: 0.9067995\ttotal: 8m 30s\tremaining: 15m 11s\n",
            "359:\tlearn: 0.9067875\ttotal: 8m 31s\tremaining: 15m 9s\n",
            "360:\tlearn: 0.9067287\ttotal: 8m 33s\tremaining: 15m 8s\n",
            "361:\tlearn: 0.9066748\ttotal: 8m 34s\tremaining: 15m 6s\n",
            "362:\tlearn: 0.9066143\ttotal: 8m 36s\tremaining: 15m 5s\n",
            "363:\tlearn: 0.9065618\ttotal: 8m 37s\tremaining: 15m 4s\n",
            "364:\tlearn: 0.9065232\ttotal: 8m 39s\tremaining: 15m 3s\n",
            "365:\tlearn: 0.9064971\ttotal: 8m 40s\tremaining: 15m 1s\n",
            "366:\tlearn: 0.9064594\ttotal: 8m 41s\tremaining: 15m\n",
            "367:\tlearn: 0.9064282\ttotal: 8m 43s\tremaining: 14m 58s\n",
            "368:\tlearn: 0.9063579\ttotal: 8m 44s\tremaining: 14m 57s\n",
            "369:\tlearn: 0.9063306\ttotal: 8m 46s\tremaining: 14m 55s\n",
            "370:\tlearn: 0.9063075\ttotal: 8m 47s\tremaining: 14m 54s\n",
            "371:\tlearn: 0.9062695\ttotal: 8m 48s\tremaining: 14m 52s\n",
            "372:\tlearn: 0.9062478\ttotal: 8m 49s\tremaining: 14m 50s\n",
            "373:\tlearn: 0.9062273\ttotal: 8m 51s\tremaining: 14m 48s\n",
            "374:\tlearn: 0.9061755\ttotal: 8m 52s\tremaining: 14m 47s\n",
            "375:\tlearn: 0.9061445\ttotal: 8m 53s\tremaining: 14m 46s\n",
            "376:\tlearn: 0.9060974\ttotal: 8m 55s\tremaining: 14m 45s\n",
            "377:\tlearn: 0.9060515\ttotal: 8m 56s\tremaining: 14m 43s\n",
            "378:\tlearn: 0.9060159\ttotal: 8m 58s\tremaining: 14m 42s\n",
            "379:\tlearn: 0.9059915\ttotal: 9m\tremaining: 14m 41s\n",
            "380:\tlearn: 0.9059575\ttotal: 9m 1s\tremaining: 14m 39s\n",
            "381:\tlearn: 0.9059293\ttotal: 9m 2s\tremaining: 14m 38s\n",
            "382:\tlearn: 0.9058715\ttotal: 9m 4s\tremaining: 14m 37s\n",
            "383:\tlearn: 0.9058096\ttotal: 9m 6s\tremaining: 14m 35s\n",
            "384:\tlearn: 0.9057760\ttotal: 9m 7s\tremaining: 14m 34s\n",
            "385:\tlearn: 0.9057591\ttotal: 9m 8s\tremaining: 14m 32s\n",
            "386:\tlearn: 0.9057239\ttotal: 9m 10s\tremaining: 14m 31s\n",
            "387:\tlearn: 0.9056880\ttotal: 9m 11s\tremaining: 14m 29s\n",
            "388:\tlearn: 0.9056225\ttotal: 9m 13s\tremaining: 14m 28s\n",
            "389:\tlearn: 0.9055695\ttotal: 9m 14s\tremaining: 14m 27s\n",
            "390:\tlearn: 0.9055420\ttotal: 9m 15s\tremaining: 14m 25s\n",
            "391:\tlearn: 0.9054912\ttotal: 9m 17s\tremaining: 14m 24s\n",
            "392:\tlearn: 0.9054612\ttotal: 9m 18s\tremaining: 14m 23s\n",
            "393:\tlearn: 0.9054224\ttotal: 9m 20s\tremaining: 14m 21s\n",
            "394:\tlearn: 0.9053537\ttotal: 9m 21s\tremaining: 14m 20s\n",
            "395:\tlearn: 0.9053051\ttotal: 9m 23s\tremaining: 14m 18s\n",
            "396:\tlearn: 0.9052888\ttotal: 9m 24s\tremaining: 14m 17s\n",
            "397:\tlearn: 0.9052499\ttotal: 9m 25s\tremaining: 14m 16s\n",
            "398:\tlearn: 0.9052320\ttotal: 9m 27s\tremaining: 14m 14s\n",
            "399:\tlearn: 0.9052095\ttotal: 9m 28s\tremaining: 14m 12s\n",
            "400:\tlearn: 0.9051855\ttotal: 9m 30s\tremaining: 14m 11s\n",
            "401:\tlearn: 0.9051122\ttotal: 9m 31s\tremaining: 14m 10s\n",
            "402:\tlearn: 0.9050810\ttotal: 9m 33s\tremaining: 14m 9s\n",
            "403:\tlearn: 0.9050358\ttotal: 9m 34s\tremaining: 14m 7s\n",
            "404:\tlearn: 0.9050114\ttotal: 9m 36s\tremaining: 14m 6s\n",
            "405:\tlearn: 0.9049833\ttotal: 9m 37s\tremaining: 14m 4s\n",
            "406:\tlearn: 0.9049543\ttotal: 9m 38s\tremaining: 14m 3s\n",
            "407:\tlearn: 0.9049329\ttotal: 9m 39s\tremaining: 14m 1s\n",
            "408:\tlearn: 0.9048944\ttotal: 9m 41s\tremaining: 14m\n",
            "409:\tlearn: 0.9048658\ttotal: 9m 43s\tremaining: 13m 59s\n",
            "410:\tlearn: 0.9048390\ttotal: 9m 44s\tremaining: 13m 57s\n",
            "411:\tlearn: 0.9048012\ttotal: 9m 45s\tremaining: 13m 56s\n",
            "412:\tlearn: 0.9047769\ttotal: 9m 47s\tremaining: 13m 54s\n",
            "413:\tlearn: 0.9047270\ttotal: 9m 48s\tremaining: 13m 53s\n",
            "414:\tlearn: 0.9046920\ttotal: 9m 50s\tremaining: 13m 51s\n",
            "415:\tlearn: 0.9046359\ttotal: 9m 51s\tremaining: 13m 50s\n",
            "416:\tlearn: 0.9045655\ttotal: 9m 53s\tremaining: 13m 49s\n",
            "417:\tlearn: 0.9045419\ttotal: 9m 54s\tremaining: 13m 48s\n",
            "418:\tlearn: 0.9044811\ttotal: 9m 56s\tremaining: 13m 46s\n",
            "419:\tlearn: 0.9044637\ttotal: 9m 57s\tremaining: 13m 45s\n",
            "420:\tlearn: 0.9044507\ttotal: 9m 58s\tremaining: 13m 43s\n",
            "421:\tlearn: 0.9044087\ttotal: 10m\tremaining: 13m 42s\n",
            "422:\tlearn: 0.9043766\ttotal: 10m 1s\tremaining: 13m 40s\n",
            "423:\tlearn: 0.9043314\ttotal: 10m 3s\tremaining: 13m 39s\n",
            "424:\tlearn: 0.9043040\ttotal: 10m 4s\tremaining: 13m 37s\n",
            "425:\tlearn: 0.9042744\ttotal: 10m 5s\tremaining: 13m 36s\n",
            "426:\tlearn: 0.9042388\ttotal: 10m 7s\tremaining: 13m 35s\n",
            "427:\tlearn: 0.9042093\ttotal: 10m 9s\tremaining: 13m 33s\n",
            "428:\tlearn: 0.9041698\ttotal: 10m 10s\tremaining: 13m 32s\n",
            "429:\tlearn: 0.9041058\ttotal: 10m 11s\tremaining: 13m 31s\n",
            "430:\tlearn: 0.9040851\ttotal: 10m 13s\tremaining: 13m 29s\n",
            "431:\tlearn: 0.9040315\ttotal: 10m 14s\tremaining: 13m 28s\n",
            "432:\tlearn: 0.9039992\ttotal: 10m 16s\tremaining: 13m 26s\n",
            "433:\tlearn: 0.9039700\ttotal: 10m 17s\tremaining: 13m 25s\n",
            "434:\tlearn: 0.9039378\ttotal: 10m 18s\tremaining: 13m 23s\n",
            "435:\tlearn: 0.9038522\ttotal: 10m 20s\tremaining: 13m 22s\n",
            "436:\tlearn: 0.9038253\ttotal: 10m 22s\tremaining: 13m 21s\n",
            "437:\tlearn: 0.9037885\ttotal: 10m 23s\tremaining: 13m 20s\n",
            "438:\tlearn: 0.9037431\ttotal: 10m 25s\tremaining: 13m 19s\n",
            "439:\tlearn: 0.9037184\ttotal: 10m 26s\tremaining: 13m 17s\n",
            "440:\tlearn: 0.9036891\ttotal: 10m 28s\tremaining: 13m 16s\n",
            "441:\tlearn: 0.9036551\ttotal: 10m 29s\tremaining: 13m 14s\n",
            "442:\tlearn: 0.9036304\ttotal: 10m 31s\tremaining: 13m 13s\n",
            "443:\tlearn: 0.9035874\ttotal: 10m 32s\tremaining: 13m 12s\n",
            "444:\tlearn: 0.9035592\ttotal: 10m 34s\tremaining: 13m 11s\n",
            "445:\tlearn: 0.9035102\ttotal: 10m 35s\tremaining: 13m 9s\n",
            "446:\tlearn: 0.9034561\ttotal: 10m 37s\tremaining: 13m 8s\n",
            "447:\tlearn: 0.9034004\ttotal: 10m 38s\tremaining: 13m 7s\n",
            "448:\tlearn: 0.9033682\ttotal: 10m 40s\tremaining: 13m 5s\n",
            "449:\tlearn: 0.9033309\ttotal: 10m 41s\tremaining: 13m 4s\n",
            "450:\tlearn: 0.9033083\ttotal: 10m 43s\tremaining: 13m 3s\n",
            "451:\tlearn: 0.9032682\ttotal: 10m 45s\tremaining: 13m 2s\n",
            "452:\tlearn: 0.9032547\ttotal: 10m 46s\tremaining: 13m\n",
            "453:\tlearn: 0.9031817\ttotal: 10m 48s\tremaining: 12m 59s\n",
            "454:\tlearn: 0.9031493\ttotal: 10m 49s\tremaining: 12m 58s\n",
            "455:\tlearn: 0.9031276\ttotal: 10m 51s\tremaining: 12m 56s\n",
            "456:\tlearn: 0.9031128\ttotal: 10m 52s\tremaining: 12m 55s\n",
            "457:\tlearn: 0.9030586\ttotal: 10m 54s\tremaining: 12m 54s\n",
            "458:\tlearn: 0.9030232\ttotal: 10m 55s\tremaining: 12m 53s\n",
            "459:\tlearn: 0.9030013\ttotal: 10m 57s\tremaining: 12m 51s\n",
            "460:\tlearn: 0.9029522\ttotal: 10m 59s\tremaining: 12m 50s\n",
            "461:\tlearn: 0.9029260\ttotal: 11m\tremaining: 12m 49s\n",
            "462:\tlearn: 0.9029016\ttotal: 11m 2s\tremaining: 12m 48s\n",
            "463:\tlearn: 0.9028524\ttotal: 11m 3s\tremaining: 12m 46s\n",
            "464:\tlearn: 0.9028316\ttotal: 11m 5s\tremaining: 12m 45s\n",
            "465:\tlearn: 0.9028115\ttotal: 11m 6s\tremaining: 12m 44s\n",
            "466:\tlearn: 0.9027653\ttotal: 11m 8s\tremaining: 12m 42s\n",
            "467:\tlearn: 0.9027200\ttotal: 11m 9s\tremaining: 12m 41s\n",
            "468:\tlearn: 0.9026770\ttotal: 11m 11s\tremaining: 12m 40s\n",
            "469:\tlearn: 0.9026177\ttotal: 11m 13s\tremaining: 12m 38s\n",
            "470:\tlearn: 0.9025738\ttotal: 11m 14s\tremaining: 12m 37s\n",
            "471:\tlearn: 0.9025385\ttotal: 11m 16s\tremaining: 12m 36s\n",
            "472:\tlearn: 0.9025133\ttotal: 11m 17s\tremaining: 12m 34s\n",
            "473:\tlearn: 0.9024763\ttotal: 11m 19s\tremaining: 12m 33s\n",
            "474:\tlearn: 0.9024229\ttotal: 11m 20s\tremaining: 12m 32s\n",
            "475:\tlearn: 0.9023722\ttotal: 11m 22s\tremaining: 12m 30s\n",
            "476:\tlearn: 0.9023376\ttotal: 11m 23s\tremaining: 12m 29s\n",
            "477:\tlearn: 0.9023052\ttotal: 11m 25s\tremaining: 12m 28s\n",
            "478:\tlearn: 0.9022727\ttotal: 11m 26s\tremaining: 12m 26s\n",
            "479:\tlearn: 0.9022372\ttotal: 11m 28s\tremaining: 12m 25s\n",
            "480:\tlearn: 0.9022175\ttotal: 11m 29s\tremaining: 12m 23s\n",
            "481:\tlearn: 0.9021893\ttotal: 11m 31s\tremaining: 12m 22s\n",
            "482:\tlearn: 0.9021583\ttotal: 11m 32s\tremaining: 12m 21s\n",
            "483:\tlearn: 0.9021290\ttotal: 11m 34s\tremaining: 12m 20s\n",
            "484:\tlearn: 0.9020643\ttotal: 11m 35s\tremaining: 12m 18s\n",
            "485:\tlearn: 0.9020395\ttotal: 11m 37s\tremaining: 12m 17s\n",
            "486:\tlearn: 0.9019986\ttotal: 11m 38s\tremaining: 12m 16s\n",
            "487:\tlearn: 0.9019777\ttotal: 11m 40s\tremaining: 12m 14s\n",
            "488:\tlearn: 0.9019378\ttotal: 11m 41s\tremaining: 12m 13s\n",
            "489:\tlearn: 0.9018882\ttotal: 11m 43s\tremaining: 12m 11s\n",
            "490:\tlearn: 0.9018466\ttotal: 11m 44s\tremaining: 12m 10s\n",
            "491:\tlearn: 0.9017884\ttotal: 11m 46s\tremaining: 12m 9s\n",
            "492:\tlearn: 0.9017607\ttotal: 11m 47s\tremaining: 12m 7s\n",
            "493:\tlearn: 0.9017472\ttotal: 11m 48s\tremaining: 12m 6s\n",
            "494:\tlearn: 0.9017295\ttotal: 11m 50s\tremaining: 12m 4s\n",
            "495:\tlearn: 0.9017114\ttotal: 11m 51s\tremaining: 12m 3s\n",
            "496:\tlearn: 0.9016676\ttotal: 11m 53s\tremaining: 12m 1s\n",
            "497:\tlearn: 0.9016367\ttotal: 11m 55s\tremaining: 12m\n",
            "498:\tlearn: 0.9016172\ttotal: 11m 56s\tremaining: 11m 59s\n",
            "499:\tlearn: 0.9015838\ttotal: 11m 57s\tremaining: 11m 57s\n",
            "500:\tlearn: 0.9015391\ttotal: 11m 59s\tremaining: 11m 56s\n",
            "501:\tlearn: 0.9015038\ttotal: 12m\tremaining: 11m 55s\n",
            "502:\tlearn: 0.9014504\ttotal: 12m 2s\tremaining: 11m 53s\n",
            "503:\tlearn: 0.9014185\ttotal: 12m 3s\tremaining: 11m 52s\n",
            "504:\tlearn: 0.9013858\ttotal: 12m 5s\tremaining: 11m 51s\n",
            "505:\tlearn: 0.9013535\ttotal: 12m 7s\tremaining: 11m 49s\n",
            "506:\tlearn: 0.9013241\ttotal: 12m 8s\tremaining: 11m 48s\n",
            "507:\tlearn: 0.9013041\ttotal: 12m 10s\tremaining: 11m 47s\n",
            "508:\tlearn: 0.9012874\ttotal: 12m 11s\tremaining: 11m 45s\n",
            "509:\tlearn: 0.9012521\ttotal: 12m 13s\tremaining: 11m 44s\n",
            "510:\tlearn: 0.9012135\ttotal: 12m 14s\tremaining: 11m 43s\n",
            "511:\tlearn: 0.9011819\ttotal: 12m 16s\tremaining: 11m 42s\n",
            "512:\tlearn: 0.9011349\ttotal: 12m 18s\tremaining: 11m 40s\n",
            "513:\tlearn: 0.9010807\ttotal: 12m 19s\tremaining: 11m 39s\n",
            "514:\tlearn: 0.9010498\ttotal: 12m 21s\tremaining: 11m 38s\n",
            "515:\tlearn: 0.9009973\ttotal: 12m 22s\tremaining: 11m 36s\n",
            "516:\tlearn: 0.9009670\ttotal: 12m 24s\tremaining: 11m 35s\n",
            "517:\tlearn: 0.9009219\ttotal: 12m 25s\tremaining: 11m 34s\n",
            "518:\tlearn: 0.9008884\ttotal: 12m 27s\tremaining: 11m 32s\n",
            "519:\tlearn: 0.9008534\ttotal: 12m 29s\tremaining: 11m 31s\n",
            "520:\tlearn: 0.9008267\ttotal: 12m 30s\tremaining: 11m 30s\n",
            "521:\tlearn: 0.9007789\ttotal: 12m 32s\tremaining: 11m 29s\n",
            "522:\tlearn: 0.9007418\ttotal: 12m 34s\tremaining: 11m 27s\n",
            "523:\tlearn: 0.9006904\ttotal: 12m 35s\tremaining: 11m 26s\n",
            "524:\tlearn: 0.9006496\ttotal: 12m 37s\tremaining: 11m 25s\n",
            "525:\tlearn: 0.9006087\ttotal: 12m 39s\tremaining: 11m 23s\n",
            "526:\tlearn: 0.9005474\ttotal: 12m 40s\tremaining: 11m 22s\n",
            "527:\tlearn: 0.9005202\ttotal: 12m 42s\tremaining: 11m 21s\n",
            "528:\tlearn: 0.9004849\ttotal: 12m 43s\tremaining: 11m 20s\n",
            "529:\tlearn: 0.9004503\ttotal: 12m 45s\tremaining: 11m 18s\n",
            "530:\tlearn: 0.9004228\ttotal: 12m 46s\tremaining: 11m 17s\n",
            "531:\tlearn: 0.9003909\ttotal: 12m 48s\tremaining: 11m 15s\n",
            "532:\tlearn: 0.9003547\ttotal: 12m 49s\tremaining: 11m 14s\n",
            "533:\tlearn: 0.9003318\ttotal: 12m 51s\tremaining: 11m 13s\n",
            "534:\tlearn: 0.9002962\ttotal: 12m 52s\tremaining: 11m 11s\n",
            "535:\tlearn: 0.9002474\ttotal: 12m 54s\tremaining: 11m 10s\n",
            "536:\tlearn: 0.9002231\ttotal: 12m 55s\tremaining: 11m 8s\n",
            "537:\tlearn: 0.9001832\ttotal: 12m 57s\tremaining: 11m 7s\n",
            "538:\tlearn: 0.9001419\ttotal: 12m 58s\tremaining: 11m 6s\n",
            "539:\tlearn: 0.9001200\ttotal: 13m\tremaining: 11m 4s\n",
            "540:\tlearn: 0.9000943\ttotal: 13m 1s\tremaining: 11m 3s\n",
            "541:\tlearn: 0.9000529\ttotal: 13m 3s\tremaining: 11m 2s\n",
            "542:\tlearn: 0.9000220\ttotal: 13m 5s\tremaining: 11m\n",
            "543:\tlearn: 0.8999865\ttotal: 13m 6s\tremaining: 10m 59s\n",
            "544:\tlearn: 0.8999576\ttotal: 13m 8s\tremaining: 10m 57s\n",
            "545:\tlearn: 0.8999243\ttotal: 13m 9s\tremaining: 10m 56s\n",
            "546:\tlearn: 0.8998943\ttotal: 13m 10s\tremaining: 10m 55s\n",
            "547:\tlearn: 0.8998636\ttotal: 13m 12s\tremaining: 10m 53s\n",
            "548:\tlearn: 0.8998254\ttotal: 13m 14s\tremaining: 10m 52s\n",
            "549:\tlearn: 0.8997879\ttotal: 13m 15s\tremaining: 10m 50s\n",
            "550:\tlearn: 0.8997519\ttotal: 13m 17s\tremaining: 10m 49s\n",
            "551:\tlearn: 0.8997052\ttotal: 13m 18s\tremaining: 10m 48s\n",
            "552:\tlearn: 0.8996576\ttotal: 13m 20s\tremaining: 10m 46s\n",
            "553:\tlearn: 0.8996229\ttotal: 13m 21s\tremaining: 10m 45s\n",
            "554:\tlearn: 0.8996039\ttotal: 13m 23s\tremaining: 10m 44s\n",
            "555:\tlearn: 0.8995672\ttotal: 13m 25s\tremaining: 10m 42s\n",
            "556:\tlearn: 0.8995500\ttotal: 13m 26s\tremaining: 10m 41s\n",
            "557:\tlearn: 0.8995158\ttotal: 13m 28s\tremaining: 10m 40s\n",
            "558:\tlearn: 0.8994722\ttotal: 13m 29s\tremaining: 10m 38s\n",
            "559:\tlearn: 0.8994350\ttotal: 13m 31s\tremaining: 10m 37s\n",
            "560:\tlearn: 0.8994033\ttotal: 13m 33s\tremaining: 10m 36s\n",
            "561:\tlearn: 0.8993714\ttotal: 13m 34s\tremaining: 10m 34s\n",
            "562:\tlearn: 0.8993533\ttotal: 13m 36s\tremaining: 10m 33s\n",
            "563:\tlearn: 0.8993194\ttotal: 13m 37s\tremaining: 10m 32s\n",
            "564:\tlearn: 0.8992772\ttotal: 13m 39s\tremaining: 10m 30s\n",
            "565:\tlearn: 0.8992494\ttotal: 13m 40s\tremaining: 10m 29s\n",
            "566:\tlearn: 0.8992194\ttotal: 13m 42s\tremaining: 10m 28s\n",
            "567:\tlearn: 0.8991837\ttotal: 13m 44s\tremaining: 10m 26s\n",
            "568:\tlearn: 0.8991580\ttotal: 13m 45s\tremaining: 10m 25s\n",
            "569:\tlearn: 0.8991261\ttotal: 13m 47s\tremaining: 10m 23s\n",
            "570:\tlearn: 0.8990907\ttotal: 13m 48s\tremaining: 10m 22s\n",
            "571:\tlearn: 0.8990569\ttotal: 13m 50s\tremaining: 10m 21s\n",
            "572:\tlearn: 0.8990314\ttotal: 13m 51s\tremaining: 10m 19s\n",
            "573:\tlearn: 0.8990039\ttotal: 13m 53s\tremaining: 10m 18s\n",
            "574:\tlearn: 0.8989648\ttotal: 13m 55s\tremaining: 10m 17s\n",
            "575:\tlearn: 0.8989407\ttotal: 13m 56s\tremaining: 10m 15s\n",
            "576:\tlearn: 0.8989019\ttotal: 13m 58s\tremaining: 10m 14s\n",
            "577:\tlearn: 0.8988689\ttotal: 13m 59s\tremaining: 10m 13s\n",
            "578:\tlearn: 0.8988366\ttotal: 14m 1s\tremaining: 10m 11s\n",
            "579:\tlearn: 0.8988008\ttotal: 14m 2s\tremaining: 10m 10s\n",
            "580:\tlearn: 0.8987785\ttotal: 14m 4s\tremaining: 10m 8s\n",
            "581:\tlearn: 0.8987637\ttotal: 14m 5s\tremaining: 10m 7s\n",
            "582:\tlearn: 0.8987371\ttotal: 14m 7s\tremaining: 10m 6s\n",
            "583:\tlearn: 0.8987044\ttotal: 14m 9s\tremaining: 10m 4s\n",
            "584:\tlearn: 0.8986645\ttotal: 14m 10s\tremaining: 10m 3s\n",
            "585:\tlearn: 0.8986365\ttotal: 14m 12s\tremaining: 10m 2s\n",
            "586:\tlearn: 0.8986179\ttotal: 14m 13s\tremaining: 10m\n",
            "587:\tlearn: 0.8985871\ttotal: 14m 15s\tremaining: 9m 59s\n",
            "588:\tlearn: 0.8985729\ttotal: 14m 16s\tremaining: 9m 57s\n",
            "589:\tlearn: 0.8985282\ttotal: 14m 18s\tremaining: 9m 56s\n",
            "590:\tlearn: 0.8985119\ttotal: 14m 19s\tremaining: 9m 55s\n",
            "591:\tlearn: 0.8984918\ttotal: 14m 21s\tremaining: 9m 53s\n",
            "592:\tlearn: 0.8984595\ttotal: 14m 22s\tremaining: 9m 52s\n",
            "593:\tlearn: 0.8984315\ttotal: 14m 24s\tremaining: 9m 50s\n",
            "594:\tlearn: 0.8984082\ttotal: 14m 25s\tremaining: 9m 49s\n",
            "595:\tlearn: 0.8983769\ttotal: 14m 27s\tremaining: 9m 48s\n",
            "596:\tlearn: 0.8983315\ttotal: 14m 29s\tremaining: 9m 46s\n",
            "597:\tlearn: 0.8982929\ttotal: 14m 30s\tremaining: 9m 45s\n",
            "598:\tlearn: 0.8982682\ttotal: 14m 32s\tremaining: 9m 44s\n",
            "599:\tlearn: 0.8982378\ttotal: 14m 34s\tremaining: 9m 42s\n",
            "600:\tlearn: 0.8982310\ttotal: 14m 35s\tremaining: 9m 41s\n",
            "601:\tlearn: 0.8981997\ttotal: 14m 37s\tremaining: 9m 39s\n",
            "602:\tlearn: 0.8981815\ttotal: 14m 38s\tremaining: 9m 38s\n",
            "603:\tlearn: 0.8981570\ttotal: 14m 40s\tremaining: 9m 37s\n",
            "604:\tlearn: 0.8981241\ttotal: 14m 41s\tremaining: 9m 35s\n",
            "605:\tlearn: 0.8980909\ttotal: 14m 43s\tremaining: 9m 34s\n",
            "606:\tlearn: 0.8980628\ttotal: 14m 45s\tremaining: 9m 33s\n",
            "607:\tlearn: 0.8980461\ttotal: 14m 46s\tremaining: 9m 31s\n",
            "608:\tlearn: 0.8980364\ttotal: 14m 48s\tremaining: 9m 30s\n",
            "609:\tlearn: 0.8980014\ttotal: 14m 49s\tremaining: 9m 28s\n",
            "610:\tlearn: 0.8979760\ttotal: 14m 51s\tremaining: 9m 27s\n",
            "611:\tlearn: 0.8979511\ttotal: 14m 52s\tremaining: 9m 25s\n",
            "612:\tlearn: 0.8979220\ttotal: 14m 54s\tremaining: 9m 24s\n",
            "613:\tlearn: 0.8978883\ttotal: 14m 55s\tremaining: 9m 23s\n",
            "614:\tlearn: 0.8978587\ttotal: 14m 57s\tremaining: 9m 21s\n",
            "615:\tlearn: 0.8978322\ttotal: 14m 58s\tremaining: 9m 20s\n",
            "616:\tlearn: 0.8978070\ttotal: 15m\tremaining: 9m 18s\n",
            "617:\tlearn: 0.8977947\ttotal: 15m 1s\tremaining: 9m 17s\n",
            "618:\tlearn: 0.8977716\ttotal: 15m 3s\tremaining: 9m 15s\n",
            "619:\tlearn: 0.8977484\ttotal: 15m 4s\tremaining: 9m 14s\n",
            "620:\tlearn: 0.8977300\ttotal: 15m 6s\tremaining: 9m 13s\n",
            "621:\tlearn: 0.8977022\ttotal: 15m 7s\tremaining: 9m 11s\n",
            "622:\tlearn: 0.8976859\ttotal: 15m 9s\tremaining: 9m 10s\n",
            "623:\tlearn: 0.8976674\ttotal: 15m 10s\tremaining: 9m 8s\n",
            "624:\tlearn: 0.8976438\ttotal: 15m 12s\tremaining: 9m 7s\n",
            "625:\tlearn: 0.8976303\ttotal: 15m 13s\tremaining: 9m 6s\n",
            "626:\tlearn: 0.8976061\ttotal: 15m 15s\tremaining: 9m 4s\n",
            "627:\tlearn: 0.8975838\ttotal: 15m 17s\tremaining: 9m 3s\n",
            "628:\tlearn: 0.8975535\ttotal: 15m 18s\tremaining: 9m 1s\n",
            "629:\tlearn: 0.8975169\ttotal: 15m 20s\tremaining: 9m\n",
            "630:\tlearn: 0.8975042\ttotal: 15m 21s\tremaining: 8m 58s\n",
            "631:\tlearn: 0.8974918\ttotal: 15m 22s\tremaining: 8m 57s\n",
            "632:\tlearn: 0.8974698\ttotal: 15m 24s\tremaining: 8m 55s\n",
            "633:\tlearn: 0.8974412\ttotal: 15m 25s\tremaining: 8m 54s\n",
            "634:\tlearn: 0.8974161\ttotal: 15m 27s\tremaining: 8m 53s\n",
            "635:\tlearn: 0.8973800\ttotal: 15m 29s\tremaining: 8m 51s\n",
            "636:\tlearn: 0.8973604\ttotal: 15m 30s\tremaining: 8m 50s\n",
            "637:\tlearn: 0.8973241\ttotal: 15m 32s\tremaining: 8m 48s\n",
            "638:\tlearn: 0.8972984\ttotal: 15m 33s\tremaining: 8m 47s\n",
            "639:\tlearn: 0.8972696\ttotal: 15m 35s\tremaining: 8m 46s\n",
            "640:\tlearn: 0.8972528\ttotal: 15m 36s\tremaining: 8m 44s\n",
            "641:\tlearn: 0.8972199\ttotal: 15m 38s\tremaining: 8m 43s\n",
            "642:\tlearn: 0.8971939\ttotal: 15m 40s\tremaining: 8m 41s\n",
            "643:\tlearn: 0.8971683\ttotal: 15m 41s\tremaining: 8m 40s\n",
            "644:\tlearn: 0.8971509\ttotal: 15m 43s\tremaining: 8m 39s\n",
            "645:\tlearn: 0.8971324\ttotal: 15m 44s\tremaining: 8m 37s\n",
            "646:\tlearn: 0.8971136\ttotal: 15m 46s\tremaining: 8m 36s\n",
            "647:\tlearn: 0.8970883\ttotal: 15m 47s\tremaining: 8m 34s\n",
            "648:\tlearn: 0.8970736\ttotal: 15m 49s\tremaining: 8m 33s\n",
            "649:\tlearn: 0.8970390\ttotal: 15m 51s\tremaining: 8m 32s\n",
            "650:\tlearn: 0.8970163\ttotal: 15m 52s\tremaining: 8m 30s\n",
            "651:\tlearn: 0.8969901\ttotal: 15m 54s\tremaining: 8m 29s\n",
            "652:\tlearn: 0.8969719\ttotal: 15m 55s\tremaining: 8m 27s\n",
            "653:\tlearn: 0.8969524\ttotal: 15m 56s\tremaining: 8m 26s\n",
            "654:\tlearn: 0.8969339\ttotal: 15m 58s\tremaining: 8m 24s\n",
            "655:\tlearn: 0.8969045\ttotal: 15m 59s\tremaining: 8m 23s\n",
            "656:\tlearn: 0.8968755\ttotal: 16m 1s\tremaining: 8m 21s\n",
            "657:\tlearn: 0.8968648\ttotal: 16m 3s\tremaining: 8m 20s\n",
            "658:\tlearn: 0.8968428\ttotal: 16m 4s\tremaining: 8m 19s\n",
            "659:\tlearn: 0.8968097\ttotal: 16m 6s\tremaining: 8m 17s\n",
            "660:\tlearn: 0.8967703\ttotal: 16m 7s\tremaining: 8m 16s\n",
            "661:\tlearn: 0.8967486\ttotal: 16m 9s\tremaining: 8m 14s\n",
            "662:\tlearn: 0.8967309\ttotal: 16m 10s\tremaining: 8m 13s\n",
            "663:\tlearn: 0.8967013\ttotal: 16m 12s\tremaining: 8m 11s\n",
            "664:\tlearn: 0.8966768\ttotal: 16m 13s\tremaining: 8m 10s\n",
            "665:\tlearn: 0.8966598\ttotal: 16m 15s\tremaining: 8m 9s\n",
            "666:\tlearn: 0.8966330\ttotal: 16m 16s\tremaining: 8m 7s\n",
            "667:\tlearn: 0.8966002\ttotal: 16m 18s\tremaining: 8m 6s\n",
            "668:\tlearn: 0.8965837\ttotal: 16m 19s\tremaining: 8m 4s\n",
            "669:\tlearn: 0.8965557\ttotal: 16m 21s\tremaining: 8m 3s\n",
            "670:\tlearn: 0.8965304\ttotal: 16m 23s\tremaining: 8m 1s\n",
            "671:\tlearn: 0.8965099\ttotal: 16m 24s\tremaining: 8m\n",
            "672:\tlearn: 0.8964839\ttotal: 16m 26s\tremaining: 7m 59s\n",
            "673:\tlearn: 0.8964684\ttotal: 16m 27s\tremaining: 7m 57s\n",
            "674:\tlearn: 0.8964342\ttotal: 16m 29s\tremaining: 7m 56s\n",
            "675:\tlearn: 0.8964145\ttotal: 16m 30s\tremaining: 7m 54s\n",
            "676:\tlearn: 0.8963850\ttotal: 16m 32s\tremaining: 7m 53s\n",
            "677:\tlearn: 0.8963651\ttotal: 16m 33s\tremaining: 7m 52s\n",
            "678:\tlearn: 0.8963464\ttotal: 16m 35s\tremaining: 7m 50s\n",
            "679:\tlearn: 0.8963187\ttotal: 16m 36s\tremaining: 7m 49s\n",
            "680:\tlearn: 0.8962946\ttotal: 16m 38s\tremaining: 7m 47s\n",
            "681:\tlearn: 0.8962802\ttotal: 16m 39s\tremaining: 7m 46s\n",
            "682:\tlearn: 0.8962570\ttotal: 16m 41s\tremaining: 7m 44s\n",
            "683:\tlearn: 0.8962402\ttotal: 16m 43s\tremaining: 7m 43s\n",
            "684:\tlearn: 0.8962268\ttotal: 16m 44s\tremaining: 7m 42s\n",
            "685:\tlearn: 0.8962044\ttotal: 16m 46s\tremaining: 7m 40s\n",
            "686:\tlearn: 0.8961876\ttotal: 16m 48s\tremaining: 7m 39s\n",
            "687:\tlearn: 0.8961696\ttotal: 16m 49s\tremaining: 7m 37s\n",
            "688:\tlearn: 0.8961384\ttotal: 16m 51s\tremaining: 7m 36s\n",
            "689:\tlearn: 0.8961236\ttotal: 16m 52s\tremaining: 7m 34s\n",
            "690:\tlearn: 0.8961044\ttotal: 16m 54s\tremaining: 7m 33s\n",
            "691:\tlearn: 0.8960613\ttotal: 16m 55s\tremaining: 7m 32s\n",
            "692:\tlearn: 0.8960427\ttotal: 16m 57s\tremaining: 7m 30s\n",
            "693:\tlearn: 0.8960230\ttotal: 16m 59s\tremaining: 7m 29s\n",
            "694:\tlearn: 0.8960040\ttotal: 17m\tremaining: 7m 27s\n",
            "695:\tlearn: 0.8959835\ttotal: 17m 2s\tremaining: 7m 26s\n",
            "696:\tlearn: 0.8959540\ttotal: 17m 4s\tremaining: 7m 25s\n",
            "697:\tlearn: 0.8959353\ttotal: 17m 5s\tremaining: 7m 23s\n",
            "698:\tlearn: 0.8959126\ttotal: 17m 6s\tremaining: 7m 22s\n",
            "699:\tlearn: 0.8958948\ttotal: 17m 8s\tremaining: 7m 20s\n",
            "700:\tlearn: 0.8958653\ttotal: 17m 9s\tremaining: 7m 19s\n",
            "701:\tlearn: 0.8958471\ttotal: 17m 11s\tremaining: 7m 17s\n",
            "702:\tlearn: 0.8958264\ttotal: 17m 12s\tremaining: 7m 16s\n",
            "703:\tlearn: 0.8958100\ttotal: 17m 13s\tremaining: 7m 14s\n",
            "704:\tlearn: 0.8957795\ttotal: 17m 15s\tremaining: 7m 13s\n",
            "705:\tlearn: 0.8957706\ttotal: 17m 16s\tremaining: 7m 11s\n",
            "706:\tlearn: 0.8957564\ttotal: 17m 18s\tremaining: 7m 10s\n",
            "707:\tlearn: 0.8957169\ttotal: 17m 19s\tremaining: 7m 8s\n",
            "708:\tlearn: 0.8956995\ttotal: 17m 21s\tremaining: 7m 7s\n",
            "709:\tlearn: 0.8956493\ttotal: 17m 22s\tremaining: 7m 5s\n",
            "710:\tlearn: 0.8956334\ttotal: 17m 24s\tremaining: 7m 4s\n",
            "711:\tlearn: 0.8955931\ttotal: 17m 25s\tremaining: 7m 3s\n",
            "712:\tlearn: 0.8955778\ttotal: 17m 27s\tremaining: 7m 1s\n",
            "713:\tlearn: 0.8955578\ttotal: 17m 29s\tremaining: 7m\n",
            "714:\tlearn: 0.8955311\ttotal: 17m 30s\tremaining: 6m 58s\n",
            "715:\tlearn: 0.8955100\ttotal: 17m 32s\tremaining: 6m 57s\n",
            "716:\tlearn: 0.8954975\ttotal: 17m 33s\tremaining: 6m 55s\n",
            "717:\tlearn: 0.8954746\ttotal: 17m 35s\tremaining: 6m 54s\n",
            "718:\tlearn: 0.8954610\ttotal: 17m 37s\tremaining: 6m 53s\n",
            "719:\tlearn: 0.8954407\ttotal: 17m 38s\tremaining: 6m 51s\n",
            "720:\tlearn: 0.8954162\ttotal: 17m 40s\tremaining: 6m 50s\n",
            "721:\tlearn: 0.8953880\ttotal: 17m 41s\tremaining: 6m 48s\n",
            "722:\tlearn: 0.8953764\ttotal: 17m 42s\tremaining: 6m 47s\n",
            "723:\tlearn: 0.8953453\ttotal: 17m 44s\tremaining: 6m 45s\n",
            "724:\tlearn: 0.8953120\ttotal: 17m 45s\tremaining: 6m 44s\n",
            "725:\tlearn: 0.8953025\ttotal: 17m 46s\tremaining: 6m 42s\n",
            "726:\tlearn: 0.8952759\ttotal: 17m 48s\tremaining: 6m 41s\n",
            "727:\tlearn: 0.8952540\ttotal: 17m 50s\tremaining: 6m 39s\n",
            "728:\tlearn: 0.8952309\ttotal: 17m 51s\tremaining: 6m 38s\n",
            "729:\tlearn: 0.8952129\ttotal: 17m 53s\tremaining: 6m 37s\n",
            "730:\tlearn: 0.8951961\ttotal: 17m 55s\tremaining: 6m 35s\n",
            "731:\tlearn: 0.8951696\ttotal: 17m 56s\tremaining: 6m 34s\n",
            "732:\tlearn: 0.8951449\ttotal: 17m 58s\tremaining: 6m 32s\n",
            "733:\tlearn: 0.8951145\ttotal: 17m 59s\tremaining: 6m 31s\n",
            "734:\tlearn: 0.8950977\ttotal: 18m 1s\tremaining: 6m 29s\n",
            "735:\tlearn: 0.8950906\ttotal: 18m 2s\tremaining: 6m 28s\n",
            "736:\tlearn: 0.8950509\ttotal: 18m 4s\tremaining: 6m 27s\n",
            "737:\tlearn: 0.8950171\ttotal: 18m 6s\tremaining: 6m 25s\n",
            "738:\tlearn: 0.8949894\ttotal: 18m 7s\tremaining: 6m 24s\n",
            "739:\tlearn: 0.8949637\ttotal: 18m 9s\tremaining: 6m 22s\n",
            "740:\tlearn: 0.8949542\ttotal: 18m 11s\tremaining: 6m 21s\n",
            "741:\tlearn: 0.8949400\ttotal: 18m 12s\tremaining: 6m 19s\n",
            "742:\tlearn: 0.8949125\ttotal: 18m 14s\tremaining: 6m 18s\n",
            "743:\tlearn: 0.8949026\ttotal: 18m 15s\tremaining: 6m 17s\n",
            "744:\tlearn: 0.8948857\ttotal: 18m 17s\tremaining: 6m 15s\n",
            "745:\tlearn: 0.8948640\ttotal: 18m 18s\tremaining: 6m 14s\n",
            "746:\tlearn: 0.8948429\ttotal: 18m 20s\tremaining: 6m 12s\n",
            "747:\tlearn: 0.8948277\ttotal: 18m 21s\tremaining: 6m 11s\n",
            "748:\tlearn: 0.8948029\ttotal: 18m 23s\tremaining: 6m 9s\n",
            "749:\tlearn: 0.8947836\ttotal: 18m 24s\tremaining: 6m 8s\n",
            "750:\tlearn: 0.8947638\ttotal: 18m 26s\tremaining: 6m 6s\n",
            "751:\tlearn: 0.8947487\ttotal: 18m 27s\tremaining: 6m 5s\n",
            "752:\tlearn: 0.8947339\ttotal: 18m 29s\tremaining: 6m 3s\n",
            "753:\tlearn: 0.8947122\ttotal: 18m 30s\tremaining: 6m 2s\n",
            "754:\tlearn: 0.8946808\ttotal: 18m 31s\tremaining: 6m\n",
            "755:\tlearn: 0.8946553\ttotal: 18m 33s\tremaining: 5m 59s\n",
            "756:\tlearn: 0.8946394\ttotal: 18m 34s\tremaining: 5m 57s\n",
            "757:\tlearn: 0.8946255\ttotal: 18m 36s\tremaining: 5m 56s\n",
            "758:\tlearn: 0.8946074\ttotal: 18m 37s\tremaining: 5m 54s\n",
            "759:\tlearn: 0.8945736\ttotal: 18m 39s\tremaining: 5m 53s\n",
            "760:\tlearn: 0.8945508\ttotal: 18m 40s\tremaining: 5m 51s\n",
            "761:\tlearn: 0.8945342\ttotal: 18m 42s\tremaining: 5m 50s\n",
            "762:\tlearn: 0.8945091\ttotal: 18m 43s\tremaining: 5m 48s\n",
            "763:\tlearn: 0.8944954\ttotal: 18m 45s\tremaining: 5m 47s\n",
            "764:\tlearn: 0.8944827\ttotal: 18m 46s\tremaining: 5m 46s\n",
            "765:\tlearn: 0.8944590\ttotal: 18m 48s\tremaining: 5m 44s\n",
            "766:\tlearn: 0.8944428\ttotal: 18m 49s\tremaining: 5m 43s\n",
            "767:\tlearn: 0.8944203\ttotal: 18m 51s\tremaining: 5m 41s\n",
            "768:\tlearn: 0.8944091\ttotal: 18m 52s\tremaining: 5m 40s\n",
            "769:\tlearn: 0.8943869\ttotal: 18m 54s\tremaining: 5m 38s\n",
            "770:\tlearn: 0.8943673\ttotal: 18m 55s\tremaining: 5m 37s\n",
            "771:\tlearn: 0.8943570\ttotal: 18m 56s\tremaining: 5m 35s\n",
            "772:\tlearn: 0.8943305\ttotal: 18m 58s\tremaining: 5m 34s\n",
            "773:\tlearn: 0.8943173\ttotal: 18m 59s\tremaining: 5m 32s\n",
            "774:\tlearn: 0.8943020\ttotal: 19m\tremaining: 5m 31s\n",
            "775:\tlearn: 0.8942828\ttotal: 19m 2s\tremaining: 5m 29s\n",
            "776:\tlearn: 0.8942562\ttotal: 19m 4s\tremaining: 5m 28s\n",
            "777:\tlearn: 0.8942311\ttotal: 19m 5s\tremaining: 5m 26s\n",
            "778:\tlearn: 0.8942208\ttotal: 19m 7s\tremaining: 5m 25s\n",
            "779:\tlearn: 0.8942040\ttotal: 19m 8s\tremaining: 5m 24s\n",
            "780:\tlearn: 0.8941906\ttotal: 19m 10s\tremaining: 5m 22s\n",
            "781:\tlearn: 0.8941692\ttotal: 19m 11s\tremaining: 5m 21s\n",
            "782:\tlearn: 0.8941483\ttotal: 19m 13s\tremaining: 5m 19s\n",
            "783:\tlearn: 0.8941170\ttotal: 19m 15s\tremaining: 5m 18s\n",
            "784:\tlearn: 0.8941025\ttotal: 19m 16s\tremaining: 5m 16s\n",
            "785:\tlearn: 0.8940823\ttotal: 19m 18s\tremaining: 5m 15s\n",
            "786:\tlearn: 0.8940626\ttotal: 19m 19s\tremaining: 5m 13s\n",
            "787:\tlearn: 0.8940462\ttotal: 19m 20s\tremaining: 5m 12s\n",
            "788:\tlearn: 0.8940292\ttotal: 19m 22s\tremaining: 5m 10s\n",
            "789:\tlearn: 0.8940130\ttotal: 19m 24s\tremaining: 5m 9s\n",
            "790:\tlearn: 0.8939947\ttotal: 19m 25s\tremaining: 5m 7s\n",
            "791:\tlearn: 0.8939792\ttotal: 19m 27s\tremaining: 5m 6s\n",
            "792:\tlearn: 0.8939560\ttotal: 19m 28s\tremaining: 5m 5s\n",
            "793:\tlearn: 0.8939288\ttotal: 19m 30s\tremaining: 5m 3s\n",
            "794:\tlearn: 0.8939114\ttotal: 19m 31s\tremaining: 5m 2s\n",
            "795:\tlearn: 0.8938956\ttotal: 19m 33s\tremaining: 5m\n",
            "796:\tlearn: 0.8938760\ttotal: 19m 34s\tremaining: 4m 59s\n",
            "797:\tlearn: 0.8938573\ttotal: 19m 36s\tremaining: 4m 57s\n",
            "798:\tlearn: 0.8938408\ttotal: 19m 37s\tremaining: 4m 56s\n",
            "799:\tlearn: 0.8938137\ttotal: 19m 39s\tremaining: 4m 54s\n",
            "800:\tlearn: 0.8937863\ttotal: 19m 40s\tremaining: 4m 53s\n",
            "801:\tlearn: 0.8937688\ttotal: 19m 42s\tremaining: 4m 51s\n",
            "802:\tlearn: 0.8937624\ttotal: 19m 43s\tremaining: 4m 50s\n",
            "803:\tlearn: 0.8937449\ttotal: 19m 45s\tremaining: 4m 48s\n",
            "804:\tlearn: 0.8937236\ttotal: 19m 46s\tremaining: 4m 47s\n",
            "805:\tlearn: 0.8937086\ttotal: 19m 47s\tremaining: 4m 45s\n",
            "806:\tlearn: 0.8936945\ttotal: 19m 49s\tremaining: 4m 44s\n",
            "807:\tlearn: 0.8936657\ttotal: 19m 50s\tremaining: 4m 42s\n",
            "808:\tlearn: 0.8936456\ttotal: 19m 52s\tremaining: 4m 41s\n",
            "809:\tlearn: 0.8936240\ttotal: 19m 54s\tremaining: 4m 40s\n",
            "810:\tlearn: 0.8936100\ttotal: 19m 55s\tremaining: 4m 38s\n",
            "811:\tlearn: 0.8935988\ttotal: 19m 57s\tremaining: 4m 37s\n",
            "812:\tlearn: 0.8935882\ttotal: 19m 58s\tremaining: 4m 35s\n",
            "813:\tlearn: 0.8935679\ttotal: 20m\tremaining: 4m 34s\n",
            "814:\tlearn: 0.8935403\ttotal: 20m 1s\tremaining: 4m 32s\n",
            "815:\tlearn: 0.8935133\ttotal: 20m 3s\tremaining: 4m 31s\n",
            "816:\tlearn: 0.8934939\ttotal: 20m 4s\tremaining: 4m 29s\n",
            "817:\tlearn: 0.8934784\ttotal: 20m 6s\tremaining: 4m 28s\n",
            "818:\tlearn: 0.8934560\ttotal: 20m 7s\tremaining: 4m 26s\n",
            "819:\tlearn: 0.8934344\ttotal: 20m 9s\tremaining: 4m 25s\n",
            "820:\tlearn: 0.8934113\ttotal: 20m 10s\tremaining: 4m 23s\n",
            "821:\tlearn: 0.8933897\ttotal: 20m 12s\tremaining: 4m 22s\n",
            "822:\tlearn: 0.8933697\ttotal: 20m 13s\tremaining: 4m 21s\n",
            "823:\tlearn: 0.8933543\ttotal: 20m 14s\tremaining: 4m 19s\n",
            "824:\tlearn: 0.8933392\ttotal: 20m 16s\tremaining: 4m 18s\n",
            "825:\tlearn: 0.8933286\ttotal: 20m 18s\tremaining: 4m 16s\n",
            "826:\tlearn: 0.8933099\ttotal: 20m 19s\tremaining: 4m 15s\n",
            "827:\tlearn: 0.8932684\ttotal: 20m 21s\tremaining: 4m 13s\n",
            "828:\tlearn: 0.8932623\ttotal: 20m 22s\tremaining: 4m 12s\n",
            "829:\tlearn: 0.8932506\ttotal: 20m 24s\tremaining: 4m 10s\n",
            "830:\tlearn: 0.8932198\ttotal: 20m 25s\tremaining: 4m 9s\n",
            "831:\tlearn: 0.8932002\ttotal: 20m 27s\tremaining: 4m 7s\n",
            "832:\tlearn: 0.8931893\ttotal: 20m 28s\tremaining: 4m 6s\n",
            "833:\tlearn: 0.8931739\ttotal: 20m 30s\tremaining: 4m 4s\n",
            "834:\tlearn: 0.8931376\ttotal: 20m 31s\tremaining: 4m 3s\n",
            "835:\tlearn: 0.8931247\ttotal: 20m 33s\tremaining: 4m 1s\n",
            "836:\tlearn: 0.8931095\ttotal: 20m 34s\tremaining: 4m\n",
            "837:\tlearn: 0.8930895\ttotal: 20m 36s\tremaining: 3m 59s\n",
            "838:\tlearn: 0.8930756\ttotal: 20m 38s\tremaining: 3m 57s\n",
            "839:\tlearn: 0.8930575\ttotal: 20m 39s\tremaining: 3m 56s\n",
            "840:\tlearn: 0.8930469\ttotal: 20m 40s\tremaining: 3m 54s\n",
            "841:\tlearn: 0.8930264\ttotal: 20m 42s\tremaining: 3m 53s\n",
            "842:\tlearn: 0.8930100\ttotal: 20m 44s\tremaining: 3m 51s\n",
            "843:\tlearn: 0.8929744\ttotal: 20m 45s\tremaining: 3m 50s\n",
            "844:\tlearn: 0.8929512\ttotal: 20m 47s\tremaining: 3m 48s\n",
            "845:\tlearn: 0.8929239\ttotal: 20m 48s\tremaining: 3m 47s\n",
            "846:\tlearn: 0.8929057\ttotal: 20m 50s\tremaining: 3m 45s\n",
            "847:\tlearn: 0.8928911\ttotal: 20m 51s\tremaining: 3m 44s\n",
            "848:\tlearn: 0.8928799\ttotal: 20m 53s\tremaining: 3m 42s\n",
            "849:\tlearn: 0.8928680\ttotal: 20m 54s\tremaining: 3m 41s\n",
            "850:\tlearn: 0.8928483\ttotal: 20m 55s\tremaining: 3m 39s\n",
            "851:\tlearn: 0.8928331\ttotal: 20m 57s\tremaining: 3m 38s\n",
            "852:\tlearn: 0.8928125\ttotal: 20m 58s\tremaining: 3m 36s\n",
            "853:\tlearn: 0.8927988\ttotal: 21m\tremaining: 3m 35s\n",
            "854:\tlearn: 0.8927816\ttotal: 21m 1s\tremaining: 3m 34s\n",
            "855:\tlearn: 0.8927688\ttotal: 21m 3s\tremaining: 3m 32s\n",
            "856:\tlearn: 0.8927431\ttotal: 21m 5s\tremaining: 3m 31s\n",
            "857:\tlearn: 0.8927266\ttotal: 21m 6s\tremaining: 3m 29s\n",
            "858:\tlearn: 0.8927125\ttotal: 21m 8s\tremaining: 3m 28s\n",
            "859:\tlearn: 0.8926938\ttotal: 21m 10s\tremaining: 3m 26s\n",
            "860:\tlearn: 0.8926814\ttotal: 21m 11s\tremaining: 3m 25s\n",
            "861:\tlearn: 0.8926586\ttotal: 21m 13s\tremaining: 3m 23s\n",
            "862:\tlearn: 0.8926523\ttotal: 21m 14s\tremaining: 3m 22s\n",
            "863:\tlearn: 0.8926269\ttotal: 21m 16s\tremaining: 3m 20s\n",
            "864:\tlearn: 0.8926194\ttotal: 21m 17s\tremaining: 3m 19s\n",
            "865:\tlearn: 0.8926006\ttotal: 21m 19s\tremaining: 3m 17s\n",
            "866:\tlearn: 0.8925913\ttotal: 21m 20s\tremaining: 3m 16s\n",
            "867:\tlearn: 0.8925706\ttotal: 21m 22s\tremaining: 3m 15s\n",
            "868:\tlearn: 0.8925645\ttotal: 21m 23s\tremaining: 3m 13s\n",
            "869:\tlearn: 0.8925454\ttotal: 21m 25s\tremaining: 3m 12s\n",
            "870:\tlearn: 0.8925176\ttotal: 21m 26s\tremaining: 3m 10s\n",
            "871:\tlearn: 0.8925050\ttotal: 21m 27s\tremaining: 3m 9s\n",
            "872:\tlearn: 0.8924881\ttotal: 21m 29s\tremaining: 3m 7s\n",
            "873:\tlearn: 0.8924805\ttotal: 21m 30s\tremaining: 3m 5s\n",
            "874:\tlearn: 0.8924611\ttotal: 21m 31s\tremaining: 3m 4s\n",
            "875:\tlearn: 0.8924456\ttotal: 21m 33s\tremaining: 3m 3s\n",
            "876:\tlearn: 0.8924249\ttotal: 21m 34s\tremaining: 3m 1s\n",
            "877:\tlearn: 0.8924110\ttotal: 21m 36s\tremaining: 3m\n",
            "878:\tlearn: 0.8923876\ttotal: 21m 37s\tremaining: 2m 58s\n",
            "879:\tlearn: 0.8923714\ttotal: 21m 39s\tremaining: 2m 57s\n",
            "880:\tlearn: 0.8923586\ttotal: 21m 40s\tremaining: 2m 55s\n",
            "881:\tlearn: 0.8923399\ttotal: 21m 42s\tremaining: 2m 54s\n",
            "882:\tlearn: 0.8923244\ttotal: 21m 43s\tremaining: 2m 52s\n",
            "883:\tlearn: 0.8922998\ttotal: 21m 45s\tremaining: 2m 51s\n",
            "884:\tlearn: 0.8922715\ttotal: 21m 47s\tremaining: 2m 49s\n",
            "885:\tlearn: 0.8922567\ttotal: 21m 48s\tremaining: 2m 48s\n",
            "886:\tlearn: 0.8922420\ttotal: 21m 50s\tremaining: 2m 46s\n",
            "887:\tlearn: 0.8922341\ttotal: 21m 51s\tremaining: 2m 45s\n",
            "888:\tlearn: 0.8922231\ttotal: 21m 52s\tremaining: 2m 43s\n",
            "889:\tlearn: 0.8922103\ttotal: 21m 54s\tremaining: 2m 42s\n",
            "890:\tlearn: 0.8921875\ttotal: 21m 56s\tremaining: 2m 41s\n",
            "891:\tlearn: 0.8921791\ttotal: 21m 57s\tremaining: 2m 39s\n",
            "892:\tlearn: 0.8921720\ttotal: 21m 59s\tremaining: 2m 38s\n",
            "893:\tlearn: 0.8921636\ttotal: 22m\tremaining: 2m 36s\n",
            "894:\tlearn: 0.8921446\ttotal: 22m 2s\tremaining: 2m 35s\n",
            "895:\tlearn: 0.8921156\ttotal: 22m 3s\tremaining: 2m 33s\n",
            "896:\tlearn: 0.8921009\ttotal: 22m 5s\tremaining: 2m 32s\n",
            "897:\tlearn: 0.8920908\ttotal: 22m 6s\tremaining: 2m 30s\n",
            "898:\tlearn: 0.8920803\ttotal: 22m 8s\tremaining: 2m 29s\n",
            "899:\tlearn: 0.8920541\ttotal: 22m 9s\tremaining: 2m 27s\n",
            "900:\tlearn: 0.8920408\ttotal: 22m 11s\tremaining: 2m 26s\n",
            "901:\tlearn: 0.8920259\ttotal: 22m 12s\tremaining: 2m 24s\n",
            "902:\tlearn: 0.8920148\ttotal: 22m 13s\tremaining: 2m 23s\n",
            "903:\tlearn: 0.8919981\ttotal: 22m 15s\tremaining: 2m 21s\n",
            "904:\tlearn: 0.8919880\ttotal: 22m 16s\tremaining: 2m 20s\n",
            "905:\tlearn: 0.8919712\ttotal: 22m 17s\tremaining: 2m 18s\n",
            "906:\tlearn: 0.8919627\ttotal: 22m 19s\tremaining: 2m 17s\n",
            "907:\tlearn: 0.8919490\ttotal: 22m 21s\tremaining: 2m 15s\n",
            "908:\tlearn: 0.8919388\ttotal: 22m 22s\tremaining: 2m 14s\n",
            "909:\tlearn: 0.8919237\ttotal: 22m 24s\tremaining: 2m 12s\n",
            "910:\tlearn: 0.8919093\ttotal: 22m 25s\tremaining: 2m 11s\n",
            "911:\tlearn: 0.8919010\ttotal: 22m 27s\tremaining: 2m 9s\n",
            "912:\tlearn: 0.8918821\ttotal: 22m 28s\tremaining: 2m 8s\n",
            "913:\tlearn: 0.8918654\ttotal: 22m 30s\tremaining: 2m 7s\n",
            "914:\tlearn: 0.8918505\ttotal: 22m 31s\tremaining: 2m 5s\n",
            "915:\tlearn: 0.8918307\ttotal: 22m 33s\tremaining: 2m 4s\n",
            "916:\tlearn: 0.8918211\ttotal: 22m 34s\tremaining: 2m 2s\n",
            "917:\tlearn: 0.8918116\ttotal: 22m 35s\tremaining: 2m 1s\n",
            "918:\tlearn: 0.8917914\ttotal: 22m 37s\tremaining: 1m 59s\n",
            "919:\tlearn: 0.8917800\ttotal: 22m 38s\tremaining: 1m 58s\n",
            "920:\tlearn: 0.8917652\ttotal: 22m 40s\tremaining: 1m 56s\n",
            "921:\tlearn: 0.8917490\ttotal: 22m 41s\tremaining: 1m 55s\n",
            "922:\tlearn: 0.8917333\ttotal: 22m 43s\tremaining: 1m 53s\n",
            "923:\tlearn: 0.8917222\ttotal: 22m 44s\tremaining: 1m 52s\n",
            "924:\tlearn: 0.8917195\ttotal: 22m 46s\tremaining: 1m 50s\n",
            "925:\tlearn: 0.8917062\ttotal: 22m 47s\tremaining: 1m 49s\n",
            "926:\tlearn: 0.8916936\ttotal: 22m 48s\tremaining: 1m 47s\n",
            "927:\tlearn: 0.8916807\ttotal: 22m 50s\tremaining: 1m 46s\n",
            "928:\tlearn: 0.8916411\ttotal: 22m 51s\tremaining: 1m 44s\n",
            "929:\tlearn: 0.8916225\ttotal: 22m 53s\tremaining: 1m 43s\n",
            "930:\tlearn: 0.8915965\ttotal: 22m 54s\tremaining: 1m 41s\n",
            "931:\tlearn: 0.8915904\ttotal: 22m 56s\tremaining: 1m 40s\n",
            "932:\tlearn: 0.8915819\ttotal: 22m 57s\tremaining: 1m 38s\n",
            "933:\tlearn: 0.8915688\ttotal: 22m 58s\tremaining: 1m 37s\n",
            "934:\tlearn: 0.8915600\ttotal: 23m\tremaining: 1m 35s\n",
            "935:\tlearn: 0.8915384\ttotal: 23m 1s\tremaining: 1m 34s\n",
            "936:\tlearn: 0.8915156\ttotal: 23m 3s\tremaining: 1m 33s\n",
            "937:\tlearn: 0.8915051\ttotal: 23m 4s\tremaining: 1m 31s\n",
            "938:\tlearn: 0.8914836\ttotal: 23m 6s\tremaining: 1m 30s\n",
            "939:\tlearn: 0.8914586\ttotal: 23m 7s\tremaining: 1m 28s\n",
            "940:\tlearn: 0.8914496\ttotal: 23m 9s\tremaining: 1m 27s\n",
            "941:\tlearn: 0.8914296\ttotal: 23m 11s\tremaining: 1m 25s\n",
            "942:\tlearn: 0.8914106\ttotal: 23m 12s\tremaining: 1m 24s\n",
            "943:\tlearn: 0.8913954\ttotal: 23m 14s\tremaining: 1m 22s\n",
            "944:\tlearn: 0.8913797\ttotal: 23m 15s\tremaining: 1m 21s\n",
            "945:\tlearn: 0.8913693\ttotal: 23m 17s\tremaining: 1m 19s\n",
            "946:\tlearn: 0.8913542\ttotal: 23m 18s\tremaining: 1m 18s\n",
            "947:\tlearn: 0.8913353\ttotal: 23m 19s\tremaining: 1m 16s\n",
            "948:\tlearn: 0.8913195\ttotal: 23m 21s\tremaining: 1m 15s\n",
            "949:\tlearn: 0.8913055\ttotal: 23m 22s\tremaining: 1m 13s\n",
            "950:\tlearn: 0.8912890\ttotal: 23m 24s\tremaining: 1m 12s\n",
            "951:\tlearn: 0.8912758\ttotal: 23m 25s\tremaining: 1m 10s\n",
            "952:\tlearn: 0.8912622\ttotal: 23m 26s\tremaining: 1m 9s\n",
            "953:\tlearn: 0.8912468\ttotal: 23m 28s\tremaining: 1m 7s\n",
            "954:\tlearn: 0.8912224\ttotal: 23m 29s\tremaining: 1m 6s\n",
            "955:\tlearn: 0.8912014\ttotal: 23m 31s\tremaining: 1m 4s\n",
            "956:\tlearn: 0.8911830\ttotal: 23m 32s\tremaining: 1m 3s\n",
            "957:\tlearn: 0.8911666\ttotal: 23m 34s\tremaining: 1m 1s\n",
            "958:\tlearn: 0.8911538\ttotal: 23m 35s\tremaining: 1m\n",
            "959:\tlearn: 0.8911312\ttotal: 23m 36s\tremaining: 59s\n",
            "960:\tlearn: 0.8911051\ttotal: 23m 38s\tremaining: 57.6s\n",
            "961:\tlearn: 0.8910861\ttotal: 23m 40s\tremaining: 56.1s\n",
            "962:\tlearn: 0.8910697\ttotal: 23m 41s\tremaining: 54.6s\n",
            "963:\tlearn: 0.8910503\ttotal: 23m 43s\tremaining: 53.2s\n",
            "964:\tlearn: 0.8910206\ttotal: 23m 45s\tremaining: 51.7s\n",
            "965:\tlearn: 0.8910075\ttotal: 23m 46s\tremaining: 50.2s\n",
            "966:\tlearn: 0.8909916\ttotal: 23m 47s\tremaining: 48.7s\n",
            "967:\tlearn: 0.8909710\ttotal: 23m 49s\tremaining: 47.3s\n",
            "968:\tlearn: 0.8909508\ttotal: 23m 51s\tremaining: 45.8s\n",
            "969:\tlearn: 0.8909236\ttotal: 23m 52s\tremaining: 44.3s\n",
            "970:\tlearn: 0.8909105\ttotal: 23m 53s\tremaining: 42.8s\n",
            "971:\tlearn: 0.8908972\ttotal: 23m 55s\tremaining: 41.3s\n",
            "972:\tlearn: 0.8908888\ttotal: 23m 56s\tremaining: 39.9s\n",
            "973:\tlearn: 0.8908716\ttotal: 23m 57s\tremaining: 38.4s\n",
            "974:\tlearn: 0.8908535\ttotal: 23m 59s\tremaining: 36.9s\n",
            "975:\tlearn: 0.8908440\ttotal: 24m\tremaining: 35.4s\n",
            "976:\tlearn: 0.8908234\ttotal: 24m 2s\tremaining: 34s\n",
            "977:\tlearn: 0.8908139\ttotal: 24m 3s\tremaining: 32.5s\n",
            "978:\tlearn: 0.8907944\ttotal: 24m 5s\tremaining: 31s\n",
            "979:\tlearn: 0.8907797\ttotal: 24m 6s\tremaining: 29.5s\n",
            "980:\tlearn: 0.8907595\ttotal: 24m 7s\tremaining: 28s\n",
            "981:\tlearn: 0.8907481\ttotal: 24m 9s\tremaining: 26.6s\n",
            "982:\tlearn: 0.8907348\ttotal: 24m 10s\tremaining: 25.1s\n",
            "983:\tlearn: 0.8907088\ttotal: 24m 12s\tremaining: 23.6s\n",
            "984:\tlearn: 0.8906826\ttotal: 24m 14s\tremaining: 22.1s\n",
            "985:\tlearn: 0.8906699\ttotal: 24m 15s\tremaining: 20.7s\n",
            "986:\tlearn: 0.8906561\ttotal: 24m 17s\tremaining: 19.2s\n",
            "987:\tlearn: 0.8906283\ttotal: 24m 18s\tremaining: 17.7s\n",
            "988:\tlearn: 0.8906086\ttotal: 24m 20s\tremaining: 16.2s\n",
            "989:\tlearn: 0.8905946\ttotal: 24m 21s\tremaining: 14.8s\n",
            "990:\tlearn: 0.8905733\ttotal: 24m 23s\tremaining: 13.3s\n",
            "991:\tlearn: 0.8905573\ttotal: 24m 24s\tremaining: 11.8s\n",
            "992:\tlearn: 0.8905437\ttotal: 24m 25s\tremaining: 10.3s\n",
            "993:\tlearn: 0.8905327\ttotal: 24m 27s\tremaining: 8.86s\n",
            "994:\tlearn: 0.8905172\ttotal: 24m 28s\tremaining: 7.38s\n",
            "995:\tlearn: 0.8905003\ttotal: 24m 30s\tremaining: 5.9s\n",
            "996:\tlearn: 0.8904826\ttotal: 24m 31s\tremaining: 4.43s\n",
            "997:\tlearn: 0.8904603\ttotal: 24m 33s\tremaining: 2.95s\n",
            "998:\tlearn: 0.8904478\ttotal: 24m 34s\tremaining: 1.48s\n",
            "999:\tlearn: 0.8904259\ttotal: 24m 36s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fa1e5c39fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIoS0hI_qLPf",
        "colab_type": "code",
        "outputId": "44415242-ee66-4bf7-bcfa-59b329ac68d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "y_pred = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,y_pred))\n",
        "print(confusion_matrix(y_valid,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.23      0.51      0.31     17217\n",
            "        Okay       0.17      0.62      0.26      8730\n",
            "        Poor       0.95      0.62      0.75    132815\n",
            "\n",
            "    accuracy                           0.61    158762\n",
            "   macro avg       0.45      0.58      0.44    158762\n",
            "weighted avg       0.82      0.61      0.68    158762\n",
            "\n",
            "[[ 8703  4759  3755]\n",
            " [ 2248  5416  1066]\n",
            " [27267 22629 82919]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiGkDGGKz6jg",
        "colab_type": "text"
      },
      "source": [
        "Cat Boost with MultiClass Loss function, AUC as metric and iterations = 60, max_depth = 15, learning_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_F3cX5cX2pq",
        "colab_type": "code",
        "outputId": "ac93adfe-db17-473a-8cdc-137ce0ade7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = CatBoostClassifier(random_seed=42,loss_function='MultiClass',eval_metric = 'AUC',class_weights=sample_weights_data,early_stopping_rounds=2,iterations=60, max_depth=15, learning_rate=0.1)\n",
        "clf.fit(X_train, y_train, cat_features=cate_features_index )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\ttotal: 28.4s\tremaining: 27m 53s\n",
            "1:\ttotal: 58.5s\tremaining: 28m 16s\n",
            "2:\ttotal: 1m 31s\tremaining: 28m 58s\n",
            "3:\ttotal: 2m 6s\tremaining: 29m 24s\n",
            "4:\ttotal: 2m 41s\tremaining: 29m 41s\n",
            "5:\ttotal: 3m 18s\tremaining: 29m 47s\n",
            "6:\ttotal: 3m 56s\tremaining: 29m 50s\n",
            "7:\ttotal: 4m 35s\tremaining: 29m 48s\n",
            "8:\ttotal: 5m 14s\tremaining: 29m 43s\n",
            "9:\ttotal: 5m 55s\tremaining: 29m 35s\n",
            "10:\ttotal: 6m 35s\tremaining: 29m 23s\n",
            "11:\ttotal: 7m 17s\tremaining: 29m 9s\n",
            "12:\ttotal: 7m 58s\tremaining: 28m 51s\n",
            "13:\ttotal: 8m 41s\tremaining: 28m 32s\n",
            "14:\ttotal: 9m 23s\tremaining: 28m 9s\n",
            "15:\ttotal: 10m 6s\tremaining: 27m 47s\n",
            "16:\ttotal: 10m 50s\tremaining: 27m 24s\n",
            "17:\ttotal: 11m 33s\tremaining: 26m 58s\n",
            "18:\ttotal: 12m 17s\tremaining: 26m 31s\n",
            "19:\ttotal: 13m 1s\tremaining: 26m 2s\n",
            "20:\ttotal: 13m 44s\tremaining: 25m 31s\n",
            "21:\ttotal: 14m 28s\tremaining: 25m\n",
            "22:\ttotal: 14m 29s\tremaining: 23m 18s\n",
            "23:\ttotal: 15m 14s\tremaining: 22m 51s\n",
            "24:\ttotal: 15m 59s\tremaining: 22m 23s\n",
            "25:\ttotal: 16m 44s\tremaining: 21m 53s\n",
            "26:\ttotal: 17m 28s\tremaining: 21m 22s\n",
            "27:\ttotal: 18m 13s\tremaining: 20m 49s\n",
            "28:\ttotal: 18m 58s\tremaining: 20m 17s\n",
            "29:\ttotal: 19m 43s\tremaining: 19m 43s\n",
            "30:\ttotal: 20m 27s\tremaining: 19m 8s\n",
            "31:\ttotal: 21m 13s\tremaining: 18m 34s\n",
            "32:\ttotal: 21m 57s\tremaining: 17m 57s\n",
            "33:\ttotal: 22m 42s\tremaining: 17m 21s\n",
            "34:\ttotal: 23m 26s\tremaining: 16m 44s\n",
            "35:\ttotal: 24m 11s\tremaining: 16m 7s\n",
            "36:\ttotal: 24m 56s\tremaining: 15m 30s\n",
            "37:\ttotal: 25m 42s\tremaining: 14m 53s\n",
            "38:\ttotal: 26m 28s\tremaining: 14m 15s\n",
            "39:\ttotal: 27m 13s\tremaining: 13m 36s\n",
            "40:\ttotal: 27m 59s\tremaining: 12m 58s\n",
            "41:\ttotal: 28m 45s\tremaining: 12m 19s\n",
            "42:\ttotal: 29m 29s\tremaining: 11m 39s\n",
            "43:\ttotal: 30m 14s\tremaining: 10m 59s\n",
            "44:\ttotal: 30m 59s\tremaining: 10m 19s\n",
            "45:\ttotal: 31m 46s\tremaining: 9m 40s\n",
            "46:\ttotal: 32m 31s\tremaining: 8m 59s\n",
            "47:\ttotal: 33m 17s\tremaining: 8m 19s\n",
            "48:\ttotal: 34m 2s\tremaining: 7m 38s\n",
            "49:\ttotal: 34m 47s\tremaining: 6m 57s\n",
            "50:\ttotal: 35m 34s\tremaining: 6m 16s\n",
            "51:\ttotal: 35m 34s\tremaining: 5m 28s\n",
            "52:\ttotal: 35m 35s\tremaining: 4m 42s\n",
            "53:\ttotal: 36m 20s\tremaining: 4m 2s\n",
            "54:\ttotal: 37m 5s\tremaining: 3m 22s\n",
            "55:\ttotal: 37m 6s\tremaining: 2m 39s\n",
            "56:\ttotal: 37m 50s\tremaining: 1m 59s\n",
            "57:\ttotal: 38m 35s\tremaining: 1m 19s\n",
            "58:\ttotal: 39m 22s\tremaining: 40s\n",
            "59:\ttotal: 40m 7s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f9c25091c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jV00ffi-erz",
        "colab_type": "code",
        "outputId": "5e8104a7-ad67-412d-be95-4112246fc93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "y_pred = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,y_pred))\n",
        "print(confusion_matrix(y_valid,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.22      0.50      0.31     17217\n",
            "        Okay       0.16      0.61      0.26      8730\n",
            "        Poor       0.94      0.62      0.75    132815\n",
            "\n",
            "    accuracy                           0.61    158762\n",
            "   macro avg       0.44      0.58      0.44    158762\n",
            "weighted avg       0.82      0.61      0.68    158762\n",
            "\n",
            "[[ 8587  4763  3867]\n",
            " [ 2322  5312  1096]\n",
            " [27914 22200 82701]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Wycway-yOk",
        "colab_type": "text"
      },
      "source": [
        "Cat Boost with MultiClass Loss function, AUC as metric and iterations = 60, max_depth = 15, learning_rate = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76Hxo5-0-nxg",
        "colab_type": "code",
        "outputId": "5956562d-c32f-4f25-f5f4-7865ac57bb56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = CatBoostClassifier(random_seed=42,loss_function='MultiClass',eval_metric = 'AUC',class_weights=sample_weights_data,early_stopping_rounds=2,iterations=60, max_depth=15, learning_rate=0.2)\n",
        "clf.fit(X_train, y_train, cat_features=cate_features_index )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\ttotal: 47s\tremaining: 46m 10s\n",
            "1:\ttotal: 1m 33s\tremaining: 45m 1s\n",
            "2:\ttotal: 2m 24s\tremaining: 45m 51s\n",
            "3:\ttotal: 3m 11s\tremaining: 44m 43s\n",
            "4:\ttotal: 3m 57s\tremaining: 43m 34s\n",
            "5:\ttotal: 4m 44s\tremaining: 42m 43s\n",
            "6:\ttotal: 5m 30s\tremaining: 41m 43s\n",
            "7:\ttotal: 6m 18s\tremaining: 41m\n",
            "8:\ttotal: 7m 6s\tremaining: 40m 14s\n",
            "9:\ttotal: 7m 52s\tremaining: 39m 22s\n",
            "10:\ttotal: 8m 38s\tremaining: 38m 30s\n",
            "11:\ttotal: 9m 24s\tremaining: 37m 37s\n",
            "12:\ttotal: 10m 10s\tremaining: 36m 47s\n",
            "13:\ttotal: 10m 57s\tremaining: 35m 59s\n",
            "14:\ttotal: 11m 44s\tremaining: 35m 13s\n",
            "15:\ttotal: 12m 30s\tremaining: 34m 22s\n",
            "16:\ttotal: 13m 16s\tremaining: 33m 34s\n",
            "17:\ttotal: 14m 3s\tremaining: 32m 49s\n",
            "18:\ttotal: 14m 49s\tremaining: 32m\n",
            "19:\ttotal: 15m 36s\tremaining: 31m 13s\n",
            "20:\ttotal: 16m 22s\tremaining: 30m 24s\n",
            "21:\ttotal: 17m 9s\tremaining: 29m 38s\n",
            "22:\ttotal: 17m 55s\tremaining: 28m 50s\n",
            "23:\ttotal: 18m 43s\tremaining: 28m 4s\n",
            "24:\ttotal: 19m 28s\tremaining: 27m 16s\n",
            "25:\ttotal: 20m 14s\tremaining: 26m 28s\n",
            "26:\ttotal: 20m 59s\tremaining: 25m 39s\n",
            "27:\ttotal: 21m 46s\tremaining: 24m 53s\n",
            "28:\ttotal: 22m 32s\tremaining: 24m 5s\n",
            "29:\ttotal: 23m 18s\tremaining: 23m 18s\n",
            "30:\ttotal: 24m 4s\tremaining: 22m 31s\n",
            "31:\ttotal: 24m 51s\tremaining: 21m 44s\n",
            "32:\ttotal: 25m 37s\tremaining: 20m 57s\n",
            "33:\ttotal: 26m 24s\tremaining: 20m 11s\n",
            "34:\ttotal: 26m 24s\tremaining: 18m 51s\n",
            "35:\ttotal: 27m 16s\tremaining: 18m 11s\n",
            "36:\ttotal: 28m 3s\tremaining: 17m 26s\n",
            "37:\ttotal: 28m 49s\tremaining: 16m 41s\n",
            "38:\ttotal: 29m 35s\tremaining: 15m 56s\n",
            "39:\ttotal: 29m 36s\tremaining: 14m 48s\n",
            "40:\ttotal: 30m 23s\tremaining: 14m 4s\n",
            "41:\ttotal: 30m 24s\tremaining: 13m 1s\n",
            "42:\ttotal: 30m 24s\tremaining: 12m 1s\n",
            "43:\ttotal: 31m 11s\tremaining: 11m 20s\n",
            "44:\ttotal: 31m 59s\tremaining: 10m 39s\n",
            "45:\ttotal: 32m 46s\tremaining: 9m 58s\n",
            "46:\ttotal: 33m 33s\tremaining: 9m 16s\n",
            "47:\ttotal: 34m 20s\tremaining: 8m 35s\n",
            "48:\ttotal: 35m 9s\tremaining: 7m 53s\n",
            "49:\ttotal: 36m 1s\tremaining: 7m 12s\n",
            "50:\ttotal: 36m 46s\tremaining: 6m 29s\n",
            "51:\ttotal: 37m 33s\tremaining: 5m 46s\n",
            "52:\ttotal: 38m 26s\tremaining: 5m 4s\n",
            "53:\ttotal: 38m 31s\tremaining: 4m 16s\n",
            "54:\ttotal: 39m 20s\tremaining: 3m 34s\n",
            "55:\ttotal: 40m 7s\tremaining: 2m 51s\n",
            "56:\ttotal: 40m 54s\tremaining: 2m 9s\n",
            "57:\ttotal: 40m 55s\tremaining: 1m 24s\n",
            "58:\ttotal: 41m 42s\tremaining: 42.4s\n",
            "59:\ttotal: 42m 30s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f9c250919e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqZ7BnFeGwmz",
        "colab_type": "code",
        "outputId": "612b52c6-8dd8-4647-a5a7-278075a6d9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "y_pred = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,y_pred))\n",
        "print(confusion_matrix(y_valid,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.23      0.51      0.31     17217\n",
            "        Okay       0.16      0.59      0.26      8730\n",
            "        Poor       0.94      0.63      0.76    132815\n",
            "\n",
            "    accuracy                           0.62    158762\n",
            "   macro avg       0.45      0.58      0.44    158762\n",
            "weighted avg       0.82      0.62      0.68    158762\n",
            "\n",
            "[[ 8743  4569  3905]\n",
            " [ 2402  5154  1174]\n",
            " [27164 21632 84019]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1gkoRs0KJNd",
        "colab_type": "text"
      },
      "source": [
        "Cat Boost with MultiClass Loss function, AUC as metric and iterations=100, depth=15, learning_rate=0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "89fe6249-306d-434d-81ff-9134af461a53",
        "id": "Ftq1ryyTrfC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = CatBoostClassifier(random_seed=42,loss_function='MultiClass',eval_metric = 'AUC',class_weights=sample_weights_data,early_stopping_rounds=2,iterations=100, depth=15, learning_rate=0.1)\n",
        "clf.fit(X_train, y_train, cat_features=cate_features_index )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\ttotal: 22.9s\tremaining: 37m 42s\n",
            "1:\ttotal: 45.1s\tremaining: 36m 50s\n",
            "2:\ttotal: 1m 9s\tremaining: 37m 13s\n",
            "3:\ttotal: 1m 36s\tremaining: 38m 31s\n",
            "4:\ttotal: 2m 3s\tremaining: 39m 12s\n",
            "5:\ttotal: 2m 31s\tremaining: 39m 32s\n",
            "6:\ttotal: 3m\tremaining: 40m 4s\n",
            "7:\ttotal: 3m 31s\tremaining: 40m 28s\n",
            "8:\ttotal: 4m 1s\tremaining: 40m 45s\n",
            "9:\ttotal: 4m 33s\tremaining: 40m 58s\n",
            "10:\ttotal: 5m 4s\tremaining: 41m 5s\n",
            "11:\ttotal: 5m 36s\tremaining: 41m 9s\n",
            "12:\ttotal: 6m 9s\tremaining: 41m 14s\n",
            "13:\ttotal: 6m 42s\tremaining: 41m 9s\n",
            "14:\ttotal: 7m 15s\tremaining: 41m 9s\n",
            "15:\ttotal: 7m 48s\tremaining: 40m 59s\n",
            "16:\ttotal: 8m 21s\tremaining: 40m 46s\n",
            "17:\ttotal: 8m 53s\tremaining: 40m 32s\n",
            "18:\ttotal: 9m 27s\tremaining: 40m 18s\n",
            "19:\ttotal: 10m 1s\tremaining: 40m 4s\n",
            "20:\ttotal: 10m 35s\tremaining: 39m 48s\n",
            "21:\ttotal: 11m 9s\tremaining: 39m 32s\n",
            "22:\ttotal: 11m 9s\tremaining: 37m 22s\n",
            "23:\ttotal: 11m 42s\tremaining: 37m 5s\n",
            "24:\ttotal: 12m 17s\tremaining: 36m 51s\n",
            "25:\ttotal: 12m 51s\tremaining: 36m 34s\n",
            "26:\ttotal: 13m 25s\tremaining: 36m 17s\n",
            "27:\ttotal: 13m 58s\tremaining: 35m 57s\n",
            "28:\ttotal: 14m 32s\tremaining: 35m 36s\n",
            "29:\ttotal: 15m 5s\tremaining: 35m 13s\n",
            "30:\ttotal: 15m 40s\tremaining: 34m 52s\n",
            "31:\ttotal: 16m 14s\tremaining: 34m 30s\n",
            "32:\ttotal: 16m 48s\tremaining: 34m 7s\n",
            "33:\ttotal: 17m 22s\tremaining: 33m 43s\n",
            "34:\ttotal: 17m 56s\tremaining: 33m 19s\n",
            "35:\ttotal: 18m 31s\tremaining: 32m 55s\n",
            "36:\ttotal: 19m 5s\tremaining: 32m 31s\n",
            "37:\ttotal: 19m 41s\tremaining: 32m 7s\n",
            "38:\ttotal: 20m 17s\tremaining: 31m 44s\n",
            "39:\ttotal: 20m 52s\tremaining: 31m 19s\n",
            "40:\ttotal: 21m 28s\tremaining: 30m 53s\n",
            "41:\ttotal: 22m 3s\tremaining: 30m 27s\n",
            "42:\ttotal: 22m 37s\tremaining: 29m 59s\n",
            "43:\ttotal: 23m 12s\tremaining: 29m 32s\n",
            "44:\ttotal: 23m 46s\tremaining: 29m 4s\n",
            "45:\ttotal: 24m 20s\tremaining: 28m 34s\n",
            "46:\ttotal: 24m 55s\tremaining: 28m 6s\n",
            "47:\ttotal: 25m 30s\tremaining: 27m 37s\n",
            "48:\ttotal: 26m 4s\tremaining: 27m 8s\n",
            "49:\ttotal: 26m 39s\tremaining: 26m 39s\n",
            "50:\ttotal: 27m 13s\tremaining: 26m 9s\n",
            "51:\ttotal: 27m 14s\tremaining: 25m 8s\n",
            "52:\ttotal: 27m 14s\tremaining: 24m 9s\n",
            "53:\ttotal: 27m 49s\tremaining: 23m 42s\n",
            "54:\ttotal: 28m 24s\tremaining: 23m 14s\n",
            "55:\ttotal: 28m 25s\tremaining: 22m 19s\n",
            "56:\ttotal: 29m\tremaining: 21m 52s\n",
            "57:\ttotal: 29m 34s\tremaining: 21m 24s\n",
            "58:\ttotal: 30m 8s\tremaining: 20m 56s\n",
            "59:\ttotal: 30m 42s\tremaining: 20m 28s\n",
            "60:\ttotal: 31m 17s\tremaining: 20m\n",
            "61:\ttotal: 31m 50s\tremaining: 19m 30s\n",
            "62:\ttotal: 32m 25s\tremaining: 19m 2s\n",
            "63:\ttotal: 32m 58s\tremaining: 18m 33s\n",
            "64:\ttotal: 33m 33s\tremaining: 18m 3s\n",
            "65:\ttotal: 34m 10s\tremaining: 17m 36s\n",
            "66:\ttotal: 34m 44s\tremaining: 17m 6s\n",
            "67:\ttotal: 35m 18s\tremaining: 16m 37s\n",
            "68:\ttotal: 35m 52s\tremaining: 16m 6s\n",
            "69:\ttotal: 36m 26s\tremaining: 15m 36s\n",
            "70:\ttotal: 37m 1s\tremaining: 15m 7s\n",
            "71:\ttotal: 37m 39s\tremaining: 14m 38s\n",
            "72:\ttotal: 37m 40s\tremaining: 13m 55s\n",
            "73:\ttotal: 38m 14s\tremaining: 13m 26s\n",
            "74:\ttotal: 38m 48s\tremaining: 12m 56s\n",
            "75:\ttotal: 39m 22s\tremaining: 12m 25s\n",
            "76:\ttotal: 39m 55s\tremaining: 11m 55s\n",
            "77:\ttotal: 40m 29s\tremaining: 11m 25s\n",
            "78:\ttotal: 41m 3s\tremaining: 10m 54s\n",
            "79:\ttotal: 41m 37s\tremaining: 10m 24s\n",
            "80:\ttotal: 42m 11s\tremaining: 9m 53s\n",
            "81:\ttotal: 42m 44s\tremaining: 9m 22s\n",
            "82:\ttotal: 43m 18s\tremaining: 8m 52s\n",
            "83:\ttotal: 43m 52s\tremaining: 8m 21s\n",
            "84:\ttotal: 44m 25s\tremaining: 7m 50s\n",
            "85:\ttotal: 44m 59s\tremaining: 7m 19s\n",
            "86:\ttotal: 45m 32s\tremaining: 6m 48s\n",
            "87:\ttotal: 46m 5s\tremaining: 6m 17s\n",
            "88:\ttotal: 46m 39s\tremaining: 5m 45s\n",
            "89:\ttotal: 46m 39s\tremaining: 5m 11s\n",
            "90:\ttotal: 47m 14s\tremaining: 4m 40s\n",
            "91:\ttotal: 47m 50s\tremaining: 4m 9s\n",
            "92:\ttotal: 48m 25s\tremaining: 3m 38s\n",
            "93:\ttotal: 48m 58s\tremaining: 3m 7s\n",
            "94:\ttotal: 49m 31s\tremaining: 2m 36s\n",
            "95:\ttotal: 49m 32s\tremaining: 2m 3s\n",
            "96:\ttotal: 50m 8s\tremaining: 1m 33s\n",
            "97:\ttotal: 50m 42s\tremaining: 1m 2s\n",
            "98:\ttotal: 51m 14s\tremaining: 31.1s\n",
            "99:\ttotal: 51m 48s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f2a0f2a1550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPzf7_jyQkwZ",
        "colab_type": "code",
        "outputId": "fd2b7d0a-0f13-4a36-f011-5d2aca42b35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "y_pred = clf.predict(X_valid)\n",
        "print(classification_report(y_valid,y_pred))\n",
        "print(confusion_matrix(y_valid,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.23      0.51      0.31     17217\n",
            "        Okay       0.17      0.60      0.26      8730\n",
            "        Poor       0.94      0.63      0.76    132815\n",
            "\n",
            "    accuracy                           0.62    158762\n",
            "   macro avg       0.45      0.58      0.44    158762\n",
            "weighted avg       0.82      0.62      0.68    158762\n",
            "\n",
            "[[ 8712  4607  3898]\n",
            " [ 2335  5238  1157]\n",
            " [27088 21597 84130]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQcsj49LMS30",
        "colab_type": "text"
      },
      "source": [
        "The above model was the best one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g0ul56xMWo6",
        "colab_type": "text"
      },
      "source": [
        "**Preictions on test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yykDruTJQkiZ",
        "colab_type": "code",
        "outputId": "1bda0c90-3e17-4b66-822f-ba5d839c755b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Good       0.23      0.51      0.32     19565\n",
            "        Okay       0.17      0.60      0.26      9920\n",
            "        Poor       0.94      0.64      0.76    150926\n",
            "\n",
            "    accuracy                           0.62    180411\n",
            "   macro avg       0.45      0.58      0.44    180411\n",
            "weighted avg       0.82      0.62      0.68    180411\n",
            "\n",
            "[[ 9887  5427  4251]\n",
            " [ 2634  5914  1372]\n",
            " [30606 24419 95901]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}